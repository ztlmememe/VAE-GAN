{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_it_pool:  [0, 2000]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "================== Exp 80 ==================\n",
      " \n",
      "Hyper-parameters: \n",
      " {'dataset': 'CIFAR10', 'model': 'ConvNet', 'ipc': 50, 'eval_mode': 'SS', 'num_exp': 3, 'num_eval': 1, 'epoch_eval_train': 1000, 'Iteration': 2000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/home/ssd7T/ZTL_gcond/data_cv', 'save_path': '/home/ssd7T/ztl_dm/gen', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 50, 'inner_loop': 10, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7fbee0db1df0>, 'dsa': True}\n",
      "Evaluation model pool:  ['ConvNet']\n",
      "class c = 0: 5000 real images\n",
      "class c = 1: 5000 real images\n",
      "class c = 2: 5000 real images\n",
      "class c = 3: 5000 real images\n",
      "class c = 4: 5000 real images\n",
      "class c = 5: 5000 real images\n",
      "class c = 6: 5000 real images\n",
      "class c = 7: 5000 real images\n",
      "class c = 8: 5000 real images\n",
      "class c = 9: 5000 real images\n",
      "real images channel 0, mean = -0.0000, std = 1.2211\n",
      "real images channel 1, mean = -0.0002, std = 1.2211\n",
      "real images channel 2, mean = 0.0002, std = 1.3014\n",
      "initialize synthetic data from random real images\n",
      "\n",
      "================== Exp 81 ==================\n",
      " \n",
      "Hyper-parameters: \n",
      " {'dataset': 'CIFAR10', 'model': 'ConvNet', 'ipc': 50, 'eval_mode': 'SS', 'num_exp': 3, 'num_eval': 1, 'epoch_eval_train': 1000, 'Iteration': 2000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/home/ssd7T/ZTL_gcond/data_cv', 'save_path': '/home/ssd7T/ztl_dm/gen', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 50, 'inner_loop': 10, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7fbee0db1df0>, 'dsa': True}\n",
      "Evaluation model pool:  ['ConvNet']\n",
      "class c = 0: 5000 real images\n",
      "class c = 1: 5000 real images\n",
      "class c = 2: 5000 real images\n",
      "class c = 3: 5000 real images\n",
      "class c = 4: 5000 real images\n",
      "class c = 5: 5000 real images\n",
      "class c = 6: 5000 real images\n",
      "class c = 7: 5000 real images\n",
      "class c = 8: 5000 real images\n",
      "class c = 9: 5000 real images\n",
      "real images channel 0, mean = -0.0000, std = 1.2211\n",
      "real images channel 1, mean = -0.0002, std = 1.2211\n",
      "real images channel 2, mean = 0.0002, std = 1.3014\n",
      "initialize synthetic data from random real images\n",
      "\n",
      "================== Exp 82 ==================\n",
      " \n",
      "Hyper-parameters: \n",
      " {'dataset': 'CIFAR10', 'model': 'ConvNet', 'ipc': 50, 'eval_mode': 'SS', 'num_exp': 3, 'num_eval': 1, 'epoch_eval_train': 1000, 'Iteration': 2000, 'lr_img': 1.0, 'lr_net': 0.01, 'batch_real': 256, 'batch_train': 256, 'init': 'real', 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'data_path': '/home/ssd7T/ZTL_gcond/data_cv', 'save_path': '/home/ssd7T/ztl_dm/gen', 'dis_metric': 'ours', 'method': 'DM', 'outer_loop': 50, 'inner_loop': 10, 'device': 'cuda', 'dsa_param': <utils.ParamDiffAug object at 0x7fbee0db1df0>, 'dsa': True}\n",
      "Evaluation model pool:  ['ConvNet']\n",
      "class c = 0: 5000 real images\n",
      "class c = 1: 5000 real images\n",
      "class c = 2: 5000 real images\n",
      "class c = 3: 5000 real images\n",
      "class c = 4: 5000 real images\n",
      "class c = 5: 5000 real images\n",
      "class c = 6: 5000 real images\n",
      "class c = 7: 5000 real images\n",
      "class c = 8: 5000 real images\n",
      "class c = 9: 5000 real images\n",
      "real images channel 0, mean = -0.0000, std = 1.2211\n",
      "real images channel 1, mean = -0.0002, std = 1.2211\n",
      "real images channel 2, mean = 0.0002, std = 1.3014\n",
      "initialize synthetic data from random real images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "from utils import get_loops, get_dataset, get_network, get_eval_pool, evaluate_synset, get_daparam, match_loss, get_time, TensorDataset, epoch, DiffAugment, ParamDiffAug\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# watch -n 1 nvidia-smi\n",
    "import os\n",
    "\n",
    "# 显示第 0 和第 1 个 GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "parser = argparse.ArgumentParser(description='Parameter Processing')\n",
    "parser.add_argument('--dataset', type=str, default='CIFAR10', help='dataset')\n",
    "parser.add_argument('--model', type=str, default='ConvNet', help='model')\n",
    "parser.add_argument('--ipc', type=int, default=50, help='image(s) per class')\n",
    "parser.add_argument('--eval_mode', type=str, default='SS', help='eval_mode') # S: the same to training model, M: multi architectures,  W: net width, D: net depth, A: activation function, P: pooling layer, N: normalization layer,\n",
    "\n",
    "\n",
    "\n",
    "parser.add_argument('--num_exp', type=int, default=3, help='the number of experiments')\n",
    "\n",
    "\n",
    "\n",
    "parser.add_argument('--num_eval', type=int, default=1, help='the number of evaluating randomly initialized models')\n",
    "parser.add_argument('--epoch_eval_train', type=int, default=1000, help='epochs to train a model with synthetic data') # it can be small for speeding up with little performance drop\n",
    "parser.add_argument('--Iteration', type=int, default=2000, help='training iterations')\n",
    "parser.add_argument('--lr_img', type=float, default=1.0, help='learning rate for updating synthetic images')\n",
    "parser.add_argument('--lr_net', type=float, default=0.01, help='learning rate for updating network parameters')\n",
    "parser.add_argument('--batch_real', type=int, default=256, help='batch size for real data')\n",
    "parser.add_argument('--batch_train', type=int, default=256, help='batch size for training networks')\n",
    "parser.add_argument('--init', type=str, default='real', help='noise/real: initialize synthetic images from random noise or randomly sampled real images.')\n",
    "parser.add_argument('--dsa_strategy', type=str, default='color_crop_cutout_flip_scale_rotate', help='differentiable Siamese augmentation strategy')\n",
    "parser.add_argument('--data_path', type=str, default='/home/ssd7T/ZTL_gcond/data_cv', help='dataset path')\n",
    "parser.add_argument('--save_path', type=str, default='/home/ssd7T/ztl_dm/gen', help='path to save results')\n",
    "parser.add_argument('--dis_metric', type=str, default='ours', help='distance metric')\n",
    "\n",
    "args = parser.parse_args([])\n",
    "args.method = 'DM'\n",
    "args.outer_loop, args.inner_loop = get_loops(args.ipc)\n",
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "args.dsa_param = ParamDiffAug()\n",
    "args.dsa = False if args.dsa_strategy in ['none', 'None'] else True\n",
    "\n",
    "if not os.path.exists(args.data_path):\n",
    "    os.mkdir(args.data_path)\n",
    "\n",
    "if not os.path.exists(args.save_path):\n",
    "    os.mkdir(args.save_path)\n",
    "\n",
    "eval_it_pool = np.arange(0, args.Iteration+1, 2000).tolist() if args.eval_mode == 'S' or args.eval_mode == 'SS' else [args.Iteration] # The list of iterations when we evaluate models and record results.\n",
    "print('eval_it_pool: ', eval_it_pool)\n",
    "channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader = get_dataset(args.dataset, args.data_path)\n",
    "model_eval_pool = get_eval_pool(args.eval_mode, args.model, args.model)\n",
    "\n",
    "\n",
    "accs_all_exps = dict() # record performances of all experiments\n",
    "for key in model_eval_pool:\n",
    "    accs_all_exps[key] = []\n",
    "\n",
    "data_save = []\n",
    "pairs_real = []\n",
    "indexs_real = []\n",
    "\n",
    "for exp in range(args.num_exp):\n",
    "    # pairs_real = []\n",
    "    # indexs_real = []\n",
    "    exp = exp + 80\n",
    "    print('\\n================== Exp %d ==================\\n '%exp)\n",
    "    print('Hyper-parameters: \\n', args.__dict__)\n",
    "    print('Evaluation model pool: ', model_eval_pool)\n",
    "\n",
    "    ''' organize the real dataset '''\n",
    "    images_all = []\n",
    "    labels_all = []\n",
    "    indices_class = [[] for c in range(num_classes)]\n",
    "\n",
    "    images_all = [torch.unsqueeze(dst_train[i][0], dim=0) for i in range(len(dst_train))]\n",
    "    labels_all = [dst_train[i][1] for i in range(len(dst_train))]\n",
    "    for i, lab in enumerate(labels_all):\n",
    "        indices_class[lab].append(i)\n",
    "    images_all = torch.cat(images_all, dim=0).to(args.device)\n",
    "    labels_all = torch.tensor(labels_all, dtype=torch.long, device=args.device)\n",
    "\n",
    "\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        print('class c = %d: %d real images'%(c, len(indices_class[c])))\n",
    "\n",
    "    def get_images(c, n): # get random n images from class c\n",
    "        idx_shuffle = np.random.permutation(indices_class[c])[:n]\n",
    "        return images_all[idx_shuffle]\n",
    "    \n",
    "    def get_images_init(c, n,exp): # get random n images from class c\n",
    "        # start_idx = i  # 指定起始索引 i\n",
    "        # end_idx = i + n  # 计算结束索引（不包括结束索引）\n",
    "\n",
    "        # 从指定的起始索引到结束索引获取元素\n",
    "        idx_shuffle  = indices_class[c][exp:exp + n]\n",
    "\n",
    "        # idx_shuffle = np.random.permutation(indices_class[c])[:n]\n",
    "        return images_all[idx_shuffle],idx_shuffle\n",
    "\n",
    "    for ch in range(channel):\n",
    "        print('real images channel %d, mean = %.4f, std = %.4f'%(ch, torch.mean(images_all[:, ch]), torch.std(images_all[:, ch])))\n",
    "\n",
    "\n",
    "    ''' initialize the synthetic data '''\n",
    "    image_syn = torch.randn(size=(num_classes*args.ipc, channel, im_size[0], im_size[1]), dtype=torch.float, requires_grad=True, device=args.device)\n",
    "    label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]\n",
    "\n",
    "    if args.init == 'real':\n",
    "        print('initialize synthetic data from random real images')\n",
    "        for c in range(num_classes):\n",
    "            reals,index = get_images_init(c, args.ipc,exp)\n",
    "            reals = reals.detach().data\n",
    "            pairs_real.append(reals)\n",
    "            indexs_real.append(index)\n",
    "            image_syn.data[c*args.ipc:(c+1)*args.ipc] = reals\n",
    "            # pairs_real\n",
    "    else:\n",
    "        print('initialize synthetic data from random noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_real_test= torch.cat(pairs_real, dim=0)\n",
    "\n",
    "label_real_test = []\n",
    "for i in range(int(len(indexs_real)/10)):\n",
    "    # print(i)\n",
    "    label_real_test_ = []\n",
    "    for c in range(num_classes):\n",
    "        idx_shuffle = indexs_real[c + i*10]\n",
    "        label_real_test_.append(labels_all[idx_shuffle].to(\"cpu\"))\n",
    "        # print()\n",
    "    # img_real = torch.from_numpy(np.concatenate(img_real, axis=0))\n",
    "    label_real_test_ = torch.from_numpy(np.concatenate(label_real_test_, axis=0))\n",
    "    label_real_test.append(label_real_test_)\n",
    "label_real_test = torch.cat(label_real_test, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_syn = []\n",
    "label_syn = []\n",
    "img_real_train = []\n",
    "label_real_train = []\n",
    "# /home/ssd7T/ztl_dm/indexs_real_20.pt\n",
    "for i in range(80):\n",
    "    try:\n",
    "    \n",
    "        img_syn_ = torch.load(f'/home/ssd7T/ztl_dm/img_syn_{i}.pt')\n",
    "        label_syn_ = torch.load(f'/home/ssd7T/ztl_dm/label_syn_{i}.pt')\n",
    "        pairs_real_=torch.load(f'/home/ssd7T/ztl_dm/pairs_real_{i}.pt')\n",
    "        indexs_real_=torch.load(f'/home/ssd7T/ztl_dm/indexs_real_{i}.pt')\n",
    "        \n",
    "        img_real_train_ = torch.cat(pairs_real_, dim=0)\n",
    "        \n",
    "    \n",
    "        label_real_ = []\n",
    "        for c in range(num_classes):\n",
    "            idx_shuffle = indexs_real_[c]\n",
    "            label_real_.append(labels_all[idx_shuffle].to(\"cpu\"))\n",
    "        # img_real = torch.from_numpy(np.concatenate(img_real, axis=0))\n",
    "        label_real_train_ = torch.from_numpy(np.concatenate(label_real_, axis=0))\n",
    "        # label_real_train_ = torch.cat(label_real_train_, dim=0)\n",
    "        \n",
    "        img_syn.append(img_syn_)\n",
    "        label_syn.append(label_syn_)\n",
    "        img_real_train.append(img_real_train_)\n",
    "        label_real_train.append( label_real_train_)\n",
    "        # if i == 3 or i == 22 or i == 42 or i == 62:\n",
    "        #     pairs_real_=torch.load(f'pairs_real_{i}.pt')\n",
    "        #     img_real_train_ = torch.cat(pairs_real_, dim=0)\n",
    "        #     img_real_train.append(img_real_train_)\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "img_syn = torch.cat(img_syn, dim=0).to(device)\n",
    "label_syn = torch.cat(label_syn, dim=0).to(device)\n",
    "img_real_train = torch.cat(img_real_train, dim=0).to(device)\n",
    "label_real_train = torch.cat(label_real_train, dim=0).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18000, 3, 32, 32])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_real_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "model_eval_pool = get_eval_pool(args.eval_mode, args.model, args.model)\n",
    "import copy\n",
    "accs_all_exps = dict() # record performances of all experiments\n",
    "for key in model_eval_pool:\n",
    "    accs_all_exps[key] = []\n",
    "args.dsa_param = ParamDiffAug()\n",
    "args.dsa = False if args.dsa_strategy in ['none', 'None'] else True\n",
    "model_eval= model_eval_pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_classes = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from a_cvae import  CVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-14 13:58:24] Evaluate_01: epoch = 1000 train time = 2937 s train loss = 0.064025 train acc = 0.9830, test acc = 0.8752\n"
     ]
    }
   ],
   "source": [
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(images_all), copy.deepcopy(labels_all) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_syn = []\n",
    "label_syn = []\n",
    "img_real_train = []\n",
    "label_real_train = []\n",
    "# /home/ssd7T/ztl_dm/indexs_real_20.pt\n",
    "for i in range(90):\n",
    "    try:\n",
    "    # /home/ssd7T/ztl_ftd/pairs_real_72.pt\n",
    "        img_syn_ = torch.load(f'/home/ssd7T/ztl_ftd/img_syn_{i}.pt')\n",
    "        label_syn_ = torch.load(f'/home/ssd7T/ztl_ftd/label_syn_{i}.pt')\n",
    "        pairs_real_=torch.load(f'/home/ssd7T/ztl_ftd/pairs_real_{i}.pt')\n",
    "        indexs_real_=torch.load(f'/home/ssd7T/ztl_ftd/indexs_real_{i}.pt')\n",
    "        \n",
    "        img_real_train_ = torch.cat(pairs_real_, dim=0)\n",
    "        \n",
    "    \n",
    "        label_real_ = []\n",
    "        for c in range(num_classes):\n",
    "            idx_shuffle = indexs_real_[c]\n",
    "            label_real_.append(labels_all[idx_shuffle].to(\"cpu\"))\n",
    "        # img_real = torch.from_numpy(np.concatenate(img_real, axis=0))\n",
    "        label_real_train_ = torch.from_numpy(np.concatenate(label_real_, axis=0))\n",
    "        # label_real_train_ = torch.cat(label_real_train_, dim=0)\n",
    "        \n",
    "        img_syn.append(img_syn_)\n",
    "        label_syn.append(label_syn_)\n",
    "        img_real_train.append(img_real_train_)\n",
    "        label_real_train.append( label_real_train_)\n",
    "        # if i == 3 or i == 22 or i == 42 or i == 62:\n",
    "        #     pairs_real_=torch.load(f'pairs_real_{i}.pt')\n",
    "        #     img_real_train_ = torch.cat(pairs_real_, dim=0)\n",
    "        #     img_real_train.append(img_real_train_)\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "img_syn = torch.cat(img_syn, dim=0).to(device)\n",
    "label_syn = torch.cat(label_syn, dim=0).to(device)\n",
    "img_real_train = torch.cat(img_real_train, dim=0).to(device)\n",
    "label_real_train = torch.cat(label_real_train, dim=0).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40000, 3, 32, 32])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_syn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40000, 3, 32, 32])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_real_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 3, 32, 32])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90000, 3, 32, 32])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((img_real_train,images_all), dim = 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 9, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((label_syn,labels_all), dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 230 || 0.422725647687912\n",
      "====> Epoch: 240 || 0.482896089553833\n",
      "====> Epoch: 250 || 0.4822136163711548\n",
      "====> Epoch: 260 || 0.5269333124160767\n",
      "====> Epoch: 270 || 0.4414944052696228\n",
      "====> Epoch: 280 || 0.4615752696990967\n",
      "====> Epoch: 290 || 0.4423099756240845\n",
      "====> Epoch: 300 || 0.4907228350639343\n",
      "====> Epoch: 310 || 0.46839991211891174\n",
      "====> Epoch: 320 || 0.47450411319732666\n",
      "====> Epoch: 330 || 0.4529281258583069\n",
      "====> Epoch: 340 || 0.4565031826496124\n",
      "====> Epoch: 350 || 0.4256156086921692\n",
      "====> Epoch: 360 || 0.45230239629745483\n",
      "====> Epoch: 370 || 0.480398029088974\n",
      "====> Epoch: 380 || 0.45993131399154663\n",
      "====> Epoch: 390 || 0.4347468316555023\n",
      "====> Epoch: 400 || 0.4285741448402405\n",
      "====> Epoch: 410 || 0.42451804876327515\n",
      "====> Epoch: 420 || 0.44213834404945374\n",
      "====> Epoch: 430 || 0.4809691309928894\n",
      "====> Epoch: 440 || 0.4328254759311676\n",
      "====> Epoch: 450 || 0.46104544401168823\n",
      "====> Epoch: 460 || 0.4584049880504608\n",
      "====> Epoch: 470 || 0.38739049434661865\n",
      "====> Epoch: 480 || 0.4609202742576599\n",
      "====> Epoch: 490 || 0.43681904673576355\n",
      "====> Epoch: 500 || 0.4233855605125427\n",
      "====> Epoch: 510 || 0.4229145348072052\n",
      "====> Epoch: 520 || 0.43405264616012573\n",
      "====> Epoch: 530 || 0.4410521388053894\n",
      "====> Epoch: 540 || 0.4221917390823364\n",
      "====> Epoch: 550 || 0.4378714859485626\n",
      "====> Epoch: 560 || 0.4750182330608368\n",
      "====> Epoch: 570 || 0.47211718559265137\n",
      "====> Epoch: 580 || 0.4279678761959076\n",
      "====> Epoch: 590 || 0.4748905301094055\n",
      "====> Epoch: 600 || 0.4955548346042633\n",
      "====> Epoch: 610 || 0.4451374113559723\n",
      "====> Epoch: 620 || 0.3877490162849426\n",
      "====> Epoch: 630 || 0.42284902930259705\n",
      "====> Epoch: 640 || 0.42629167437553406\n",
      "====> Epoch: 650 || 0.46125414967536926\n",
      "====> Epoch: 660 || 0.43221747875213623\n",
      "====> Epoch: 670 || 0.43265533447265625\n",
      "====> Epoch: 680 || 0.4517620801925659\n",
      "====> Epoch: 690 || 0.43290185928344727\n",
      "====> Epoch: 700 || 0.3793436884880066\n",
      "====> Epoch: 710 || 0.4029422104358673\n",
      "====> Epoch: 720 || 0.432902067899704\n",
      "====> Epoch: 730 || 0.4020022749900818\n",
      "====> Epoch: 740 || 0.484497606754303\n",
      "====> Epoch: 750 || 0.39808911085128784\n",
      "====> Epoch: 760 || 0.391687273979187\n",
      "====> Epoch: 770 || 0.43568819761276245\n",
      "====> Epoch: 780 || 0.42278602719306946\n",
      "====> Epoch: 790 || 0.4347248077392578\n",
      "====> Epoch: 800 || 0.4312109351158142\n",
      "====> Epoch: 810 || 0.449349582195282\n",
      "====> Epoch: 820 || 0.42846688628196716\n",
      "====> Epoch: 830 || 0.43459588289260864\n",
      "====> Epoch: 840 || 0.45427820086479187\n",
      "====> Epoch: 850 || 0.3988884687423706\n",
      "====> Epoch: 860 || 0.4475860893726349\n",
      "====> Epoch: 870 || 0.42947667837142944\n",
      "====> Epoch: 880 || 0.43137413263320923\n",
      "====> Epoch: 890 || 0.4414076805114746\n",
      "====> Epoch: 900 || 0.4231245219707489\n",
      "====> Epoch: 910 || 0.4200322926044464\n",
      "====> Epoch: 920 || 0.4716024398803711\n",
      "====> Epoch: 930 || 0.44667819142341614\n",
      "====> Epoch: 940 || 0.3911586105823517\n",
      "====> Epoch: 950 || 0.4134347438812256\n",
      "====> Epoch: 960 || 0.4093174636363983\n",
      "====> Epoch: 970 || 0.3701654076576233\n",
      "====> Epoch: 980 || 0.4140215218067169\n",
      "====> Epoch: 990 || 0.42444658279418945\n",
      "====> Epoch: 1000 || 0.4278605580329895\n",
      "====> Epoch: 1010 || 0.40242213010787964\n",
      "====> Epoch: 1020 || 0.3865809440612793\n",
      "====> Epoch: 1030 || 0.4086487889289856\n",
      "====> Epoch: 1040 || 0.39381396770477295\n",
      "====> Epoch: 1050 || 0.42092615365982056\n",
      "====> Epoch: 1060 || 0.41631409525871277\n",
      "====> Epoch: 1070 || 0.4599328637123108\n",
      "====> Epoch: 1080 || 0.45809483528137207\n",
      "====> Epoch: 1090 || 0.3916522264480591\n",
      "====> Epoch: 1100 || 0.417116641998291\n",
      "====> Epoch: 1110 || 0.40833550691604614\n",
      "====> Epoch: 1120 || 0.45233801007270813\n",
      "====> Epoch: 1130 || 0.44738656282424927\n",
      "====> Epoch: 1140 || 0.4150370657444\n",
      "====> Epoch: 1150 || 0.3993525505065918\n",
      "====> Epoch: 1160 || 0.41686561703681946\n",
      "====> Epoch: 1170 || 0.4004644751548767\n",
      "====> Epoch: 1180 || 0.42189380526542664\n",
      "====> Epoch: 1190 || 0.42242899537086487\n",
      "====> Epoch: 1200 || 0.39174214005470276\n",
      "====> Epoch: 1210 || 0.4059126377105713\n",
      "====> Epoch: 1220 || 0.3622209131717682\n",
      "====> Epoch: 1230 || 0.3775312304496765\n",
      "====> Epoch: 1240 || 0.3846808671951294\n",
      "====> Epoch: 1250 || 0.41588377952575684\n",
      "====> Epoch: 1260 || 0.43567603826522827\n",
      "====> Epoch: 1270 || 0.38824328780174255\n",
      "====> Epoch: 1280 || 0.3817572593688965\n",
      "====> Epoch: 1290 || 0.3959024250507355\n",
      "====> Epoch: 1300 || 0.4399019181728363\n",
      "====> Epoch: 1310 || 0.3652494251728058\n",
      "====> Epoch: 1320 || 0.4309016466140747\n",
      "====> Epoch: 1330 || 0.3999544084072113\n",
      "====> Epoch: 1340 || 0.4086061716079712\n",
      "====> Epoch: 1350 || 0.4126325845718384\n",
      "====> Epoch: 1360 || 0.37212538719177246\n",
      "====> Epoch: 1370 || 0.40899524092674255\n",
      "====> Epoch: 1380 || 0.38117948174476624\n",
      "====> Epoch: 1390 || 0.40119171142578125\n",
      "====> Epoch: 1400 || 0.3695388436317444\n",
      "====> Epoch: 1410 || 0.3964660167694092\n",
      "====> Epoch: 1420 || 0.40406864881515503\n",
      "====> Epoch: 1430 || 0.4332411289215088\n",
      "====> Epoch: 1440 || 0.4195243716239929\n",
      "====> Epoch: 1450 || 0.37312081456184387\n",
      "====> Epoch: 1460 || 0.35029157996177673\n",
      "====> Epoch: 1470 || 0.37951961159706116\n",
      "====> Epoch: 1480 || 0.39864760637283325\n",
      "====> Epoch: 1490 || 0.36711058020591736\n",
      "====> Epoch: 1500 || 0.4439377188682556\n",
      "====> Epoch: 1510 || 0.4028906524181366\n",
      "====> Epoch: 1520 || 0.4351727366447449\n",
      "====> Epoch: 1530 || 0.3971048593521118\n",
      "====> Epoch: 1540 || 0.381431519985199\n",
      "====> Epoch: 1550 || 0.3727682828903198\n",
      "====> Epoch: 1560 || 0.42506128549575806\n",
      "====> Epoch: 1570 || 0.34887000918388367\n",
      "====> Epoch: 1580 || 0.3753635585308075\n",
      "====> Epoch: 1590 || 0.3665550947189331\n",
      "====> Epoch: 1600 || 0.38761842250823975\n",
      "====> Epoch: 1610 || 0.3642943203449249\n",
      "====> Epoch: 1620 || 0.41037991642951965\n",
      "====> Epoch: 1630 || 0.3620637357234955\n",
      "====> Epoch: 1640 || 0.38334786891937256\n",
      "====> Epoch: 1650 || 0.39185768365859985\n",
      "====> Epoch: 1660 || 0.39067381620407104\n",
      "====> Epoch: 1670 || 0.3839673697948456\n",
      "====> Epoch: 1680 || 0.3751443028450012\n",
      "====> Epoch: 1690 || 0.3859538733959198\n",
      "====> Epoch: 1700 || 0.37682971358299255\n",
      "====> Epoch: 1710 || 0.3674776554107666\n",
      "====> Epoch: 1720 || 0.3557537794113159\n",
      "====> Epoch: 1730 || 0.4092942178249359\n",
      "====> Epoch: 1740 || 0.3351983428001404\n",
      "====> Epoch: 1750 || 0.37390199303627014\n",
      "====> Epoch: 1760 || 0.38519948720932007\n",
      "====> Epoch: 1770 || 0.42516887187957764\n",
      "====> Epoch: 1780 || 0.3670094311237335\n",
      "====> Epoch: 1790 || 0.4302898943424225\n",
      "====> Epoch: 1800 || 0.37982314825057983\n",
      "====> Epoch: 1810 || 0.38842031359672546\n",
      "====> Epoch: 1820 || 0.4335404932498932\n",
      "====> Epoch: 1830 || 0.4591522216796875\n",
      "====> Epoch: 1840 || 0.34033632278442383\n",
      "====> Epoch: 1850 || 0.37270867824554443\n",
      "====> Epoch: 1860 || 0.40029555559158325\n",
      "====> Epoch: 1870 || 0.4229772686958313\n",
      "====> Epoch: 1880 || 0.3598288893699646\n",
      "====> Epoch: 1890 || 0.3403973877429962\n",
      "====> Epoch: 1900 || 0.4005115032196045\n",
      "====> Epoch: 1910 || 0.37764543294906616\n",
      "====> Epoch: 1920 || 0.33519503474235535\n",
      "====> Epoch: 1930 || 0.346090167760849\n",
      "====> Epoch: 1940 || 0.3476206660270691\n",
      "====> Epoch: 1950 || 0.4029213786125183\n",
      "====> Epoch: 1960 || 0.3928990364074707\n",
      "====> Epoch: 1970 || 0.3746185302734375\n",
      "====> Epoch: 1980 || 0.3788264989852905\n",
      "====> Epoch: 1990 || 0.3352804481983185\n",
      "====> Epoch: 2000 || 0.40965574979782104\n",
      "====> Epoch: 2010 || 0.3725394606590271\n",
      "====> Epoch: 2020 || 0.3296550512313843\n",
      "====> Epoch: 2030 || 0.3788091540336609\n",
      "====> Epoch: 2040 || 0.330390989780426\n",
      "====> Epoch: 2050 || 0.35383909940719604\n",
      "====> Epoch: 2060 || 0.3459860384464264\n",
      "====> Epoch: 2070 || 0.4215419888496399\n",
      "====> Epoch: 2080 || 0.3585161566734314\n",
      "====> Epoch: 2090 || 0.39571961760520935\n",
      "====> Epoch: 2100 || 0.40781936049461365\n",
      "====> Epoch: 2110 || 0.397116482257843\n",
      "====> Epoch: 2120 || 0.375398725271225\n",
      "====> Epoch: 2130 || 0.3641342222690582\n",
      "====> Epoch: 2140 || 0.39774245023727417\n",
      "====> Epoch: 2150 || 0.3542127311229706\n",
      "====> Epoch: 2160 || 0.34519824385643005\n",
      "====> Epoch: 2170 || 0.3564760386943817\n",
      "====> Epoch: 2180 || 0.3897779583930969\n",
      "====> Epoch: 2190 || 0.33661404252052307\n",
      "====> Epoch: 2200 || 0.3698809742927551\n",
      "====> Epoch: 2210 || 0.4069039225578308\n",
      "====> Epoch: 2220 || 0.35658225417137146\n",
      "====> Epoch: 2230 || 0.40577366948127747\n",
      "====> Epoch: 2240 || 0.34029561281204224\n",
      "====> Epoch: 2250 || 0.38139843940734863\n",
      "====> Epoch: 2260 || 0.3672037124633789\n",
      "====> Epoch: 2270 || 0.39799565076828003\n",
      "====> Epoch: 2280 || 0.4148330092430115\n",
      "====> Epoch: 2290 || 0.37291109561920166\n",
      "====> Epoch: 2300 || 0.3615522086620331\n",
      "====> Epoch: 2310 || 0.36695393919944763\n",
      "====> Epoch: 2320 || 0.36643803119659424\n",
      "====> Epoch: 2330 || 0.37806254625320435\n",
      "====> Epoch: 2340 || 0.34719786047935486\n",
      "====> Epoch: 2350 || 0.3626258969306946\n",
      "====> Epoch: 2360 || 0.39367660880088806\n",
      "====> Epoch: 2370 || 0.3746917247772217\n",
      "====> Epoch: 2380 || 0.3802427053451538\n",
      "====> Epoch: 2390 || 0.34720301628112793\n",
      "====> Epoch: 2400 || 0.3702930510044098\n",
      "====> Epoch: 2410 || 0.36642125248908997\n",
      "====> Epoch: 2420 || 0.3219708800315857\n",
      "====> Epoch: 2430 || 0.3795539438724518\n",
      "====> Epoch: 2440 || 0.41568562388420105\n",
      "====> Epoch: 2450 || 0.3673362135887146\n",
      "====> Epoch: 2460 || 0.3827027976512909\n",
      "====> Epoch: 2470 || 0.34329283237457275\n",
      "====> Epoch: 2480 || 0.36660924553871155\n",
      "====> Epoch: 2490 || 0.36974892020225525\n",
      "====> Epoch: 2500 || 0.36294999718666077\n",
      "====> Epoch: 2510 || 0.38046199083328247\n",
      "====> Epoch: 2520 || 0.38643500208854675\n",
      "====> Epoch: 2530 || 0.3470596969127655\n",
      "====> Epoch: 2540 || 0.37851792573928833\n",
      "====> Epoch: 2550 || 0.3822507858276367\n",
      "====> Epoch: 2560 || 0.3907329738140106\n",
      "====> Epoch: 2570 || 0.3895072042942047\n",
      "====> Epoch: 2580 || 0.38405925035476685\n",
      "====> Epoch: 2590 || 0.37217995524406433\n",
      "====> Epoch: 2600 || 0.3591561019420624\n",
      "====> Epoch: 2610 || 0.32367464900016785\n",
      "====> Epoch: 2620 || 0.3443831205368042\n",
      "====> Epoch: 2630 || 0.3476935625076294\n",
      "====> Epoch: 2640 || 0.3830266296863556\n",
      "====> Epoch: 2650 || 0.3964846134185791\n",
      "====> Epoch: 2660 || 0.32040920853614807\n",
      "====> Epoch: 2670 || 0.3380502462387085\n",
      "====> Epoch: 2680 || 0.3932696282863617\n",
      "====> Epoch: 2690 || 0.35269656777381897\n",
      "====> Epoch: 2700 || 0.38220715522766113\n",
      "====> Epoch: 2710 || 0.3520677387714386\n",
      "====> Epoch: 2720 || 0.3332453966140747\n",
      "====> Epoch: 2730 || 0.3627585768699646\n",
      "====> Epoch: 2740 || 0.39821478724479675\n",
      "====> Epoch: 2750 || 0.34468793869018555\n",
      "====> Epoch: 2760 || 0.35380181670188904\n",
      "====> Epoch: 2770 || 0.3512429893016815\n",
      "====> Epoch: 2780 || 0.3559708297252655\n",
      "====> Epoch: 2790 || 0.3816695213317871\n",
      "====> Epoch: 2800 || 0.3976646959781647\n",
      "====> Epoch: 2810 || 0.3642926514148712\n",
      "====> Epoch: 2820 || 0.39629867672920227\n",
      "====> Epoch: 2830 || 0.3725491464138031\n",
      "====> Epoch: 2840 || 0.40170836448669434\n",
      "====> Epoch: 2850 || 0.3797587752342224\n",
      "====> Epoch: 2860 || 0.33710360527038574\n",
      "====> Epoch: 2870 || 0.3675719201564789\n",
      "====> Epoch: 2880 || 0.3614993691444397\n",
      "====> Epoch: 2890 || 0.32130539417266846\n",
      "====> Epoch: 2900 || 0.3286227285861969\n",
      "====> Epoch: 2910 || 0.3848038911819458\n",
      "====> Epoch: 2920 || 0.38961315155029297\n",
      "====> Epoch: 2930 || 0.4074121415615082\n",
      "====> Epoch: 2940 || 0.34061411023139954\n",
      "====> Epoch: 2950 || 0.3582665026187897\n",
      "====> Epoch: 2960 || 0.3796502649784088\n",
      "====> Epoch: 2970 || 0.3733198642730713\n",
      "====> Epoch: 2980 || 0.36582568287849426\n",
      "====> Epoch: 2990 || 0.3456808626651764\n",
      "====> Epoch: 2999 || 0.37940073013305664\n",
      "[2023-10-13 12:17:28] Evaluate_01: epoch = 1000 train time = 100 s train loss = 0.003055 train acc = 1.0000, test acc = 0.4639\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import argparse\n",
    "\n",
    "import torch.utils.data\n",
    "from torch import optim\n",
    "\n",
    "from torchvision.utils import save_image, make_grid\n",
    "    # 'custom': {'lr': 2e-4, 'k': 512, 'hidden': 128},\n",
    "    # 'imagenet': {'lr': 2e-4, 'k': 512, 'hidden': 128},\n",
    "    # 'cifar10': {'lr': 2e-4, 'k': 10, 'hidden': 256},\n",
    "    # 'mnist': {'lr': 1e-4, 'k': 10, 'hidden': 64}\n",
    "parser = argparse.ArgumentParser(description='Variational AutoEncoders')\n",
    "\n",
    "model_parser = parser.add_argument_group('Model Parameters')\n",
    "model_parser.add_argument('--model', default='vae', choices=['vae', 'vqvae'],\n",
    "                            help='autoencoder variant to use: vae | vqvae')\n",
    "model_parser.add_argument('--batch-size', type=int, default=128, metavar='N',\n",
    "                            help='input batch size for training (default: 128)')\n",
    "model_parser.add_argument('--hidden', type=int, default=256, metavar='N',\n",
    "                            help='number of hidden channels')\n",
    "model_parser.add_argument('-k', '--dict-size',  default=10,type=int, dest='k', metavar='K',\n",
    "                            help='number of atoms in dictionary')\n",
    "model_parser.add_argument('--lr', type=float, default=2e-4,\n",
    "                            help='learning rate')\n",
    "model_parser.add_argument('--vq_coef', type=float, default=None,\n",
    "                            help='vq coefficient in loss')\n",
    "model_parser.add_argument('--commit_coef', type=float, default=None,\n",
    "                            help='commitment coefficient in loss')\n",
    "model_parser.add_argument('--kl_coef', type=float, default=None,\n",
    "                            help='kl-divergence coefficient in loss')\n",
    "\n",
    "training_parser = parser.add_argument_group('Training Parameters')\n",
    "training_parser.add_argument('--dataset', default='cifar10', choices=['mnist', 'cifar10', 'imagenet',\n",
    "                                                                        'custom'],\n",
    "                                help='dataset to use: mnist | cifar10 | imagenet | custom')\n",
    "training_parser.add_argument('--dataset_dir_name', default='',\n",
    "                                help='name of the dir containing the dataset if dataset == custom')\n",
    "training_parser.add_argument('--data-dir', default='/media/ssd/Datasets',\n",
    "                                help='directory containing the dataset')\n",
    "training_parser.add_argument('--epochs', type=int, default=20, metavar='N',\n",
    "                                help='number of epochs to train (default: 10)')\n",
    "training_parser.add_argument('--max-epoch-samples', type=int, default=50000,\n",
    "                                help='max num of samples per epoch')\n",
    "training_parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                                help='enables CUDA training')\n",
    "training_parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                                help='random seed (default: 1)')\n",
    "training_parser.add_argument('--gpus', default='0',\n",
    "                                help='gpus used for training - e.g 0,1,3')\n",
    "\n",
    "logging_parser = parser.add_argument_group('Logging Parameters')\n",
    "logging_parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                            help='how many batches to wait before logging training status')\n",
    "logging_parser.add_argument('--results-dir', metavar='RESULTS_DIR', default='./results',\n",
    "                            help='results dir')\n",
    "logging_parser.add_argument('--save-name', default='',\n",
    "                            help='saved folder')\n",
    "logging_parser.add_argument('--data-format', default='json',\n",
    "                            help='in which format to save the data')\n",
    "\n",
    "\n",
    "# 256, 794, 3, 3\n",
    "\n",
    "args_cave = parser.parse_args([])\n",
    "\n",
    "\n",
    "torch.manual_seed(args_cave.seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(args_cave.seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# dataset = MNIST(\n",
    "#     root='/home/ssd7T/ZTL_gcond/data_cv', train=True, transform=transforms.ToTensor(),\n",
    "#     download=True)\n",
    "# data_loader = DataLoader(\n",
    "#     dataset=dataset, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "lr = args_cave.lr \n",
    "k = args_cave.k \n",
    "hidden = args_cave.hidden \n",
    "num_channels = 3 # CIFA\n",
    "\n",
    "model = CVAE(d = hidden, k=k, num_channels=num_channels).to(device) \n",
    "\n",
    "# def __init__(self, d, kl_coef=0.1, **kwargs):\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 10 if args_cave.dataset == 'imagenet' else 30, 0.5,)\n",
    "    \n",
    "    \n",
    "batch = args_cave.batch_size\n",
    "# A\n",
    "\n",
    "epochs = 3000\n",
    "for epoch in range(epochs):\n",
    "\n",
    "        \n",
    "    random_indices = np.random.choice(len(img_real_train), batch, replace=False)\n",
    "\n",
    "# 使用随机选择的索引来获取数据并改变形状\n",
    "    batch_img = images_all[random_indices].reshape((batch, 3, 32, 32)).to(device)\n",
    "    # batch_syn = img_syn[random_indices].reshape((batch, 3, 32, 32)).to(device) \n",
    "    # batch_img_y = label_real_train[c*batch:(c+1)*batch].to(device) \n",
    "        \n",
    "    outputs = model(batch_img)\n",
    "    \n",
    "    loss = model.loss_function(batch_img, *outputs)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "        # logs['loss'].append(loss.item())\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == epochs -1:\n",
    "        # print(\"Epoch {:02d}/{:02d} , Loss {:9.4f}\".format(\n",
    "        #     epoch, epochs,  loss.item()))\n",
    "        print(\"====> Epoch: {} || {}\".format(epoch, loss.item()))\n",
    "        \n",
    "with torch.no_grad():\n",
    "  output = model(img_real_test.to(device))\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[0]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'cvae_all.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 || 2.066448926925659\n",
      "====> Epoch: 10 || 0.8942238092422485\n",
      "====> Epoch: 20 || 0.7132065892219543\n",
      "====> Epoch: 30 || 0.5983194708824158\n",
      "====> Epoch: 40 || 0.6322553157806396\n",
      "====> Epoch: 50 || 0.5465779304504395\n",
      "====> Epoch: 60 || 0.5191893577575684\n",
      "====> Epoch: 70 || 0.486300528049469\n",
      "====> Epoch: 80 || 0.5136184692382812\n",
      "====> Epoch: 90 || 0.45442846417427063\n",
      "====> Epoch: 100 || 0.43417632579803467\n",
      "====> Epoch: 110 || 0.5293276906013489\n",
      "====> Epoch: 120 || 0.4558901786804199\n",
      "====> Epoch: 130 || 0.4727620780467987\n",
      "====> Epoch: 140 || 0.49037349224090576\n",
      "====> Epoch: 150 || 0.46710193157196045\n",
      "====> Epoch: 160 || 0.442527174949646\n",
      "====> Epoch: 170 || 0.4338109493255615\n",
      "====> Epoch: 180 || 0.4441336989402771\n",
      "====> Epoch: 190 || 0.4115105867385864\n",
      "====> Epoch: 200 || 0.4368806481361389\n",
      "====> Epoch: 210 || 0.41821739077568054\n",
      "====> Epoch: 220 || 0.504594087600708\n",
      "====> Epoch: 230 || 0.42109209299087524\n",
      "====> Epoch: 240 || 0.4639461636543274\n",
      "====> Epoch: 250 || 0.427253782749176\n",
      "====> Epoch: 260 || 0.434297114610672\n",
      "====> Epoch: 270 || 0.4122365713119507\n",
      "====> Epoch: 280 || 0.46022921800613403\n",
      "====> Epoch: 290 || 0.4744033217430115\n",
      "====> Epoch: 300 || 0.43533647060394287\n",
      "====> Epoch: 310 || 0.41102853417396545\n",
      "====> Epoch: 320 || 0.4523215591907501\n",
      "====> Epoch: 330 || 0.44117671251296997\n",
      "====> Epoch: 340 || 0.38700002431869507\n",
      "====> Epoch: 350 || 0.40153810381889343\n",
      "====> Epoch: 360 || 0.4364572763442993\n",
      "====> Epoch: 370 || 0.400240957736969\n",
      "====> Epoch: 380 || 0.41065213084220886\n",
      "====> Epoch: 390 || 0.41396835446357727\n",
      "====> Epoch: 400 || 0.4301828145980835\n",
      "====> Epoch: 410 || 0.40905138850212097\n",
      "====> Epoch: 420 || 0.37813621759414673\n",
      "====> Epoch: 430 || 0.44221317768096924\n",
      "====> Epoch: 440 || 0.3922351896762848\n",
      "====> Epoch: 450 || 0.4461153745651245\n",
      "====> Epoch: 460 || 0.4394998848438263\n",
      "====> Epoch: 470 || 0.42617207765579224\n",
      "====> Epoch: 480 || 0.4494595527648926\n",
      "====> Epoch: 490 || 0.3853100538253784\n",
      "====> Epoch: 500 || 0.3781706988811493\n",
      "====> Epoch: 510 || 0.3950144350528717\n",
      "====> Epoch: 520 || 0.396810382604599\n",
      "====> Epoch: 530 || 0.41924604773521423\n",
      "====> Epoch: 540 || 0.4195035994052887\n",
      "====> Epoch: 550 || 0.3980666995048523\n",
      "====> Epoch: 560 || 0.4145021140575409\n",
      "====> Epoch: 570 || 0.41560041904449463\n",
      "====> Epoch: 580 || 0.40969395637512207\n",
      "====> Epoch: 590 || 0.44124752283096313\n",
      "====> Epoch: 600 || 0.3731140196323395\n",
      "====> Epoch: 610 || 0.3966815173625946\n",
      "====> Epoch: 620 || 0.39799240231513977\n",
      "====> Epoch: 630 || 0.451201856136322\n",
      "====> Epoch: 640 || 0.4321826696395874\n",
      "====> Epoch: 650 || 0.4029228985309601\n",
      "====> Epoch: 660 || 0.3926416039466858\n",
      "====> Epoch: 670 || 0.3903629779815674\n",
      "====> Epoch: 680 || 0.40291935205459595\n",
      "====> Epoch: 690 || 0.43456342816352844\n",
      "====> Epoch: 700 || 0.426065057516098\n",
      "====> Epoch: 710 || 0.40491214394569397\n",
      "====> Epoch: 720 || 0.421990305185318\n",
      "====> Epoch: 730 || 0.3712210953235626\n",
      "====> Epoch: 740 || 0.4137282073497772\n",
      "====> Epoch: 750 || 0.46144992113113403\n",
      "====> Epoch: 760 || 0.3999165892601013\n",
      "====> Epoch: 770 || 0.4247652292251587\n",
      "====> Epoch: 780 || 0.33606451749801636\n",
      "====> Epoch: 790 || 0.3616511821746826\n",
      "====> Epoch: 800 || 0.4280516505241394\n",
      "====> Epoch: 810 || 0.3635701835155487\n",
      "====> Epoch: 820 || 0.3859146535396576\n",
      "====> Epoch: 830 || 0.4327875077724457\n",
      "====> Epoch: 840 || 0.40308842062950134\n",
      "====> Epoch: 850 || 0.3992006182670593\n",
      "====> Epoch: 860 || 0.3643127679824829\n",
      "====> Epoch: 870 || 0.43202459812164307\n",
      "====> Epoch: 880 || 0.4044884443283081\n",
      "====> Epoch: 890 || 0.4193369746208191\n",
      "====> Epoch: 900 || 0.37713387608528137\n",
      "====> Epoch: 910 || 0.40957313776016235\n",
      "====> Epoch: 920 || 0.3332701623439789\n",
      "====> Epoch: 930 || 0.36449065804481506\n",
      "====> Epoch: 940 || 0.3904085159301758\n",
      "====> Epoch: 950 || 0.39424023032188416\n",
      "====> Epoch: 960 || 0.3988124132156372\n",
      "====> Epoch: 970 || 0.3992893695831299\n",
      "====> Epoch: 980 || 0.4345436692237854\n",
      "====> Epoch: 990 || 0.40241116285324097\n",
      "====> Epoch: 1000 || 0.40248367190361023\n",
      "====> Epoch: 1010 || 0.4236944913864136\n",
      "====> Epoch: 1020 || 0.39036306738853455\n",
      "====> Epoch: 1030 || 0.39894717931747437\n",
      "====> Epoch: 1040 || 0.3493863046169281\n",
      "====> Epoch: 1050 || 0.40398702025413513\n",
      "====> Epoch: 1060 || 0.39436936378479004\n",
      "====> Epoch: 1070 || 0.39966633915901184\n",
      "====> Epoch: 1080 || 0.3876344859600067\n",
      "====> Epoch: 1090 || 0.3767262101173401\n",
      "====> Epoch: 1100 || 0.3573281168937683\n",
      "====> Epoch: 1110 || 0.4000483751296997\n",
      "====> Epoch: 1120 || 0.3684764802455902\n",
      "====> Epoch: 1130 || 0.3984358310699463\n",
      "====> Epoch: 1140 || 0.4081581234931946\n",
      "====> Epoch: 1150 || 0.4053363502025604\n",
      "====> Epoch: 1160 || 0.36716315150260925\n",
      "====> Epoch: 1170 || 0.3760475814342499\n",
      "====> Epoch: 1180 || 0.4078799784183502\n",
      "====> Epoch: 1190 || 0.3349378705024719\n",
      "====> Epoch: 1200 || 0.3622478246688843\n",
      "====> Epoch: 1210 || 0.35989823937416077\n",
      "====> Epoch: 1220 || 0.4210066497325897\n",
      "====> Epoch: 1230 || 0.3421435058116913\n",
      "====> Epoch: 1240 || 0.39227432012557983\n",
      "====> Epoch: 1250 || 0.3893628716468811\n",
      "====> Epoch: 1260 || 0.41433700919151306\n",
      "====> Epoch: 1270 || 0.35140031576156616\n",
      "====> Epoch: 1280 || 0.3862268030643463\n",
      "====> Epoch: 1290 || 0.31795117259025574\n",
      "====> Epoch: 1300 || 0.3780660033226013\n",
      "====> Epoch: 1310 || 0.3543602526187897\n",
      "====> Epoch: 1320 || 0.38725945353507996\n",
      "====> Epoch: 1330 || 0.36712944507598877\n",
      "====> Epoch: 1340 || 0.3555082380771637\n",
      "====> Epoch: 1350 || 0.3769736588001251\n",
      "====> Epoch: 1360 || 0.3414781093597412\n",
      "====> Epoch: 1370 || 0.37078726291656494\n",
      "====> Epoch: 1380 || 0.3955014944076538\n",
      "====> Epoch: 1390 || 0.43738481402397156\n",
      "====> Epoch: 1400 || 0.40680867433547974\n",
      "====> Epoch: 1410 || 0.3612915277481079\n",
      "====> Epoch: 1420 || 0.37185439467430115\n",
      "====> Epoch: 1430 || 0.3409666121006012\n",
      "====> Epoch: 1440 || 0.3864263892173767\n",
      "====> Epoch: 1450 || 0.35139012336730957\n",
      "====> Epoch: 1460 || 0.36079567670822144\n",
      "====> Epoch: 1470 || 0.34952017664909363\n",
      "====> Epoch: 1480 || 0.33543092012405396\n",
      "====> Epoch: 1490 || 0.39669403433799744\n",
      "====> Epoch: 1500 || 0.3378554880619049\n",
      "====> Epoch: 1510 || 0.33100786805152893\n",
      "====> Epoch: 1520 || 0.3517124354839325\n",
      "====> Epoch: 1530 || 0.4168657958507538\n",
      "====> Epoch: 1540 || 0.34222978353500366\n",
      "====> Epoch: 1550 || 0.3678477108478546\n",
      "====> Epoch: 1560 || 0.3733568489551544\n",
      "====> Epoch: 1570 || 0.38415464758872986\n",
      "====> Epoch: 1580 || 0.3905715346336365\n",
      "====> Epoch: 1590 || 0.3740018606185913\n",
      "====> Epoch: 1600 || 0.4037962257862091\n",
      "====> Epoch: 1610 || 0.40294745564460754\n",
      "====> Epoch: 1620 || 0.3524666428565979\n",
      "====> Epoch: 1630 || 0.38346409797668457\n",
      "====> Epoch: 1640 || 0.36993592977523804\n",
      "====> Epoch: 1650 || 0.3627164363861084\n",
      "====> Epoch: 1660 || 0.38615626096725464\n",
      "====> Epoch: 1670 || 0.3914879262447357\n",
      "====> Epoch: 1680 || 0.33191901445388794\n",
      "====> Epoch: 1690 || 0.3484019637107849\n",
      "====> Epoch: 1700 || 0.37199756503105164\n",
      "====> Epoch: 1710 || 0.3631867468357086\n",
      "====> Epoch: 1720 || 0.3873871862888336\n",
      "====> Epoch: 1730 || 0.34413719177246094\n",
      "====> Epoch: 1740 || 0.3869014084339142\n",
      "====> Epoch: 1750 || 0.39986279606819153\n",
      "====> Epoch: 1760 || 0.3549458086490631\n",
      "====> Epoch: 1770 || 0.3870662450790405\n",
      "====> Epoch: 1780 || 0.34186694025993347\n",
      "====> Epoch: 1790 || 0.3656679391860962\n",
      "====> Epoch: 1800 || 0.34216538071632385\n",
      "====> Epoch: 1810 || 0.3984862267971039\n",
      "====> Epoch: 1820 || 0.4027833342552185\n",
      "====> Epoch: 1830 || 0.3990347385406494\n",
      "====> Epoch: 1840 || 0.3961900472640991\n",
      "====> Epoch: 1850 || 0.38734832406044006\n",
      "====> Epoch: 1860 || 0.41916996240615845\n",
      "====> Epoch: 1870 || 0.35681578516960144\n",
      "====> Epoch: 1880 || 0.3760063052177429\n",
      "====> Epoch: 1890 || 0.32858845591545105\n",
      "====> Epoch: 1900 || 0.37218958139419556\n",
      "====> Epoch: 1910 || 0.37155604362487793\n",
      "====> Epoch: 1920 || 0.37789541482925415\n",
      "====> Epoch: 1930 || 0.37244534492492676\n",
      "====> Epoch: 1940 || 0.3198946416378021\n",
      "====> Epoch: 1950 || 0.36141636967658997\n",
      "====> Epoch: 1960 || 0.368020236492157\n",
      "====> Epoch: 1970 || 0.3700093626976013\n",
      "====> Epoch: 1980 || 0.3971193730831146\n",
      "====> Epoch: 1990 || 0.3318731188774109\n",
      "====> Epoch: 2000 || 0.35650327801704407\n",
      "====> Epoch: 2010 || 0.3664533197879791\n",
      "====> Epoch: 2020 || 0.3512658178806305\n",
      "====> Epoch: 2030 || 0.3725389838218689\n",
      "====> Epoch: 2040 || 0.3427610695362091\n",
      "====> Epoch: 2050 || 0.3270876407623291\n",
      "====> Epoch: 2060 || 0.3443378210067749\n",
      "====> Epoch: 2070 || 0.38217803835868835\n",
      "====> Epoch: 2080 || 0.36550983786582947\n",
      "====> Epoch: 2090 || 0.3071550726890564\n",
      "====> Epoch: 2100 || 0.38266149163246155\n",
      "====> Epoch: 2110 || 0.3762444257736206\n",
      "====> Epoch: 2120 || 0.3554864525794983\n",
      "====> Epoch: 2130 || 0.3472573161125183\n",
      "====> Epoch: 2140 || 0.33376508951187134\n",
      "====> Epoch: 2150 || 0.33509597182273865\n",
      "====> Epoch: 2160 || 0.33773860335350037\n",
      "====> Epoch: 2170 || 0.3860931396484375\n",
      "====> Epoch: 2180 || 0.36646541953086853\n",
      "====> Epoch: 2190 || 0.32060670852661133\n",
      "====> Epoch: 2200 || 0.43432217836380005\n",
      "====> Epoch: 2210 || 0.34590858221054077\n",
      "====> Epoch: 2220 || 0.3789522647857666\n",
      "====> Epoch: 2230 || 0.3669205605983734\n",
      "====> Epoch: 2240 || 0.3190377950668335\n",
      "====> Epoch: 2250 || 0.3573911190032959\n",
      "====> Epoch: 2260 || 0.36169758439064026\n",
      "====> Epoch: 2270 || 0.335624635219574\n",
      "====> Epoch: 2280 || 0.28972339630126953\n",
      "====> Epoch: 2290 || 0.38043212890625\n",
      "====> Epoch: 2300 || 0.29354381561279297\n",
      "====> Epoch: 2310 || 0.36950913071632385\n",
      "====> Epoch: 2320 || 0.3543843626976013\n",
      "====> Epoch: 2330 || 0.3087352216243744\n",
      "====> Epoch: 2340 || 0.39545005559921265\n",
      "====> Epoch: 2350 || 0.33734363317489624\n",
      "====> Epoch: 2360 || 0.29072105884552\n",
      "====> Epoch: 2370 || 0.37259113788604736\n",
      "====> Epoch: 2380 || 0.36796241998672485\n",
      "====> Epoch: 2390 || 0.383181095123291\n",
      "====> Epoch: 2400 || 0.33041781187057495\n",
      "====> Epoch: 2410 || 0.39573177695274353\n",
      "====> Epoch: 2420 || 0.3464953303337097\n",
      "====> Epoch: 2430 || 0.34209468960762024\n",
      "====> Epoch: 2440 || 0.374249666929245\n",
      "====> Epoch: 2450 || 0.3162209391593933\n",
      "====> Epoch: 2460 || 0.34866756200790405\n",
      "====> Epoch: 2470 || 0.3134780526161194\n",
      "====> Epoch: 2480 || 0.36500969529151917\n",
      "====> Epoch: 2490 || 0.362140953540802\n",
      "====> Epoch: 2500 || 0.36402690410614014\n",
      "====> Epoch: 2510 || 0.35980460047721863\n",
      "====> Epoch: 2520 || 0.3294808864593506\n",
      "====> Epoch: 2530 || 0.3226037919521332\n",
      "====> Epoch: 2540 || 0.38715675473213196\n",
      "====> Epoch: 2550 || 0.3137306272983551\n",
      "====> Epoch: 2560 || 0.33355310559272766\n",
      "====> Epoch: 2570 || 0.32852038741111755\n",
      "====> Epoch: 2580 || 0.37656134366989136\n",
      "====> Epoch: 2590 || 0.334098219871521\n",
      "====> Epoch: 2600 || 0.34431079030036926\n",
      "====> Epoch: 2610 || 0.35786616802215576\n",
      "====> Epoch: 2620 || 0.3793456554412842\n",
      "====> Epoch: 2630 || 0.30889567732810974\n",
      "====> Epoch: 2640 || 0.34063732624053955\n",
      "====> Epoch: 2650 || 0.33821094036102295\n",
      "====> Epoch: 2660 || 0.38261646032333374\n",
      "====> Epoch: 2670 || 0.39421629905700684\n",
      "====> Epoch: 2680 || 0.36665818095207214\n",
      "====> Epoch: 2690 || 0.3559000492095947\n",
      "====> Epoch: 2700 || 0.35478606820106506\n",
      "====> Epoch: 2710 || 0.32563525438308716\n",
      "====> Epoch: 2720 || 0.35292890667915344\n",
      "====> Epoch: 2730 || 0.33588624000549316\n",
      "====> Epoch: 2740 || 0.3686729669570923\n",
      "====> Epoch: 2750 || 0.3441910445690155\n",
      "====> Epoch: 2760 || 0.41103655099868774\n",
      "====> Epoch: 2770 || 0.3130170702934265\n",
      "====> Epoch: 2780 || 0.35955551266670227\n",
      "====> Epoch: 2790 || 0.3202976882457733\n",
      "====> Epoch: 2800 || 0.3759017884731293\n",
      "====> Epoch: 2810 || 0.34082093834877014\n",
      "====> Epoch: 2820 || 0.3875289261341095\n",
      "====> Epoch: 2830 || 0.3679729402065277\n",
      "====> Epoch: 2840 || 0.363267183303833\n",
      "====> Epoch: 2850 || 0.372546523809433\n",
      "====> Epoch: 2860 || 0.3365863263607025\n",
      "====> Epoch: 2870 || 0.35897618532180786\n",
      "====> Epoch: 2880 || 0.38549354672431946\n",
      "====> Epoch: 2890 || 0.3695463538169861\n",
      "====> Epoch: 2900 || 0.3698616921901703\n",
      "====> Epoch: 2910 || 0.35676875710487366\n",
      "====> Epoch: 2920 || 0.3761577904224396\n",
      "====> Epoch: 2930 || 0.34544914960861206\n",
      "====> Epoch: 2940 || 0.340067058801651\n",
      "====> Epoch: 2950 || 0.3357774019241333\n",
      "====> Epoch: 2960 || 0.34959861636161804\n",
      "====> Epoch: 2970 || 0.39512237906455994\n",
      "====> Epoch: 2980 || 0.4214789569377899\n",
      "====> Epoch: 2990 || 0.3580658435821533\n",
      "====> Epoch: 2999 || 0.38966190814971924\n",
      "[2023-10-13 12:24:30] Evaluate_01: epoch = 1000 train time = 99 s train loss = 0.003031 train acc = 1.0000, test acc = 0.4674\n"
     ]
    }
   ],
   "source": [
    "model = CVAE(d = hidden, k=k, num_channels=num_channels).to(device) \n",
    "\n",
    "# 训练原图训\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 10 if args_cave.dataset == 'imagenet' else 30, 0.5,)\n",
    "\n",
    "epochs = 3000\n",
    "for epoch in range(epochs):\n",
    "\n",
    "\n",
    "    random_indices = np.random.choice(len(img_real_train), batch, replace=False)\n",
    "\n",
    "# 使用随机选择的索引来获取数据并改变形状\n",
    "    batch_img = img_real_train[random_indices].reshape((batch, 3, 32, 32)).to(device)\n",
    "    # batch_syn = img_syn[random_indices].reshape((batch, 3, 32, 32)).to(device) \n",
    "    # batch_img_y = label_real_train[c*batch:(c+1)*batch].to(device) \n",
    "        \n",
    "    outputs = model(batch_img)\n",
    "    \n",
    "    loss = model.loss_function(batch_img, *outputs)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "        # logs['loss'].append(loss.item())\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == epochs -1:\n",
    "        # print(\"Epoch {:02d}/{:02d} , Loss {:9.4f}\".format(\n",
    "        #     epoch, epochs,  loss.item()))\n",
    "        print(\"====> Epoch: {} || {}\".format(epoch, loss.item()))\n",
    "        \n",
    "with torch.no_grad():\n",
    "  output = model(img_real_test.to(device))\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[0]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 || 2.1260056495666504\n",
      "====> Epoch: 10 || 0.9068130254745483\n",
      "====> Epoch: 20 || 0.7513774633407593\n",
      "====> Epoch: 30 || 0.654479444026947\n",
      "====> Epoch: 40 || 0.6479647159576416\n",
      "====> Epoch: 50 || 0.5228400826454163\n",
      "====> Epoch: 60 || 0.5611713528633118\n",
      "====> Epoch: 70 || 0.5120115280151367\n",
      "====> Epoch: 80 || 0.4823131859302521\n",
      "====> Epoch: 90 || 0.4623338282108307\n",
      "====> Epoch: 100 || 0.46980592608451843\n",
      "====> Epoch: 110 || 0.48641499876976013\n",
      "====> Epoch: 120 || 0.43779847025871277\n",
      "====> Epoch: 130 || 0.4403831958770752\n",
      "====> Epoch: 140 || 0.5010635256767273\n",
      "====> Epoch: 150 || 0.4756315052509308\n",
      "====> Epoch: 160 || 0.4695318341255188\n",
      "====> Epoch: 170 || 0.48724839091300964\n",
      "====> Epoch: 180 || 0.4087326228618622\n",
      "====> Epoch: 190 || 0.43832674622535706\n",
      "====> Epoch: 200 || 0.4824279248714447\n",
      "====> Epoch: 210 || 0.501254677772522\n",
      "====> Epoch: 220 || 0.45777255296707153\n",
      "====> Epoch: 230 || 0.4298408031463623\n",
      "====> Epoch: 240 || 0.4415327310562134\n",
      "====> Epoch: 250 || 0.44378557801246643\n",
      "====> Epoch: 260 || 0.46279019117355347\n",
      "====> Epoch: 270 || 0.4103151857852936\n",
      "====> Epoch: 280 || 0.4147467613220215\n",
      "====> Epoch: 290 || 0.45073750615119934\n",
      "====> Epoch: 300 || 0.43871912360191345\n",
      "====> Epoch: 310 || 0.47395437955856323\n",
      "====> Epoch: 320 || 0.4614991247653961\n",
      "====> Epoch: 330 || 0.4893261194229126\n",
      "====> Epoch: 340 || 0.432923823595047\n",
      "====> Epoch: 350 || 0.39433276653289795\n",
      "====> Epoch: 360 || 0.4240099787712097\n",
      "====> Epoch: 370 || 0.42187151312828064\n",
      "====> Epoch: 380 || 0.4197583794593811\n",
      "====> Epoch: 390 || 0.45853906869888306\n",
      "====> Epoch: 400 || 0.41170233488082886\n",
      "====> Epoch: 410 || 0.4064832627773285\n",
      "====> Epoch: 420 || 0.5042489767074585\n",
      "====> Epoch: 430 || 0.4039269983768463\n",
      "====> Epoch: 440 || 0.43424394726753235\n",
      "====> Epoch: 450 || 0.42525243759155273\n",
      "====> Epoch: 460 || 0.4390232563018799\n",
      "====> Epoch: 470 || 0.4186933636665344\n",
      "====> Epoch: 480 || 0.413893461227417\n",
      "====> Epoch: 490 || 0.435465544462204\n",
      "====> Epoch: 500 || 0.43260204792022705\n",
      "====> Epoch: 510 || 0.378528892993927\n",
      "====> Epoch: 520 || 0.4453182816505432\n",
      "====> Epoch: 530 || 0.4070614278316498\n",
      "====> Epoch: 540 || 0.42179667949676514\n",
      "====> Epoch: 550 || 0.4086545407772064\n",
      "====> Epoch: 560 || 0.4317629635334015\n",
      "====> Epoch: 570 || 0.4320879876613617\n",
      "====> Epoch: 580 || 0.4493871033191681\n",
      "====> Epoch: 590 || 0.4723356068134308\n",
      "====> Epoch: 600 || 0.4209426939487457\n",
      "====> Epoch: 610 || 0.4310990273952484\n",
      "====> Epoch: 620 || 0.4099620580673218\n",
      "====> Epoch: 630 || 0.42398664355278015\n",
      "====> Epoch: 640 || 0.42104360461235046\n",
      "====> Epoch: 650 || 0.3911319077014923\n",
      "====> Epoch: 660 || 0.3952220678329468\n",
      "====> Epoch: 670 || 0.41627684235572815\n",
      "====> Epoch: 680 || 0.41095370054244995\n",
      "====> Epoch: 690 || 0.4025314450263977\n",
      "====> Epoch: 700 || 0.4085146486759186\n",
      "====> Epoch: 710 || 0.40017586946487427\n",
      "====> Epoch: 720 || 0.4397740662097931\n",
      "====> Epoch: 730 || 0.42464524507522583\n",
      "====> Epoch: 740 || 0.37772539258003235\n",
      "====> Epoch: 750 || 0.37568217515945435\n",
      "====> Epoch: 760 || 0.4275723993778229\n",
      "====> Epoch: 770 || 0.43687903881073\n",
      "====> Epoch: 780 || 0.3848446011543274\n",
      "====> Epoch: 790 || 0.39112740755081177\n",
      "====> Epoch: 800 || 0.40098583698272705\n",
      "====> Epoch: 810 || 0.3959307372570038\n",
      "====> Epoch: 820 || 0.38611721992492676\n",
      "====> Epoch: 830 || 0.3795061707496643\n",
      "====> Epoch: 840 || 0.3938397467136383\n",
      "====> Epoch: 850 || 0.3700105845928192\n",
      "====> Epoch: 860 || 0.35987335443496704\n",
      "====> Epoch: 870 || 0.4101894497871399\n",
      "====> Epoch: 880 || 0.400490403175354\n",
      "====> Epoch: 890 || 0.38615813851356506\n",
      "====> Epoch: 900 || 0.4249049425125122\n",
      "====> Epoch: 910 || 0.39616671204566956\n",
      "====> Epoch: 920 || 0.4154249131679535\n",
      "====> Epoch: 930 || 0.4293101727962494\n",
      "====> Epoch: 940 || 0.43043050169944763\n",
      "====> Epoch: 950 || 0.3561266362667084\n",
      "====> Epoch: 960 || 0.4007066786289215\n",
      "====> Epoch: 970 || 0.3903760015964508\n",
      "====> Epoch: 980 || 0.47159385681152344\n",
      "====> Epoch: 990 || 0.4374631941318512\n",
      "====> Epoch: 1000 || 0.35064181685447693\n",
      "====> Epoch: 1010 || 0.3936630189418793\n",
      "====> Epoch: 1020 || 0.369045227766037\n",
      "====> Epoch: 1030 || 0.4014553129673004\n",
      "====> Epoch: 1040 || 0.39116552472114563\n",
      "====> Epoch: 1050 || 0.34844323992729187\n",
      "====> Epoch: 1060 || 0.3569331169128418\n",
      "====> Epoch: 1070 || 0.445016086101532\n",
      "====> Epoch: 1080 || 0.4033057689666748\n",
      "====> Epoch: 1090 || 0.4390020966529846\n",
      "====> Epoch: 1100 || 0.4321341812610626\n",
      "====> Epoch: 1110 || 0.4017672538757324\n",
      "====> Epoch: 1120 || 0.38801679015159607\n",
      "====> Epoch: 1130 || 0.3998894691467285\n",
      "====> Epoch: 1140 || 0.40153226256370544\n",
      "====> Epoch: 1150 || 0.39570894837379456\n",
      "====> Epoch: 1160 || 0.40569931268692017\n",
      "====> Epoch: 1170 || 0.41938072443008423\n",
      "====> Epoch: 1180 || 0.40376463532447815\n",
      "====> Epoch: 1190 || 0.41434717178344727\n",
      "====> Epoch: 1200 || 0.38207924365997314\n",
      "====> Epoch: 1210 || 0.3716009259223938\n",
      "====> Epoch: 1220 || 0.3799612820148468\n",
      "====> Epoch: 1230 || 0.4208860397338867\n",
      "====> Epoch: 1240 || 0.41047027707099915\n",
      "====> Epoch: 1250 || 0.3425822854042053\n",
      "====> Epoch: 1260 || 0.42608872056007385\n",
      "====> Epoch: 1270 || 0.4455982446670532\n",
      "====> Epoch: 1280 || 0.3898018002510071\n",
      "====> Epoch: 1290 || 0.38565942645072937\n",
      "====> Epoch: 1300 || 0.39830347895622253\n",
      "====> Epoch: 1310 || 0.4215228259563446\n",
      "====> Epoch: 1320 || 0.3945479393005371\n",
      "====> Epoch: 1330 || 0.3758796453475952\n",
      "====> Epoch: 1340 || 0.39689013361930847\n",
      "====> Epoch: 1350 || 0.41781502962112427\n",
      "====> Epoch: 1360 || 0.43149611353874207\n",
      "====> Epoch: 1370 || 0.38440239429473877\n",
      "====> Epoch: 1380 || 0.3948967456817627\n",
      "====> Epoch: 1390 || 0.38838452100753784\n",
      "====> Epoch: 1400 || 0.3914237320423126\n",
      "====> Epoch: 1410 || 0.4115895628929138\n",
      "====> Epoch: 1420 || 0.38869330286979675\n",
      "====> Epoch: 1430 || 0.403402179479599\n",
      "====> Epoch: 1440 || 0.4019949734210968\n",
      "====> Epoch: 1450 || 0.36131444573402405\n",
      "====> Epoch: 1460 || 0.3807828724384308\n",
      "====> Epoch: 1470 || 0.4026210308074951\n",
      "====> Epoch: 1480 || 0.448135644197464\n",
      "====> Epoch: 1490 || 0.3905155658721924\n",
      "====> Epoch: 1500 || 0.38965317606925964\n",
      "====> Epoch: 1510 || 0.3574792742729187\n",
      "====> Epoch: 1520 || 0.411354660987854\n",
      "====> Epoch: 1530 || 0.41379332542419434\n",
      "====> Epoch: 1540 || 0.36460092663764954\n",
      "====> Epoch: 1550 || 0.40302106738090515\n",
      "====> Epoch: 1560 || 0.35036614537239075\n",
      "====> Epoch: 1570 || 0.34345364570617676\n",
      "====> Epoch: 1580 || 0.385589063167572\n",
      "====> Epoch: 1590 || 0.40540459752082825\n",
      "====> Epoch: 1600 || 0.37974658608436584\n",
      "====> Epoch: 1610 || 0.3493335545063019\n",
      "====> Epoch: 1620 || 0.385248601436615\n",
      "====> Epoch: 1630 || 0.39837825298309326\n",
      "====> Epoch: 1640 || 0.37515437602996826\n",
      "====> Epoch: 1650 || 0.4049268662929535\n",
      "====> Epoch: 1660 || 0.3818957209587097\n",
      "====> Epoch: 1670 || 0.3985283076763153\n",
      "====> Epoch: 1680 || 0.3805446922779083\n",
      "====> Epoch: 1690 || 0.3752220571041107\n",
      "====> Epoch: 1700 || 0.3746729791164398\n",
      "====> Epoch: 1710 || 0.3875391483306885\n",
      "====> Epoch: 1720 || 0.3633574843406677\n",
      "====> Epoch: 1730 || 0.4055442214012146\n",
      "====> Epoch: 1740 || 0.3814384937286377\n",
      "====> Epoch: 1750 || 0.3507004976272583\n",
      "====> Epoch: 1760 || 0.382894366979599\n",
      "====> Epoch: 1770 || 0.38407573103904724\n",
      "====> Epoch: 1780 || 0.40098726749420166\n",
      "====> Epoch: 1790 || 0.4007974863052368\n",
      "====> Epoch: 1800 || 0.3675247132778168\n",
      "====> Epoch: 1810 || 0.3392258286476135\n",
      "====> Epoch: 1820 || 0.3999652862548828\n",
      "====> Epoch: 1830 || 0.39066141843795776\n",
      "====> Epoch: 1840 || 0.3460566997528076\n",
      "====> Epoch: 1850 || 0.39800673723220825\n",
      "====> Epoch: 1860 || 0.44807669520378113\n",
      "====> Epoch: 1870 || 0.368292897939682\n",
      "====> Epoch: 1880 || 0.36170873045921326\n",
      "====> Epoch: 1890 || 0.36921676993370056\n",
      "====> Epoch: 1900 || 0.4190315306186676\n",
      "====> Epoch: 1910 || 0.4038335680961609\n",
      "====> Epoch: 1920 || 0.3663819134235382\n",
      "====> Epoch: 1930 || 0.33905622363090515\n",
      "====> Epoch: 1940 || 0.3688351511955261\n",
      "====> Epoch: 1950 || 0.3711806535720825\n",
      "====> Epoch: 1960 || 0.34360113739967346\n",
      "====> Epoch: 1970 || 0.3961275517940521\n",
      "====> Epoch: 1980 || 0.3919677138328552\n",
      "====> Epoch: 1990 || 0.3367958664894104\n",
      "====> Epoch: 2000 || 0.382802277803421\n",
      "====> Epoch: 2010 || 0.3887074589729309\n",
      "====> Epoch: 2020 || 0.4170847535133362\n",
      "====> Epoch: 2030 || 0.3583552837371826\n",
      "====> Epoch: 2040 || 0.37319445610046387\n",
      "====> Epoch: 2050 || 0.3624495565891266\n",
      "====> Epoch: 2060 || 0.3495556712150574\n",
      "====> Epoch: 2070 || 0.41867759823799133\n",
      "====> Epoch: 2080 || 0.3301540017127991\n",
      "====> Epoch: 2090 || 0.3887673318386078\n",
      "====> Epoch: 2100 || 0.37488773465156555\n",
      "====> Epoch: 2110 || 0.34012654423713684\n",
      "====> Epoch: 2120 || 0.3632192611694336\n",
      "====> Epoch: 2130 || 0.36903446912765503\n",
      "====> Epoch: 2140 || 0.3741488456726074\n",
      "====> Epoch: 2150 || 0.37869739532470703\n",
      "====> Epoch: 2160 || 0.3269374668598175\n",
      "====> Epoch: 2170 || 0.4040983021259308\n",
      "====> Epoch: 2180 || 0.33740943670272827\n",
      "====> Epoch: 2190 || 0.34437060356140137\n",
      "====> Epoch: 2200 || 0.3738706707954407\n",
      "====> Epoch: 2210 || 0.39517146348953247\n",
      "====> Epoch: 2220 || 0.37029752135276794\n",
      "====> Epoch: 2230 || 0.3289714455604553\n",
      "====> Epoch: 2240 || 0.3439736068248749\n",
      "====> Epoch: 2250 || 0.37693551182746887\n",
      "====> Epoch: 2260 || 0.35377246141433716\n",
      "====> Epoch: 2270 || 0.39908474683761597\n",
      "====> Epoch: 2280 || 0.3776076138019562\n",
      "====> Epoch: 2290 || 0.40045180916786194\n",
      "====> Epoch: 2300 || 0.31898191571235657\n",
      "====> Epoch: 2310 || 0.36744803190231323\n",
      "====> Epoch: 2320 || 0.35057470202445984\n",
      "====> Epoch: 2330 || 0.39491090178489685\n",
      "====> Epoch: 2340 || 0.38875696063041687\n",
      "====> Epoch: 2350 || 0.34354615211486816\n",
      "====> Epoch: 2360 || 0.37845680117607117\n",
      "====> Epoch: 2370 || 0.3979869782924652\n",
      "====> Epoch: 2380 || 0.38823193311691284\n",
      "====> Epoch: 2390 || 0.3868127763271332\n",
      "====> Epoch: 2400 || 0.34691017866134644\n",
      "====> Epoch: 2410 || 0.38371241092681885\n",
      "====> Epoch: 2420 || 0.3741387128829956\n",
      "====> Epoch: 2430 || 0.3385135233402252\n",
      "====> Epoch: 2440 || 0.3364173173904419\n",
      "====> Epoch: 2450 || 0.3489692211151123\n",
      "====> Epoch: 2460 || 0.37326517701148987\n",
      "====> Epoch: 2470 || 0.36031460762023926\n",
      "====> Epoch: 2480 || 0.34196460247039795\n",
      "====> Epoch: 2490 || 0.3578324615955353\n",
      "====> Epoch: 2500 || 0.37614092230796814\n",
      "====> Epoch: 2510 || 0.3537522554397583\n",
      "====> Epoch: 2520 || 0.36918312311172485\n",
      "====> Epoch: 2530 || 0.37478718161582947\n",
      "====> Epoch: 2540 || 0.36055058240890503\n",
      "====> Epoch: 2550 || 0.36781856417655945\n",
      "====> Epoch: 2560 || 0.39674457907676697\n",
      "====> Epoch: 2570 || 0.38404783606529236\n",
      "====> Epoch: 2580 || 0.36510083079338074\n",
      "====> Epoch: 2590 || 0.403233140707016\n",
      "====> Epoch: 2600 || 0.41267332434654236\n",
      "====> Epoch: 2610 || 0.3575974702835083\n",
      "====> Epoch: 2620 || 0.421335369348526\n",
      "====> Epoch: 2630 || 0.35363641381263733\n",
      "====> Epoch: 2640 || 0.3796348571777344\n",
      "====> Epoch: 2650 || 0.4064200520515442\n",
      "====> Epoch: 2660 || 0.413274347782135\n",
      "====> Epoch: 2670 || 0.3883863687515259\n",
      "====> Epoch: 2680 || 0.3757815659046173\n",
      "====> Epoch: 2690 || 0.3639775812625885\n",
      "====> Epoch: 2700 || 0.3738839626312256\n",
      "====> Epoch: 2710 || 0.34871184825897217\n",
      "====> Epoch: 2720 || 0.40474817156791687\n",
      "====> Epoch: 2730 || 0.36920884251594543\n",
      "====> Epoch: 2740 || 0.40165743231773376\n",
      "====> Epoch: 2750 || 0.34015992283821106\n",
      "====> Epoch: 2760 || 0.3969731628894806\n",
      "====> Epoch: 2770 || 0.3274015486240387\n",
      "====> Epoch: 2780 || 0.42326620221138\n",
      "====> Epoch: 2790 || 0.4036431610584259\n",
      "====> Epoch: 2800 || 0.3479180335998535\n",
      "====> Epoch: 2810 || 0.37033864855766296\n",
      "====> Epoch: 2820 || 0.39179179072380066\n",
      "====> Epoch: 2830 || 0.38023120164871216\n",
      "====> Epoch: 2840 || 0.3426089882850647\n",
      "====> Epoch: 2850 || 0.3526190519332886\n",
      "====> Epoch: 2860 || 0.37448644638061523\n",
      "====> Epoch: 2870 || 0.32963186502456665\n",
      "====> Epoch: 2880 || 0.3795222342014313\n",
      "====> Epoch: 2890 || 0.3722037076950073\n",
      "====> Epoch: 2900 || 0.33637434244155884\n",
      "====> Epoch: 2910 || 0.359954833984375\n",
      "====> Epoch: 2920 || 0.3573295772075653\n",
      "====> Epoch: 2930 || 0.33018672466278076\n",
      "====> Epoch: 2940 || 0.38171711564064026\n",
      "====> Epoch: 2950 || 0.341665118932724\n",
      "====> Epoch: 2960 || 0.40448683500289917\n",
      "====> Epoch: 2970 || 0.3398982882499695\n",
      "====> Epoch: 2980 || 0.3834817707538605\n",
      "====> Epoch: 2990 || 0.3210636377334595\n",
      "====> Epoch: 2999 || 0.38234442472457886\n",
      "[2023-10-13 12:31:16] Evaluate_01: epoch = 1000 train time = 98 s train loss = 0.002122 train acc = 1.0000, test acc = 0.4864\n"
     ]
    }
   ],
   "source": [
    "model = CVAE(d = hidden, k=k, num_channels=num_channels).to(device) \n",
    "\n",
    "# 样本对训\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 10 if args_cave.dataset == 'imagenet' else 30, 0.5,)\n",
    "\n",
    "epochs = 3000\n",
    "for epoch in range(epochs):\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    random_indices = np.random.choice(len(img_real_train), batch, replace=False)\n",
    "\n",
    "# 使用随机选择的索引来获取数据并改变形状\n",
    "    batch_img = img_real_train[random_indices].reshape((batch, 3, 32, 32)).to(device)\n",
    "    batch_syn = img_syn[random_indices].reshape((batch, 3, 32, 32)).to(device) \n",
    "    # batch_img_y = label_real_train[c*batch:(c+1)*batch].to(device) \n",
    "    \n",
    "    outputs = model(batch_img)\n",
    "    \n",
    "    loss = model.loss_function(batch_syn, *outputs)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "        # logs['loss'].append(loss.item())\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == epochs -1:\n",
    "        # print(\"Epoch {:02d}/{:02d} , Loss {:9.4f}\".format(\n",
    "        #     epoch, epochs,  loss.item()))\n",
    "        print(\"====> Epoch: {} || {}\".format(epoch, loss.item()))\n",
    "        \n",
    "with torch.no_grad():\n",
    "  output = model(img_real_test.to(device))\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[0]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 || 0.3686927855014801\n",
      "====> Epoch: 10 || 0.35229557752609253\n",
      "====> Epoch: 20 || 0.34480956196784973\n",
      "====> Epoch: 30 || 0.35006120800971985\n",
      "====> Epoch: 40 || 0.33064135909080505\n",
      "====> Epoch: 50 || 0.38443687558174133\n",
      "====> Epoch: 60 || 0.3595213294029236\n",
      "====> Epoch: 70 || 0.358097106218338\n",
      "====> Epoch: 80 || 0.3442186713218689\n",
      "====> Epoch: 90 || 0.35591447353363037\n",
      "====> Epoch: 100 || 0.3467026948928833\n",
      "====> Epoch: 110 || 0.3557693064212799\n",
      "====> Epoch: 120 || 0.38845348358154297\n",
      "====> Epoch: 130 || 0.3123314678668976\n",
      "====> Epoch: 140 || 0.39908307790756226\n",
      "====> Epoch: 150 || 0.3790074586868286\n",
      "====> Epoch: 160 || 0.3567098081111908\n",
      "====> Epoch: 170 || 0.3105849325656891\n",
      "====> Epoch: 180 || 0.36520111560821533\n",
      "====> Epoch: 190 || 0.34754905104637146\n",
      "====> Epoch: 200 || 0.3739040493965149\n",
      "====> Epoch: 210 || 0.2975155711174011\n",
      "====> Epoch: 220 || 0.36401471495628357\n",
      "====> Epoch: 230 || 0.3675159513950348\n",
      "====> Epoch: 240 || 0.37651392817497253\n",
      "====> Epoch: 250 || 0.37574899196624756\n",
      "====> Epoch: 260 || 0.3445890545845032\n",
      "====> Epoch: 270 || 0.36556845903396606\n",
      "====> Epoch: 280 || 0.35663360357284546\n",
      "====> Epoch: 290 || 0.37725940346717834\n",
      "====> Epoch: 300 || 0.3470118045806885\n",
      "====> Epoch: 310 || 0.37931814789772034\n",
      "====> Epoch: 320 || 0.38599735498428345\n",
      "====> Epoch: 330 || 0.34171515703201294\n",
      "====> Epoch: 340 || 0.35389336943626404\n",
      "====> Epoch: 350 || 0.3784705400466919\n",
      "====> Epoch: 360 || 0.3090338706970215\n",
      "====> Epoch: 370 || 0.3558719754219055\n",
      "====> Epoch: 380 || 0.3915536105632782\n",
      "====> Epoch: 390 || 0.3585664927959442\n",
      "====> Epoch: 400 || 0.3534736931324005\n",
      "====> Epoch: 410 || 0.38294345140457153\n",
      "====> Epoch: 420 || 0.3414895832538605\n",
      "====> Epoch: 430 || 0.332977294921875\n",
      "====> Epoch: 440 || 0.3417961001396179\n",
      "====> Epoch: 450 || 0.3607923686504364\n",
      "====> Epoch: 460 || 0.3418434262275696\n",
      "====> Epoch: 470 || 0.3546123504638672\n",
      "====> Epoch: 480 || 0.33632123470306396\n",
      "====> Epoch: 490 || 0.32424619793891907\n",
      "====> Epoch: 500 || 0.3288540542125702\n",
      "====> Epoch: 510 || 0.36986514925956726\n",
      "====> Epoch: 520 || 0.3783823251724243\n",
      "====> Epoch: 530 || 0.33384671807289124\n",
      "====> Epoch: 540 || 0.34229516983032227\n",
      "====> Epoch: 550 || 0.36087766289711\n",
      "====> Epoch: 560 || 0.4301575720310211\n",
      "====> Epoch: 570 || 0.39383378624916077\n",
      "====> Epoch: 580 || 0.3425997197628021\n",
      "====> Epoch: 590 || 0.409604012966156\n",
      "====> Epoch: 600 || 0.3650341331958771\n",
      "====> Epoch: 610 || 0.4142765700817108\n",
      "====> Epoch: 620 || 0.342227041721344\n",
      "====> Epoch: 630 || 0.3471675217151642\n",
      "====> Epoch: 640 || 0.35688185691833496\n",
      "====> Epoch: 650 || 0.3883516788482666\n",
      "====> Epoch: 660 || 0.37124699354171753\n",
      "====> Epoch: 670 || 0.33334141969680786\n",
      "====> Epoch: 680 || 0.3554912805557251\n",
      "====> Epoch: 690 || 0.33412426710128784\n",
      "====> Epoch: 700 || 0.3245285749435425\n",
      "====> Epoch: 710 || 0.3513224422931671\n",
      "====> Epoch: 720 || 0.3461920917034149\n",
      "====> Epoch: 730 || 0.38238224387168884\n",
      "====> Epoch: 740 || 0.37473586201667786\n",
      "====> Epoch: 750 || 0.35597413778305054\n",
      "====> Epoch: 760 || 0.3624332845211029\n",
      "====> Epoch: 770 || 0.3391607403755188\n",
      "====> Epoch: 780 || 0.3787349462509155\n",
      "====> Epoch: 790 || 0.3416042625904083\n",
      "====> Epoch: 800 || 0.37750697135925293\n",
      "====> Epoch: 810 || 0.3516829311847687\n",
      "====> Epoch: 820 || 0.3424380123615265\n",
      "====> Epoch: 830 || 0.4051302671432495\n",
      "====> Epoch: 840 || 0.2933253049850464\n",
      "====> Epoch: 850 || 0.32154643535614014\n",
      "====> Epoch: 860 || 0.349734902381897\n",
      "====> Epoch: 870 || 0.335891455411911\n",
      "====> Epoch: 880 || 0.3238484859466553\n",
      "====> Epoch: 890 || 0.38932907581329346\n",
      "====> Epoch: 900 || 0.3294740617275238\n",
      "====> Epoch: 910 || 0.3387618660926819\n",
      "====> Epoch: 920 || 0.35628631711006165\n",
      "====> Epoch: 930 || 0.34118807315826416\n",
      "====> Epoch: 940 || 0.377187579870224\n",
      "====> Epoch: 950 || 0.39431777596473694\n",
      "====> Epoch: 960 || 0.3462594449520111\n",
      "====> Epoch: 970 || 0.34762707352638245\n",
      "====> Epoch: 980 || 0.3948349058628082\n",
      "====> Epoch: 990 || 0.3414430618286133\n",
      "====> Epoch: 1000 || 0.33318763971328735\n",
      "====> Epoch: 1010 || 0.35268139839172363\n",
      "====> Epoch: 1020 || 0.3359794318675995\n",
      "====> Epoch: 1030 || 0.4047514498233795\n",
      "====> Epoch: 1040 || 0.3313911557197571\n",
      "====> Epoch: 1050 || 0.3445989489555359\n",
      "====> Epoch: 1060 || 0.3591946065425873\n",
      "====> Epoch: 1070 || 0.4004516899585724\n",
      "====> Epoch: 1080 || 0.37307894229888916\n",
      "====> Epoch: 1090 || 0.3548789620399475\n",
      "====> Epoch: 1100 || 0.34435033798217773\n",
      "====> Epoch: 1110 || 0.3478078246116638\n",
      "====> Epoch: 1120 || 0.3420611023902893\n",
      "====> Epoch: 1130 || 0.3505421578884125\n",
      "====> Epoch: 1140 || 0.3554438650608063\n",
      "====> Epoch: 1150 || 0.386982262134552\n",
      "====> Epoch: 1160 || 0.3831004202365875\n",
      "====> Epoch: 1170 || 0.35994434356689453\n",
      "====> Epoch: 1180 || 0.361980676651001\n",
      "====> Epoch: 1190 || 0.34455645084381104\n",
      "====> Epoch: 1200 || 0.33194953203201294\n",
      "====> Epoch: 1210 || 0.33963561058044434\n",
      "====> Epoch: 1220 || 0.38686543703079224\n",
      "====> Epoch: 1230 || 0.327567994594574\n",
      "====> Epoch: 1240 || 0.3709409236907959\n",
      "====> Epoch: 1250 || 0.36520519852638245\n",
      "====> Epoch: 1260 || 0.37608015537261963\n",
      "====> Epoch: 1270 || 0.35737496614456177\n",
      "====> Epoch: 1280 || 0.35082319378852844\n",
      "====> Epoch: 1290 || 0.3202611804008484\n",
      "====> Epoch: 1300 || 0.3356247544288635\n",
      "====> Epoch: 1310 || 0.3432213068008423\n",
      "====> Epoch: 1320 || 0.35225483775138855\n",
      "====> Epoch: 1330 || 0.3194267451763153\n",
      "====> Epoch: 1340 || 0.3731267750263214\n",
      "====> Epoch: 1350 || 0.3128281831741333\n",
      "====> Epoch: 1360 || 0.35366225242614746\n",
      "====> Epoch: 1370 || 0.37366214394569397\n",
      "====> Epoch: 1380 || 0.3380357623100281\n",
      "====> Epoch: 1390 || 0.33932358026504517\n",
      "====> Epoch: 1400 || 0.32256728410720825\n",
      "====> Epoch: 1410 || 0.3285004794597626\n",
      "====> Epoch: 1420 || 0.4078461229801178\n",
      "====> Epoch: 1430 || 0.32828477025032043\n",
      "====> Epoch: 1440 || 0.3524967432022095\n",
      "====> Epoch: 1450 || 0.33925101161003113\n",
      "====> Epoch: 1460 || 0.36131057143211365\n",
      "====> Epoch: 1470 || 0.3774298131465912\n",
      "====> Epoch: 1480 || 0.35862499475479126\n",
      "====> Epoch: 1490 || 0.34445273876190186\n",
      "====> Epoch: 1500 || 0.36850664019584656\n",
      "====> Epoch: 1510 || 0.3508322238922119\n",
      "====> Epoch: 1520 || 0.3521130383014679\n",
      "====> Epoch: 1530 || 0.3743276298046112\n",
      "====> Epoch: 1540 || 0.3601212501525879\n",
      "====> Epoch: 1550 || 0.35574206709861755\n",
      "====> Epoch: 1560 || 0.3769310414791107\n",
      "====> Epoch: 1570 || 0.3487822711467743\n",
      "====> Epoch: 1580 || 0.3526650071144104\n",
      "====> Epoch: 1590 || 0.34326574206352234\n",
      "====> Epoch: 1600 || 0.384151428937912\n",
      "====> Epoch: 1610 || 0.33065226674079895\n",
      "====> Epoch: 1620 || 0.33441999554634094\n",
      "====> Epoch: 1630 || 0.3649784028530121\n",
      "====> Epoch: 1640 || 0.37124213576316833\n",
      "====> Epoch: 1650 || 0.344558447599411\n",
      "====> Epoch: 1660 || 0.3124154210090637\n",
      "====> Epoch: 1670 || 0.39773422479629517\n",
      "====> Epoch: 1680 || 0.3778289258480072\n",
      "====> Epoch: 1690 || 0.3653344511985779\n",
      "====> Epoch: 1700 || 0.367951363325119\n",
      "====> Epoch: 1710 || 0.34350985288619995\n",
      "====> Epoch: 1720 || 0.32942119240760803\n",
      "====> Epoch: 1730 || 0.3446091115474701\n",
      "====> Epoch: 1740 || 0.3651667535305023\n",
      "====> Epoch: 1750 || 0.31757575273513794\n",
      "====> Epoch: 1760 || 0.3680546283721924\n",
      "====> Epoch: 1770 || 0.3296878933906555\n",
      "====> Epoch: 1780 || 0.34554165601730347\n",
      "====> Epoch: 1790 || 0.3562484085559845\n",
      "====> Epoch: 1800 || 0.36567068099975586\n",
      "====> Epoch: 1810 || 0.3589109480381012\n",
      "====> Epoch: 1820 || 0.33053576946258545\n",
      "====> Epoch: 1830 || 0.3460470139980316\n",
      "====> Epoch: 1840 || 0.31779345870018005\n",
      "====> Epoch: 1850 || 0.34556499123573303\n",
      "====> Epoch: 1860 || 0.40480929613113403\n",
      "====> Epoch: 1870 || 0.3804064095020294\n",
      "====> Epoch: 1880 || 0.3881962299346924\n",
      "====> Epoch: 1890 || 0.3407658040523529\n",
      "====> Epoch: 1900 || 0.3589436411857605\n",
      "====> Epoch: 1910 || 0.34607890248298645\n",
      "====> Epoch: 1920 || 0.3533020317554474\n",
      "====> Epoch: 1930 || 0.3878423571586609\n",
      "====> Epoch: 1940 || 0.3937748372554779\n",
      "====> Epoch: 1950 || 0.3293982744216919\n",
      "====> Epoch: 1960 || 0.3860006630420685\n",
      "====> Epoch: 1970 || 0.3373832404613495\n",
      "====> Epoch: 1980 || 0.36228930950164795\n",
      "====> Epoch: 1990 || 0.3335350751876831\n",
      "====> Epoch: 2000 || 0.28897374868392944\n",
      "====> Epoch: 2010 || 0.39771324396133423\n",
      "====> Epoch: 2020 || 0.35223817825317383\n",
      "====> Epoch: 2030 || 0.3578818440437317\n",
      "====> Epoch: 2040 || 0.3667612671852112\n",
      "====> Epoch: 2050 || 0.3887045979499817\n",
      "====> Epoch: 2060 || 0.3572421073913574\n",
      "====> Epoch: 2070 || 0.3826017379760742\n",
      "====> Epoch: 2080 || 0.32749617099761963\n",
      "====> Epoch: 2090 || 0.33298543095588684\n",
      "====> Epoch: 2100 || 0.30685076117515564\n",
      "====> Epoch: 2110 || 0.34886032342910767\n",
      "====> Epoch: 2120 || 0.39152398705482483\n",
      "====> Epoch: 2130 || 0.3375832438468933\n",
      "====> Epoch: 2140 || 0.3628900349140167\n",
      "====> Epoch: 2150 || 0.30536219477653503\n",
      "====> Epoch: 2160 || 0.358980655670166\n",
      "====> Epoch: 2170 || 0.34117746353149414\n",
      "====> Epoch: 2180 || 0.3406466245651245\n",
      "====> Epoch: 2190 || 0.36252298951148987\n",
      "====> Epoch: 2200 || 0.35580697655677795\n",
      "====> Epoch: 2210 || 0.33550480008125305\n",
      "====> Epoch: 2220 || 0.35387328267097473\n",
      "====> Epoch: 2230 || 0.34433338046073914\n",
      "====> Epoch: 2240 || 0.38274267315864563\n",
      "====> Epoch: 2250 || 0.3558320701122284\n",
      "====> Epoch: 2260 || 0.31752586364746094\n",
      "====> Epoch: 2270 || 0.37636828422546387\n",
      "====> Epoch: 2280 || 0.3856606185436249\n",
      "====> Epoch: 2290 || 0.3298947513103485\n",
      "====> Epoch: 2300 || 0.3736167848110199\n",
      "====> Epoch: 2310 || 0.313138872385025\n",
      "====> Epoch: 2320 || 0.36658862233161926\n",
      "====> Epoch: 2330 || 0.34086084365844727\n",
      "====> Epoch: 2340 || 0.3500558137893677\n",
      "====> Epoch: 2350 || 0.37228667736053467\n",
      "====> Epoch: 2360 || 0.3589993417263031\n",
      "====> Epoch: 2370 || 0.37552332878112793\n",
      "====> Epoch: 2380 || 0.3464033901691437\n",
      "====> Epoch: 2390 || 0.3713829219341278\n",
      "====> Epoch: 2400 || 0.35696038603782654\n",
      "====> Epoch: 2410 || 0.3920081853866577\n",
      "====> Epoch: 2420 || 0.33125412464141846\n",
      "====> Epoch: 2430 || 0.37046608328819275\n",
      "====> Epoch: 2440 || 0.32551154494285583\n",
      "====> Epoch: 2450 || 0.3628058135509491\n",
      "====> Epoch: 2460 || 0.40019896626472473\n",
      "====> Epoch: 2470 || 0.35568201541900635\n",
      "====> Epoch: 2480 || 0.3559074401855469\n",
      "====> Epoch: 2490 || 0.3414817154407501\n",
      "====> Epoch: 2500 || 0.36619433760643005\n",
      "====> Epoch: 2510 || 0.39448609948158264\n",
      "====> Epoch: 2520 || 0.3410169184207916\n",
      "====> Epoch: 2530 || 0.35315945744514465\n",
      "====> Epoch: 2540 || 0.3584578335285187\n",
      "====> Epoch: 2550 || 0.35809311270713806\n",
      "====> Epoch: 2560 || 0.340486615896225\n",
      "====> Epoch: 2570 || 0.35577642917633057\n",
      "====> Epoch: 2580 || 0.32467740774154663\n",
      "====> Epoch: 2590 || 0.34075281023979187\n",
      "====> Epoch: 2600 || 0.3330298662185669\n",
      "====> Epoch: 2610 || 0.3700818121433258\n",
      "====> Epoch: 2620 || 0.3570139408111572\n",
      "====> Epoch: 2630 || 0.37795642018318176\n",
      "====> Epoch: 2640 || 0.3956727087497711\n",
      "====> Epoch: 2650 || 0.34111765027046204\n",
      "====> Epoch: 2660 || 0.3596831262111664\n",
      "====> Epoch: 2670 || 0.32309627532958984\n",
      "====> Epoch: 2680 || 0.33127301931381226\n",
      "====> Epoch: 2690 || 0.3482620418071747\n",
      "====> Epoch: 2700 || 0.32796674966812134\n",
      "====> Epoch: 2710 || 0.29567664861679077\n",
      "====> Epoch: 2720 || 0.36035627126693726\n",
      "====> Epoch: 2730 || 0.3573988676071167\n",
      "====> Epoch: 2740 || 0.31725260615348816\n",
      "====> Epoch: 2750 || 0.30478131771087646\n",
      "====> Epoch: 2760 || 0.3330621123313904\n",
      "====> Epoch: 2770 || 0.3293302655220032\n",
      "====> Epoch: 2780 || 0.3219042420387268\n",
      "====> Epoch: 2790 || 0.32436835765838623\n",
      "====> Epoch: 2800 || 0.3430795967578888\n",
      "====> Epoch: 2810 || 0.3003196716308594\n",
      "====> Epoch: 2820 || 0.35155418515205383\n",
      "====> Epoch: 2830 || 0.3545152544975281\n",
      "====> Epoch: 2840 || 0.3339254856109619\n",
      "====> Epoch: 2850 || 0.36771437525749207\n",
      "====> Epoch: 2860 || 0.3303489685058594\n",
      "====> Epoch: 2870 || 0.3165357708930969\n",
      "====> Epoch: 2880 || 0.3882375955581665\n",
      "====> Epoch: 2890 || 0.3457523584365845\n",
      "====> Epoch: 2900 || 0.3499448001384735\n",
      "====> Epoch: 2910 || 0.37518712878227234\n",
      "====> Epoch: 2920 || 0.3758488595485687\n",
      "====> Epoch: 2930 || 0.39331746101379395\n",
      "====> Epoch: 2940 || 0.34547555446624756\n",
      "====> Epoch: 2950 || 0.3376656472682953\n",
      "====> Epoch: 2960 || 0.3668456971645355\n",
      "====> Epoch: 2970 || 0.3629315197467804\n",
      "====> Epoch: 2980 || 0.31775984168052673\n",
      "====> Epoch: 2990 || 0.36434534192085266\n",
      "====> Epoch: 2999 || 0.30386456847190857\n",
      "[2023-10-13 12:37:58] Evaluate_01: epoch = 1000 train time = 97 s train loss = 0.002471 train acc = 1.0000, test acc = 0.4641\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('cvae_all.pt').to(device)    \n",
    "# A + 合成数据集 \n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 10 if args_cave.dataset == 'imagenet' else 30, 0.5,)\n",
    "\n",
    "epochs = 3000\n",
    "for epoch in range(epochs):\n",
    "\n",
    "\n",
    "    # batch_img = images_all[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    \n",
    "    # batch_img = img_real_train[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    # batch_syn = img_syn[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    \n",
    "    # 随机选择batch个索引\n",
    "    random_indices = np.random.choice(len(img_real_train), batch, replace=False)\n",
    "\n",
    "    # 使用随机选择的索引来获取数据并改变形状\n",
    "    # batch_img = img_real_train[random_indices].reshape((batch, 3, 32, 32)).to(device)\n",
    "    batch_syn = img_syn[random_indices].reshape((batch, 3, 32, 32)).to(device) \n",
    "\n",
    "    # batch_img_y = label_real_train[c*batch:(c+1)*batch].to(device) \n",
    "    \n",
    "    outputs = model(batch_syn)\n",
    "    \n",
    "    loss = model.loss_function(batch_syn, *outputs)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # logs['loss'].append(loss.item())\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == epochs -1:\n",
    "        # print(\"Epoch {:02d}/{:02d} , Loss {:9.4f}\".format(\n",
    "        #     epoch, epochs,  loss.item()))\n",
    "        print(\"====> Epoch: {} || {}\".format(epoch, loss.item()))\n",
    "        \n",
    "with torch.no_grad():\n",
    "  output = model(img_real_test.to(device))\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[0]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 || 0.33656272292137146\n",
      "====> Epoch: 10 || 0.3376087248325348\n",
      "====> Epoch: 20 || 0.4088062047958374\n",
      "====> Epoch: 30 || 0.38783806562423706\n",
      "====> Epoch: 40 || 0.404959499835968\n",
      "====> Epoch: 50 || 0.34974777698516846\n",
      "====> Epoch: 60 || 0.3556029796600342\n",
      "====> Epoch: 70 || 0.3963489830493927\n",
      "====> Epoch: 80 || 0.37195566296577454\n",
      "====> Epoch: 90 || 0.3484606444835663\n",
      "====> Epoch: 100 || 0.3841311037540436\n",
      "====> Epoch: 110 || 0.3404640257358551\n",
      "====> Epoch: 120 || 0.37040287256240845\n",
      "====> Epoch: 130 || 0.357191264629364\n",
      "====> Epoch: 140 || 0.4120376706123352\n",
      "====> Epoch: 150 || 0.3762578070163727\n",
      "====> Epoch: 160 || 0.3890926241874695\n",
      "====> Epoch: 170 || 0.3978455662727356\n",
      "====> Epoch: 180 || 0.3715849220752716\n",
      "====> Epoch: 190 || 0.34011968970298767\n",
      "====> Epoch: 200 || 0.3609450161457062\n",
      "====> Epoch: 210 || 0.32383233308792114\n",
      "====> Epoch: 220 || 0.3416687250137329\n",
      "====> Epoch: 230 || 0.3344535827636719\n",
      "====> Epoch: 240 || 0.3355846405029297\n",
      "====> Epoch: 250 || 0.37278151512145996\n",
      "====> Epoch: 260 || 0.32919979095458984\n",
      "====> Epoch: 270 || 0.36564528942108154\n",
      "====> Epoch: 280 || 0.383992999792099\n",
      "====> Epoch: 290 || 0.36254724860191345\n",
      "====> Epoch: 300 || 0.3634125888347626\n",
      "====> Epoch: 310 || 0.34493526816368103\n",
      "====> Epoch: 320 || 0.36737680435180664\n",
      "====> Epoch: 330 || 0.36699849367141724\n",
      "====> Epoch: 340 || 0.34534522891044617\n",
      "====> Epoch: 350 || 0.3264571726322174\n",
      "====> Epoch: 360 || 0.3504721522331238\n",
      "====> Epoch: 370 || 0.3423669934272766\n",
      "====> Epoch: 380 || 0.3449660539627075\n",
      "====> Epoch: 390 || 0.3400569260120392\n",
      "====> Epoch: 400 || 0.37786489725112915\n",
      "====> Epoch: 410 || 0.35879069566726685\n",
      "====> Epoch: 420 || 0.4041031301021576\n",
      "====> Epoch: 430 || 0.3649322986602783\n",
      "====> Epoch: 440 || 0.34373846650123596\n",
      "====> Epoch: 450 || 0.35075390338897705\n",
      "====> Epoch: 460 || 0.3671601414680481\n",
      "====> Epoch: 470 || 0.3311840295791626\n",
      "====> Epoch: 480 || 0.3585696220397949\n",
      "====> Epoch: 490 || 0.3879171311855316\n",
      "====> Epoch: 500 || 0.3599604368209839\n",
      "====> Epoch: 510 || 0.2948399484157562\n",
      "====> Epoch: 520 || 0.38036662340164185\n",
      "====> Epoch: 530 || 0.3347201645374298\n",
      "====> Epoch: 540 || 0.4075225591659546\n",
      "====> Epoch: 550 || 0.3852449059486389\n",
      "====> Epoch: 560 || 0.3753107190132141\n",
      "====> Epoch: 570 || 0.37080705165863037\n",
      "====> Epoch: 580 || 0.3499000668525696\n",
      "====> Epoch: 590 || 0.3461003303527832\n",
      "====> Epoch: 600 || 0.35367926955223083\n",
      "====> Epoch: 610 || 0.3495398759841919\n",
      "====> Epoch: 620 || 0.32477301359176636\n",
      "====> Epoch: 630 || 0.4237130582332611\n",
      "====> Epoch: 640 || 0.33609336614608765\n",
      "====> Epoch: 650 || 0.3868202269077301\n",
      "====> Epoch: 660 || 0.35138827562332153\n",
      "====> Epoch: 670 || 0.3793991804122925\n",
      "====> Epoch: 680 || 0.41167372465133667\n",
      "====> Epoch: 690 || 0.41140201687812805\n",
      "====> Epoch: 700 || 0.3496647775173187\n",
      "====> Epoch: 710 || 0.36848199367523193\n",
      "====> Epoch: 720 || 0.37597885727882385\n",
      "====> Epoch: 730 || 0.35419541597366333\n",
      "====> Epoch: 740 || 0.3421343266963959\n",
      "====> Epoch: 750 || 0.37511569261550903\n",
      "====> Epoch: 760 || 0.38429543375968933\n",
      "====> Epoch: 770 || 0.3827829360961914\n",
      "====> Epoch: 780 || 0.32359904050827026\n",
      "====> Epoch: 790 || 0.357818067073822\n",
      "====> Epoch: 800 || 0.37521135807037354\n",
      "====> Epoch: 810 || 0.3572430908679962\n",
      "====> Epoch: 820 || 0.36555761098861694\n",
      "====> Epoch: 830 || 0.3227576017379761\n",
      "====> Epoch: 840 || 0.3529857397079468\n",
      "====> Epoch: 850 || 0.36320969462394714\n",
      "====> Epoch: 860 || 0.36752256751060486\n",
      "====> Epoch: 870 || 0.3569135069847107\n",
      "====> Epoch: 880 || 0.35450974106788635\n",
      "====> Epoch: 890 || 0.36193668842315674\n",
      "====> Epoch: 900 || 0.353262722492218\n",
      "====> Epoch: 910 || 0.3709891140460968\n",
      "====> Epoch: 920 || 0.35963505506515503\n",
      "====> Epoch: 930 || 0.3473154604434967\n",
      "====> Epoch: 940 || 0.33514922857284546\n",
      "====> Epoch: 950 || 0.37032008171081543\n",
      "====> Epoch: 960 || 0.3269076645374298\n",
      "====> Epoch: 970 || 0.35050684213638306\n",
      "====> Epoch: 980 || 0.3428754508495331\n",
      "====> Epoch: 990 || 0.3564278483390808\n",
      "====> Epoch: 1000 || 0.3664762079715729\n",
      "====> Epoch: 1010 || 0.361111581325531\n",
      "====> Epoch: 1020 || 0.36615222692489624\n",
      "====> Epoch: 1030 || 0.36073875427246094\n",
      "====> Epoch: 1040 || 0.3743506073951721\n",
      "====> Epoch: 1050 || 0.3289428949356079\n",
      "====> Epoch: 1060 || 0.36632040143013\n",
      "====> Epoch: 1070 || 0.36696454882621765\n",
      "====> Epoch: 1080 || 0.34404852986335754\n",
      "====> Epoch: 1090 || 0.31234726309776306\n",
      "====> Epoch: 1100 || 0.3393329679965973\n",
      "====> Epoch: 1110 || 0.3279000222682953\n",
      "====> Epoch: 1120 || 0.33166712522506714\n",
      "====> Epoch: 1130 || 0.3269907832145691\n",
      "====> Epoch: 1140 || 0.3510580062866211\n",
      "====> Epoch: 1150 || 0.34030717611312866\n",
      "====> Epoch: 1160 || 0.37945565581321716\n",
      "====> Epoch: 1170 || 0.3650723397731781\n",
      "====> Epoch: 1180 || 0.34179162979125977\n",
      "====> Epoch: 1190 || 0.3554854393005371\n",
      "====> Epoch: 1200 || 0.3582221269607544\n",
      "====> Epoch: 1210 || 0.36224886775016785\n",
      "====> Epoch: 1220 || 0.345910906791687\n",
      "====> Epoch: 1230 || 0.3903704583644867\n",
      "====> Epoch: 1240 || 0.41036486625671387\n",
      "====> Epoch: 1250 || 0.3383956253528595\n",
      "====> Epoch: 1260 || 0.33016741275787354\n",
      "====> Epoch: 1270 || 0.3405332863330841\n",
      "====> Epoch: 1280 || 0.37598586082458496\n",
      "====> Epoch: 1290 || 0.353039026260376\n",
      "====> Epoch: 1300 || 0.36032992601394653\n",
      "====> Epoch: 1310 || 0.34891805052757263\n",
      "====> Epoch: 1320 || 0.34584206342697144\n",
      "====> Epoch: 1330 || 0.3239718973636627\n",
      "====> Epoch: 1340 || 0.37444227933883667\n",
      "====> Epoch: 1350 || 0.3804872930049896\n",
      "====> Epoch: 1360 || 0.3571317791938782\n",
      "====> Epoch: 1370 || 0.3139905333518982\n",
      "====> Epoch: 1380 || 0.3473722040653229\n",
      "====> Epoch: 1390 || 0.4029925465583801\n",
      "====> Epoch: 1400 || 0.33692115545272827\n",
      "====> Epoch: 1410 || 0.35414671897888184\n",
      "====> Epoch: 1420 || 0.35553428530693054\n",
      "====> Epoch: 1430 || 0.39957645535469055\n",
      "====> Epoch: 1440 || 0.3251977562904358\n",
      "====> Epoch: 1450 || 0.3241780400276184\n",
      "====> Epoch: 1460 || 0.3469579219818115\n",
      "====> Epoch: 1470 || 0.3517693877220154\n",
      "====> Epoch: 1480 || 0.40187180042266846\n",
      "====> Epoch: 1490 || 0.36727914214134216\n",
      "====> Epoch: 1500 || 0.35553908348083496\n",
      "====> Epoch: 1510 || 0.34414684772491455\n",
      "====> Epoch: 1520 || 0.3269403874874115\n",
      "====> Epoch: 1530 || 0.3317040205001831\n",
      "====> Epoch: 1540 || 0.3696759343147278\n",
      "====> Epoch: 1550 || 0.36636337637901306\n",
      "====> Epoch: 1560 || 0.3166295886039734\n",
      "====> Epoch: 1570 || 0.36074990034103394\n",
      "====> Epoch: 1580 || 0.35169070959091187\n",
      "====> Epoch: 1590 || 0.3784022033214569\n",
      "====> Epoch: 1600 || 0.3737189471721649\n",
      "====> Epoch: 1610 || 0.38499584794044495\n",
      "====> Epoch: 1620 || 0.3184821903705597\n",
      "====> Epoch: 1630 || 0.39794307947158813\n",
      "====> Epoch: 1640 || 0.3525981605052948\n",
      "====> Epoch: 1650 || 0.3325274586677551\n",
      "====> Epoch: 1660 || 0.3565745949745178\n",
      "====> Epoch: 1670 || 0.3627280592918396\n",
      "====> Epoch: 1680 || 0.37965670228004456\n",
      "====> Epoch: 1690 || 0.3672330379486084\n",
      "====> Epoch: 1700 || 0.36482489109039307\n",
      "====> Epoch: 1710 || 0.34858593344688416\n",
      "====> Epoch: 1720 || 0.36961889266967773\n",
      "====> Epoch: 1730 || 0.37721553444862366\n",
      "====> Epoch: 1740 || 0.3359183073043823\n",
      "====> Epoch: 1750 || 0.3614404797554016\n",
      "====> Epoch: 1760 || 0.3367060720920563\n",
      "====> Epoch: 1770 || 0.323844850063324\n",
      "====> Epoch: 1780 || 0.35773321986198425\n",
      "====> Epoch: 1790 || 0.36333078145980835\n",
      "====> Epoch: 1800 || 0.35437843203544617\n",
      "====> Epoch: 1810 || 0.33242905139923096\n",
      "====> Epoch: 1820 || 0.3697476089000702\n",
      "====> Epoch: 1830 || 0.35099267959594727\n",
      "====> Epoch: 1840 || 0.3719952702522278\n",
      "====> Epoch: 1850 || 0.34815675020217896\n",
      "====> Epoch: 1860 || 0.34201905131340027\n",
      "====> Epoch: 1870 || 0.31130585074424744\n",
      "====> Epoch: 1880 || 0.37668344378471375\n",
      "====> Epoch: 1890 || 0.3322811424732208\n",
      "====> Epoch: 1900 || 0.3699452579021454\n",
      "====> Epoch: 1910 || 0.3326447308063507\n",
      "====> Epoch: 1920 || 0.3842088580131531\n",
      "====> Epoch: 1930 || 0.3184221684932709\n",
      "====> Epoch: 1940 || 0.34502479434013367\n",
      "====> Epoch: 1950 || 0.3705681264400482\n",
      "====> Epoch: 1960 || 0.3577183187007904\n",
      "====> Epoch: 1970 || 0.35741275548934937\n",
      "====> Epoch: 1980 || 0.3334610164165497\n",
      "====> Epoch: 1990 || 0.3923518657684326\n",
      "====> Epoch: 2000 || 0.3195009231567383\n",
      "====> Epoch: 2010 || 0.3291178047657013\n",
      "====> Epoch: 2020 || 0.3907961845397949\n",
      "====> Epoch: 2030 || 0.3855412006378174\n",
      "====> Epoch: 2040 || 0.3551696836948395\n",
      "====> Epoch: 2050 || 0.3759816884994507\n",
      "====> Epoch: 2060 || 0.3894076347351074\n",
      "====> Epoch: 2070 || 0.3973950743675232\n",
      "====> Epoch: 2080 || 0.3602604269981384\n",
      "====> Epoch: 2090 || 0.38615742325782776\n",
      "====> Epoch: 2100 || 0.31724756956100464\n",
      "====> Epoch: 2110 || 0.35435619950294495\n",
      "====> Epoch: 2120 || 0.34246519207954407\n",
      "====> Epoch: 2130 || 0.3975650668144226\n",
      "====> Epoch: 2140 || 0.3025992810726166\n",
      "====> Epoch: 2150 || 0.36494240164756775\n",
      "====> Epoch: 2160 || 0.36098745465278625\n",
      "====> Epoch: 2170 || 0.3088395595550537\n",
      "====> Epoch: 2180 || 0.345613569021225\n",
      "====> Epoch: 2190 || 0.34585070610046387\n",
      "====> Epoch: 2200 || 0.3850717842578888\n",
      "====> Epoch: 2210 || 0.3302589952945709\n",
      "====> Epoch: 2220 || 0.39637434482574463\n",
      "====> Epoch: 2230 || 0.36033162474632263\n",
      "====> Epoch: 2240 || 0.3295261859893799\n",
      "====> Epoch: 2250 || 0.3604550063610077\n",
      "====> Epoch: 2260 || 0.32724839448928833\n",
      "====> Epoch: 2270 || 0.3278953731060028\n",
      "====> Epoch: 2280 || 0.3610585629940033\n",
      "====> Epoch: 2290 || 0.3588889539241791\n",
      "====> Epoch: 2300 || 0.3574782907962799\n",
      "====> Epoch: 2310 || 0.36495834589004517\n",
      "====> Epoch: 2320 || 0.3429992198944092\n",
      "====> Epoch: 2330 || 0.34315764904022217\n",
      "====> Epoch: 2340 || 0.34180131554603577\n",
      "====> Epoch: 2350 || 0.32887014746665955\n",
      "====> Epoch: 2360 || 0.39710870385169983\n",
      "====> Epoch: 2370 || 0.36841046810150146\n",
      "====> Epoch: 2380 || 0.3366953134536743\n",
      "====> Epoch: 2390 || 0.3381613790988922\n",
      "====> Epoch: 2400 || 0.35235828161239624\n",
      "====> Epoch: 2410 || 0.34413251280784607\n",
      "====> Epoch: 2420 || 0.3247639238834381\n",
      "====> Epoch: 2430 || 0.29341769218444824\n",
      "====> Epoch: 2440 || 0.3721252381801605\n",
      "====> Epoch: 2450 || 0.3293038010597229\n",
      "====> Epoch: 2460 || 0.3577354848384857\n",
      "====> Epoch: 2470 || 0.3492151200771332\n",
      "====> Epoch: 2480 || 0.3811871111392975\n",
      "====> Epoch: 2490 || 0.3441220223903656\n",
      "====> Epoch: 2500 || 0.3427780270576477\n",
      "====> Epoch: 2510 || 0.403562068939209\n",
      "====> Epoch: 2520 || 0.34955915808677673\n",
      "====> Epoch: 2530 || 0.35091641545295715\n",
      "====> Epoch: 2540 || 0.33930304646492004\n",
      "====> Epoch: 2550 || 0.343513548374176\n",
      "====> Epoch: 2560 || 0.31371572613716125\n",
      "====> Epoch: 2570 || 0.3779531717300415\n",
      "====> Epoch: 2580 || 0.3459439277648926\n",
      "====> Epoch: 2590 || 0.36474138498306274\n",
      "====> Epoch: 2600 || 0.32707759737968445\n",
      "====> Epoch: 2610 || 0.3811638057231903\n",
      "====> Epoch: 2620 || 0.3437829315662384\n",
      "====> Epoch: 2630 || 0.38848748803138733\n",
      "====> Epoch: 2640 || 0.3584683835506439\n",
      "====> Epoch: 2650 || 0.3758472204208374\n",
      "====> Epoch: 2660 || 0.35286203026771545\n",
      "====> Epoch: 2670 || 0.3828395903110504\n",
      "====> Epoch: 2680 || 0.3656371235847473\n",
      "====> Epoch: 2690 || 0.36368727684020996\n",
      "====> Epoch: 2700 || 0.3269531726837158\n",
      "====> Epoch: 2710 || 0.3502044081687927\n",
      "====> Epoch: 2720 || 0.41478782892227173\n",
      "====> Epoch: 2730 || 0.34257906675338745\n",
      "====> Epoch: 2740 || 0.30638667941093445\n",
      "====> Epoch: 2750 || 0.34204211831092834\n",
      "====> Epoch: 2760 || 0.3774329721927643\n",
      "====> Epoch: 2770 || 0.3239304721355438\n",
      "====> Epoch: 2780 || 0.37086474895477295\n",
      "====> Epoch: 2790 || 0.33508867025375366\n",
      "====> Epoch: 2800 || 0.3739013671875\n",
      "====> Epoch: 2810 || 0.3028206527233124\n",
      "====> Epoch: 2820 || 0.32816123962402344\n",
      "====> Epoch: 2830 || 0.3934100866317749\n",
      "====> Epoch: 2840 || 0.38828036189079285\n",
      "====> Epoch: 2850 || 0.3584068715572357\n",
      "====> Epoch: 2860 || 0.35561051964759827\n",
      "====> Epoch: 2870 || 0.34668439626693726\n",
      "====> Epoch: 2880 || 0.34542006254196167\n",
      "====> Epoch: 2890 || 0.3264586925506592\n",
      "====> Epoch: 2900 || 0.4079916477203369\n",
      "====> Epoch: 2910 || 0.35194435715675354\n",
      "====> Epoch: 2920 || 0.3550829291343689\n",
      "====> Epoch: 2930 || 0.3927145004272461\n",
      "====> Epoch: 2940 || 0.3813415765762329\n",
      "====> Epoch: 2950 || 0.35370051860809326\n",
      "====> Epoch: 2960 || 0.36486122012138367\n",
      "====> Epoch: 2970 || 0.35113924741744995\n",
      "====> Epoch: 2980 || 0.3285852074623108\n",
      "====> Epoch: 2990 || 0.4185914993286133\n",
      "====> Epoch: 2999 || 0.3412122428417206\n",
      "[2023-10-13 12:44:40] Evaluate_01: epoch = 1000 train time = 97 s train loss = 0.002480 train acc = 1.0000, test acc = 0.4879\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('cvae_all.pt').to(device)   \n",
    "# A + 样本对  \n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 10 if args_cave.dataset == 'imagenet' else 30, 0.5,)\n",
    "\n",
    "epochs = 3000\n",
    "for epoch in range(epochs):\n",
    "        \n",
    "    # batch_img = images_all[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    \n",
    "    # batch_img = img_real_train[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    # batch_syn = img_syn[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    \n",
    "    # 随机选择batch个索引\n",
    "    random_indices = np.random.choice(len(img_real_train), batch, replace=False)\n",
    "\n",
    "    # 使用随机选择的索引来获取数据并改变形状\n",
    "    batch_img = img_real_train[random_indices].reshape((batch, 3, 32, 32)).to(device)\n",
    "    batch_syn = img_syn[random_indices].reshape((batch, 3, 32, 32)).to(device) \n",
    "\n",
    "    # batch_img_y = label_real_train[c*batch:(c+1)*batch].to(device) \n",
    "    \n",
    "    outputs = model(batch_img)\n",
    "    \n",
    "    loss = model.loss_function(batch_syn, *outputs)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # logs['loss'].append(loss.item())\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == epochs -1:\n",
    "        # print(\"Epoch {:02d}/{:02d} , Loss {:9.4f}\".format(\n",
    "        #     epoch, epochs,  loss.item()))\n",
    "        print(\"====> Epoch: {} || {}\".format(epoch, loss.item()))\n",
    "        \n",
    "with torch.no_grad():\n",
    "  output = model(img_real_test.to(device))\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[0]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test 合成数据集结果（1500张）\n",
    "# 直接输入原图： 0.5100  0.4517 0.4502 0.4670 0.4689 0.4764\n",
    "# 样本对训练原图 - 合成图差异： 0.5093\n",
    "\n",
    "# epoch 2000 + batch 64\n",
    "# A :                  0.4586, 0.004  |   0.4564,0.4551,0.4642\n",
    "# 只用样本对中的原图 :  0.4612, 0.005  |   0.4679,0.4598,0.4558\n",
    "# 只用样本对训 ：       0.4637, 0.008 |   0.4748,0.4576,0.4587\n",
    "# A+合成图 FINTUNE :    0.4668, 0.002  |   0.4683,0.4641,0.4680\n",
    "# A+样本对 FINTUNE(best) :   0.4782, 0.009  |    0.4904,0.4758,0.4685\n",
    "\n",
    "# epoch 3000 + batch 64\n",
    "# A :                  0.4687, 0.005  |   0.4717,0.4614, 0.4730\n",
    "# 只用样本对中的原图 :  0.4580, 0.007  |   0.4531,0.4532,0.4678\n",
    "# 只用样本对训 ：       0.4658, 0.006 |   0.4710,0.4576,0.4689\n",
    "# A+合成图 FINTUNE :    0.472, 0.005  |   0.4732, 0.4770,0.4658\n",
    "# A+样本对 FINTUNE(best) :   0.4833, 0.004  |    0.4807,0.4889,0.4802\n",
    "\n",
    "\n",
    "# epoch 3000 + batch 128 \n",
    "# A :                  0.4657, 0.003  |   0.4639,0.4693, 0.4640\n",
    "# 只用样本对中的原图 :  0.4630, 0.004  |   0.4674,0.4632,0.4585\n",
    "# 只用样本对训 ：       0.4753, 0.008 |   0.4864,0.4733, 0.4661\n",
    "# A+合成图 FINTUNE :    0.4685, 0.004  |   0.4641, 0.4732,0.4682\n",
    "# A+样本对 FINTUNE(best) :   0.4816, 0.007  |    0.4879,0.4853,0.4716\n",
    "\n",
    "\n",
    "# accs = [0.3642,0.3756,0.3759]np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [0.4879,0.4853,0.4716]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.48160000000000003, 0.007150291369354578)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_net(epoch, model, test_loader, cuda, save_path, args, writer):\n",
    "#     model.eval()\n",
    "#     loss_dict = model.latest_losses()\n",
    "#     losses = {k + '_test': 0 for k, v in loss_dict.items()}\n",
    "#     i, data = None, None\n",
    "#     with torch.no_grad():\n",
    "#         for i, (data, _) in enumerate(test_loader):\n",
    "#             if cuda:\n",
    "#                 data = data.cuda()\n",
    "#             outputs = model(data)\n",
    "#             model.loss_function(data, *outputs)\n",
    "#             latest_losses = model.latest_losses()\n",
    "#             for key in latest_losses:\n",
    "#                 losses[key + '_test'] += float(latest_losses[key])\n",
    "#             if i == 0:\n",
    "#                 write_images(data, outputs, writer, 'test')\n",
    "\n",
    "#                 save_reconstructed_images(data, epoch, outputs[0], save_path, 'reconstruction_test')\n",
    "#                 # save_checkpoint(model, epoch, save_path)\n",
    "#             if args.dataset == 'imagenet' and i * len(data) > 1000:\n",
    "#                 break\n",
    "\n",
    "#     for key in losses:\n",
    "#         if args.dataset not in ['imagenet', 'custom']:\n",
    "#             losses[key] /= (len(test_loader.dataset) / test_loader.batch_size)\n",
    "#         else:\n",
    "#             losses[key] /= (i * len(data))\n",
    "#     loss_string = ' '.join(['{}: {:.6f}'.format(k, v) for k, v in losses.items()])\n",
    "#     logging.info('====> Test set losses: {}'.format(loss_string))\n",
    "#     return losses\n",
    "\n",
    "\n",
    "# def write_images(data, outputs, writer, suffix):\n",
    "#     original = data.mul(0.5).add(0.5)\n",
    "#     original_grid = make_grid(original[:6])\n",
    "#     writer.add_image(f'original/{suffix}', original_grid)\n",
    "#     reconstructed = outputs[0].mul(0.5).add(0.5)\n",
    "#     reconstructed_grid = make_grid(reconstructed[:6])\n",
    "#     writer.add_image(f'reconstructed/{suffix}', reconstructed_grid)\n",
    "\n",
    "\n",
    "# def save_reconstructed_images(data, epoch, outputs, save_path, name):\n",
    "#     size = data.size()\n",
    "#     n = min(data.size(0), 8)\n",
    "#     batch_size = data.size(0)\n",
    "#     comparison = torch.cat([data[:n],\n",
    "#                             outputs.view(batch_size, size[1], size[2], size[3])[:n]])\n",
    "#     save_image(comparison.cpu(),\n",
    "#                os.path.join(save_path, name + '_' + str(epoch) + '.png'), nrow=n, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ztl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
