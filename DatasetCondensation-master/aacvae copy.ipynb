{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "from utils import get_loops, get_dataset, get_network, get_eval_pool, evaluate_synset, get_daparam, match_loss, get_time, TensorDataset, epoch, DiffAugment, ParamDiffAug\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# watch -n 1 nvidia-smi\n",
    "import os\n",
    "\n",
    "# 显示第 0 和第 1 个 GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "parser = argparse.ArgumentParser(description='Parameter Processing')\n",
    "parser.add_argument('--dataset', type=str, default='CIFAR10', help='dataset')\n",
    "parser.add_argument('--model', type=str, default='ConvNet', help='model')\n",
    "parser.add_argument('--ipc', type=int, default=50, help='image(s) per class')\n",
    "parser.add_argument('--eval_mode', type=str, default='SS', help='eval_mode') # S: the same to training model, M: multi architectures,  W: net width, D: net depth, A: activation function, P: pooling layer, N: normalization layer,\n",
    "\n",
    "\n",
    "\n",
    "parser.add_argument('--num_exp', type=int, default=3, help='the number of experiments')\n",
    "\n",
    "\n",
    "\n",
    "parser.add_argument('--num_eval', type=int, default=1, help='the number of evaluating randomly initialized models')\n",
    "parser.add_argument('--epoch_eval_train', type=int, default=1000, help='epochs to train a model with synthetic data') # it can be small for speeding up with little performance drop\n",
    "parser.add_argument('--Iteration', type=int, default=2000, help='training iterations')\n",
    "parser.add_argument('--lr_img', type=float, default=1.0, help='learning rate for updating synthetic images')\n",
    "parser.add_argument('--lr_net', type=float, default=0.01, help='learning rate for updating network parameters')\n",
    "parser.add_argument('--batch_real', type=int, default=256, help='batch size for real data')\n",
    "parser.add_argument('--batch_train', type=int, default=256, help='batch size for training networks')\n",
    "parser.add_argument('--init', type=str, default='real', help='noise/real: initialize synthetic images from random noise or randomly sampled real images.')\n",
    "parser.add_argument('--dsa_strategy', type=str, default='color_crop_cutout_flip_scale_rotate', help='differentiable Siamese augmentation strategy')\n",
    "parser.add_argument('--data_path', type=str, default='/home/ssd7T/ZTL_gcond/data_cv', help='dataset path')\n",
    "parser.add_argument('--save_path', type=str, default='/home/ssd7T/ztl_dm/gen', help='path to save results')\n",
    "parser.add_argument('--dis_metric', type=str, default='ours', help='distance metric')\n",
    "\n",
    "args = parser.parse_args([])\n",
    "args.method = 'DM'\n",
    "args.outer_loop, args.inner_loop = get_loops(args.ipc)\n",
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "args.dsa_param = ParamDiffAug()\n",
    "args.dsa = False if args.dsa_strategy in ['none', 'None'] else True\n",
    "\n",
    "if not os.path.exists(args.data_path):\n",
    "    os.mkdir(args.data_path)\n",
    "\n",
    "if not os.path.exists(args.save_path):\n",
    "    os.mkdir(args.save_path)\n",
    "\n",
    "eval_it_pool = np.arange(0, args.Iteration+1, 2000).tolist() if args.eval_mode == 'S' or args.eval_mode == 'SS' else [args.Iteration] # The list of iterations when we evaluate models and record results.\n",
    "print('eval_it_pool: ', eval_it_pool)\n",
    "channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader = get_dataset(args.dataset, args.data_path)\n",
    "model_eval_pool = get_eval_pool(args.eval_mode, args.model, args.model)\n",
    "\n",
    "\n",
    "accs_all_exps = dict() # record performances of all experiments\n",
    "for key in model_eval_pool:\n",
    "    accs_all_exps[key] = []\n",
    "\n",
    "data_save = []\n",
    "pairs_real = []\n",
    "indexs_real = []\n",
    "\n",
    "for exp in range(args.num_exp):\n",
    "    # pairs_real = []\n",
    "    # indexs_real = []\n",
    "    exp = exp + 85\n",
    "    print('\\n================== Exp %d ==================\\n '%exp)\n",
    "    print('Hyper-parameters: \\n', args.__dict__)\n",
    "    print('Evaluation model pool: ', model_eval_pool)\n",
    "\n",
    "    ''' organize the real dataset '''\n",
    "    images_all = []\n",
    "    labels_all = []\n",
    "    indices_class = [[] for c in range(num_classes)]\n",
    "\n",
    "    images_all = [torch.unsqueeze(dst_train[i][0], dim=0) for i in range(len(dst_train))]\n",
    "    labels_all = [dst_train[i][1] for i in range(len(dst_train))]\n",
    "    for i, lab in enumerate(labels_all):\n",
    "        indices_class[lab].append(i)\n",
    "    images_all = torch.cat(images_all, dim=0).to(args.device)\n",
    "    labels_all = torch.tensor(labels_all, dtype=torch.long, device=args.device)\n",
    "\n",
    "\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        print('class c = %d: %d real images'%(c, len(indices_class[c])))\n",
    "\n",
    "    def get_images(c, n): # get random n images from class c\n",
    "        idx_shuffle = np.random.permutation(indices_class[c])[:n]\n",
    "        return images_all[idx_shuffle]\n",
    "    \n",
    "    def get_images_init(c, n,exp): # get random n images from class c\n",
    "        # start_idx = i  # 指定起始索引 i\n",
    "        # end_idx = i + n  # 计算结束索引（不包括结束索引）\n",
    "\n",
    "        # 从指定的起始索引到结束索引获取元素\n",
    "        idx_shuffle  = indices_class[c][exp:exp + n]\n",
    "\n",
    "        # idx_shuffle = np.random.permutation(indices_class[c])[:n]\n",
    "        return images_all[idx_shuffle],idx_shuffle\n",
    "\n",
    "    for ch in range(channel):\n",
    "        print('real images channel %d, mean = %.4f, std = %.4f'%(ch, torch.mean(images_all[:, ch]), torch.std(images_all[:, ch])))\n",
    "\n",
    "\n",
    "    ''' initialize the synthetic data '''\n",
    "    image_syn = torch.randn(size=(num_classes*args.ipc, channel, im_size[0], im_size[1]), dtype=torch.float, requires_grad=True, device=args.device)\n",
    "    label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]\n",
    "\n",
    "    if args.init == 'real':\n",
    "        print('initialize synthetic data from random real images')\n",
    "        for c in range(num_classes):\n",
    "            reals,index = get_images_init(c, args.ipc,exp)\n",
    "            reals = reals.detach().data\n",
    "            pairs_real.append(reals)\n",
    "            indexs_real.append(index)\n",
    "            image_syn.data[c*args.ipc:(c+1)*args.ipc] = reals\n",
    "            # pairs_real\n",
    "    else:\n",
    "        print('initialize synthetic data from random noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_real_test= torch.cat(pairs_real, dim=0)\n",
    "\n",
    "label_real_test = []\n",
    "for i in range(int(len(indexs_real)/10)):\n",
    "    # print(i)\n",
    "    label_real_test_ = []\n",
    "    for c in range(num_classes):\n",
    "        idx_shuffle = indexs_real[c + i*10]\n",
    "        label_real_test_.append(labels_all[idx_shuffle].to(\"cpu\"))\n",
    "        # print()\n",
    "    # img_real = torch.from_numpy(np.concatenate(img_real, axis=0))\n",
    "    label_real_test_ = torch.from_numpy(np.concatenate(label_real_test_, axis=0))\n",
    "    label_real_test.append(label_real_test_)\n",
    "label_real_test = torch.cat(label_real_test, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_syn = []\n",
    "label_syn = []\n",
    "img_real_train = []\n",
    "label_real_train = []\n",
    "# /home/ssd7T/ztl_dm/indexs_real_20.pt\n",
    "for i in range(80):\n",
    "    try:\n",
    "    \n",
    "        img_syn_ = torch.load(f'/home/ssd7T/ztl_dm/img_syn_{i}.pt')\n",
    "        label_syn_ = torch.load(f'/home/ssd7T/ztl_dm/label_syn_{i}.pt')\n",
    "        pairs_real_=torch.load(f'/home/ssd7T/ztl_dm/pairs_real_{i}.pt')\n",
    "        indexs_real_=torch.load(f'/home/ssd7T/ztl_dm/indexs_real_{i}.pt')\n",
    "        \n",
    "        img_real_train_ = torch.cat(pairs_real_, dim=0)\n",
    "        \n",
    "    \n",
    "        label_real_ = []\n",
    "        for c in range(num_classes):\n",
    "            idx_shuffle = indexs_real_[c]\n",
    "            label_real_.append(labels_all[idx_shuffle].to(\"cpu\"))\n",
    "        # img_real = torch.from_numpy(np.concatenate(img_real, axis=0))\n",
    "        label_real_train_ = torch.from_numpy(np.concatenate(label_real_, axis=0))\n",
    "        # label_real_train_ = torch.cat(label_real_train_, dim=0)\n",
    "        \n",
    "        img_syn.append(img_syn_)\n",
    "        label_syn.append(label_syn_)\n",
    "        img_real_train.append(img_real_train_)\n",
    "        label_real_train.append( label_real_train_)\n",
    "        # if i == 3 or i == 22 or i == 42 or i == 62:\n",
    "        #     pairs_real_=torch.load(f'pairs_real_{i}.pt')\n",
    "        #     img_real_train_ = torch.cat(pairs_real_, dim=0)\n",
    "        #     img_real_train.append(img_real_train_)\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "img_syn = torch.cat(img_syn, dim=0).to(device)\n",
    "label_syn = torch.cat(label_syn, dim=0).to(device)\n",
    "img_real_train = torch.cat(img_real_train, dim=0).to(device)\n",
    "label_real_train = torch.cat(label_real_train, dim=0).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_real_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "model_eval_pool = get_eval_pool(args.eval_mode, args.model, args.model)\n",
    "import copy\n",
    "accs_all_exps = dict() # record performances of all experiments\n",
    "for key in model_eval_pool:\n",
    "    accs_all_exps[key] = []\n",
    "args.dsa_param = ParamDiffAug()\n",
    "args.dsa = False if args.dsa_strategy in ['none', 'None'] else True\n",
    "model_eval= model_eval_pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_classes = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from a_cvae import  CVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 310 || 0.45274198055267334\n",
      "====> Epoch: 320 || 0.3920760750770569\n",
      "====> Epoch: 330 || 0.4361448884010315\n",
      "====> Epoch: 340 || 0.4589168429374695\n",
      "====> Epoch: 350 || 0.4764600396156311\n",
      "====> Epoch: 360 || 0.45012331008911133\n",
      "====> Epoch: 370 || 0.43497318029403687\n",
      "====> Epoch: 380 || 0.4599984586238861\n",
      "====> Epoch: 390 || 0.47639983892440796\n",
      "====> Epoch: 400 || 0.3984176814556122\n",
      "====> Epoch: 410 || 0.4566979706287384\n",
      "====> Epoch: 420 || 0.4292212128639221\n",
      "====> Epoch: 430 || 0.4357945919036865\n",
      "====> Epoch: 440 || 0.45940259099006653\n",
      "====> Epoch: 450 || 0.4267178773880005\n",
      "====> Epoch: 460 || 0.43222978711128235\n",
      "====> Epoch: 470 || 0.4086083471775055\n",
      "====> Epoch: 480 || 0.4632788300514221\n",
      "====> Epoch: 490 || 0.4430690407752991\n",
      "====> Epoch: 500 || 0.43881309032440186\n",
      "====> Epoch: 510 || 0.47247737646102905\n",
      "====> Epoch: 520 || 0.44093096256256104\n",
      "====> Epoch: 530 || 0.43182870745658875\n",
      "====> Epoch: 540 || 0.42612016201019287\n",
      "====> Epoch: 550 || 0.45518621802330017\n",
      "====> Epoch: 560 || 0.48129111528396606\n",
      "====> Epoch: 570 || 0.4444354474544525\n",
      "====> Epoch: 580 || 0.4220656156539917\n",
      "====> Epoch: 590 || 0.43468761444091797\n",
      "====> Epoch: 600 || 0.4413844048976898\n",
      "====> Epoch: 610 || 0.43150272965431213\n",
      "====> Epoch: 620 || 0.41595059633255005\n",
      "====> Epoch: 630 || 0.4385277330875397\n",
      "====> Epoch: 640 || 0.44491973519325256\n",
      "====> Epoch: 650 || 0.3763267397880554\n",
      "====> Epoch: 660 || 0.4490429162979126\n",
      "====> Epoch: 670 || 0.4395291209220886\n",
      "====> Epoch: 680 || 0.4015687108039856\n",
      "====> Epoch: 690 || 0.4763173758983612\n",
      "====> Epoch: 700 || 0.41475847363471985\n",
      "====> Epoch: 710 || 0.470877468585968\n",
      "====> Epoch: 720 || 0.43277764320373535\n",
      "====> Epoch: 730 || 0.4560154974460602\n",
      "====> Epoch: 740 || 0.4521671235561371\n",
      "====> Epoch: 750 || 0.4175126552581787\n",
      "====> Epoch: 760 || 0.3990629315376282\n",
      "====> Epoch: 770 || 0.43282926082611084\n",
      "====> Epoch: 780 || 0.4277626574039459\n",
      "====> Epoch: 790 || 0.41963109374046326\n",
      "====> Epoch: 800 || 0.38537856936454773\n",
      "====> Epoch: 810 || 0.4428849220275879\n",
      "====> Epoch: 820 || 0.4126896560192108\n",
      "====> Epoch: 830 || 0.41628512740135193\n",
      "====> Epoch: 840 || 0.4201306998729706\n",
      "====> Epoch: 850 || 0.39809107780456543\n",
      "====> Epoch: 860 || 0.4069235324859619\n",
      "====> Epoch: 870 || 0.4229907691478729\n",
      "====> Epoch: 880 || 0.42285147309303284\n",
      "====> Epoch: 890 || 0.39681994915008545\n",
      "====> Epoch: 900 || 0.42660433053970337\n",
      "====> Epoch: 910 || 0.39480075240135193\n",
      "====> Epoch: 920 || 0.4576568901538849\n",
      "====> Epoch: 930 || 0.4002291262149811\n",
      "====> Epoch: 940 || 0.3931804299354553\n",
      "====> Epoch: 950 || 0.3886149525642395\n",
      "====> Epoch: 960 || 0.3865131735801697\n",
      "====> Epoch: 970 || 0.41230642795562744\n",
      "====> Epoch: 980 || 0.40505072474479675\n",
      "====> Epoch: 990 || 0.41065582633018494\n",
      "====> Epoch: 1000 || 0.41382887959480286\n",
      "====> Epoch: 1010 || 0.41122350096702576\n",
      "====> Epoch: 1020 || 0.37756967544555664\n",
      "====> Epoch: 1030 || 0.400282621383667\n",
      "====> Epoch: 1040 || 0.3958183825016022\n",
      "====> Epoch: 1050 || 0.43783387541770935\n",
      "====> Epoch: 1060 || 0.39779481291770935\n",
      "====> Epoch: 1070 || 0.36955198645591736\n",
      "====> Epoch: 1080 || 0.4171971380710602\n",
      "====> Epoch: 1090 || 0.42003950476646423\n",
      "====> Epoch: 1100 || 0.4295104146003723\n",
      "====> Epoch: 1110 || 0.41657987236976624\n",
      "====> Epoch: 1120 || 0.3842182159423828\n",
      "====> Epoch: 1130 || 0.3874540328979492\n",
      "====> Epoch: 1140 || 0.42711341381073\n",
      "====> Epoch: 1150 || 0.38381093740463257\n",
      "====> Epoch: 1160 || 0.44970670342445374\n",
      "====> Epoch: 1170 || 0.4051414728164673\n",
      "====> Epoch: 1180 || 0.36301058530807495\n",
      "====> Epoch: 1190 || 0.37207502126693726\n",
      "====> Epoch: 1200 || 0.40087711811065674\n",
      "====> Epoch: 1210 || 0.42582452297210693\n",
      "====> Epoch: 1220 || 0.4132418930530548\n",
      "====> Epoch: 1230 || 0.4230460226535797\n",
      "====> Epoch: 1240 || 0.3991292715072632\n",
      "====> Epoch: 1250 || 0.39135685563087463\n",
      "====> Epoch: 1260 || 0.4026818573474884\n",
      "====> Epoch: 1270 || 0.40068840980529785\n",
      "====> Epoch: 1280 || 0.39151206612586975\n",
      "====> Epoch: 1290 || 0.3964383900165558\n",
      "====> Epoch: 1300 || 0.4055926501750946\n",
      "====> Epoch: 1310 || 0.43924182653427124\n",
      "====> Epoch: 1320 || 0.37919285893440247\n",
      "====> Epoch: 1330 || 0.3729364573955536\n",
      "====> Epoch: 1340 || 0.3819113075733185\n",
      "====> Epoch: 1350 || 0.38751333951950073\n",
      "====> Epoch: 1360 || 0.38587358593940735\n",
      "====> Epoch: 1370 || 0.40019774436950684\n",
      "====> Epoch: 1380 || 0.3693959712982178\n",
      "====> Epoch: 1390 || 0.35855433344841003\n",
      "====> Epoch: 1400 || 0.4571283161640167\n",
      "====> Epoch: 1410 || 0.42333853244781494\n",
      "====> Epoch: 1420 || 0.4233461618423462\n",
      "====> Epoch: 1430 || 0.41089341044425964\n",
      "====> Epoch: 1440 || 0.3754670023918152\n",
      "====> Epoch: 1450 || 0.3559597134590149\n",
      "====> Epoch: 1460 || 0.36579129099845886\n",
      "====> Epoch: 1470 || 0.37552669644355774\n",
      "====> Epoch: 1480 || 0.34990060329437256\n",
      "====> Epoch: 1490 || 0.41672471165657043\n",
      "====> Epoch: 1500 || 0.4062551259994507\n",
      "====> Epoch: 1510 || 0.3385182321071625\n",
      "====> Epoch: 1520 || 0.38385725021362305\n",
      "====> Epoch: 1530 || 0.3744502067565918\n",
      "====> Epoch: 1540 || 0.41421958804130554\n",
      "====> Epoch: 1550 || 0.36270830035209656\n",
      "====> Epoch: 1560 || 0.4027080237865448\n",
      "====> Epoch: 1570 || 0.3529587984085083\n",
      "====> Epoch: 1580 || 0.4061632752418518\n",
      "====> Epoch: 1590 || 0.32124507427215576\n",
      "====> Epoch: 1600 || 0.3765259385108948\n",
      "====> Epoch: 1610 || 0.4067712724208832\n",
      "====> Epoch: 1620 || 0.3662072718143463\n",
      "====> Epoch: 1630 || 0.3806696832180023\n",
      "====> Epoch: 1640 || 0.38335588574409485\n",
      "====> Epoch: 1650 || 0.3639708161354065\n",
      "====> Epoch: 1660 || 0.36609262228012085\n",
      "====> Epoch: 1670 || 0.4305051565170288\n",
      "====> Epoch: 1680 || 0.4159574806690216\n",
      "====> Epoch: 1690 || 0.3685225546360016\n",
      "====> Epoch: 1700 || 0.3859156668186188\n",
      "====> Epoch: 1710 || 0.4412076473236084\n",
      "====> Epoch: 1720 || 0.3735060691833496\n",
      "====> Epoch: 1730 || 0.31155362725257874\n",
      "====> Epoch: 1740 || 0.3690451979637146\n",
      "====> Epoch: 1750 || 0.37213295698165894\n",
      "====> Epoch: 1760 || 0.36167097091674805\n",
      "====> Epoch: 1770 || 0.371515154838562\n",
      "====> Epoch: 1780 || 0.35329294204711914\n",
      "====> Epoch: 1790 || 0.3188205063343048\n",
      "====> Epoch: 1800 || 0.40519508719444275\n",
      "====> Epoch: 1810 || 0.40107041597366333\n",
      "====> Epoch: 1820 || 0.35726189613342285\n",
      "====> Epoch: 1830 || 0.3555361330509186\n",
      "====> Epoch: 1840 || 0.38852542638778687\n",
      "====> Epoch: 1850 || 0.4077540934085846\n",
      "====> Epoch: 1860 || 0.3535008430480957\n",
      "====> Epoch: 1870 || 0.40380021929740906\n",
      "====> Epoch: 1880 || 0.39259788393974304\n",
      "====> Epoch: 1890 || 0.3394235372543335\n",
      "====> Epoch: 1900 || 0.396932452917099\n",
      "====> Epoch: 1910 || 0.3182567059993744\n",
      "====> Epoch: 1920 || 0.36758941411972046\n",
      "====> Epoch: 1930 || 0.36999350786209106\n",
      "====> Epoch: 1940 || 0.3719428777694702\n",
      "====> Epoch: 1950 || 0.34455153346061707\n",
      "====> Epoch: 1960 || 0.39425572752952576\n",
      "====> Epoch: 1970 || 0.36063235998153687\n",
      "====> Epoch: 1980 || 0.43502363562583923\n",
      "====> Epoch: 1990 || 0.3568226099014282\n",
      "====> Epoch: 2000 || 0.3797725439071655\n",
      "====> Epoch: 2010 || 0.36210012435913086\n",
      "====> Epoch: 2020 || 0.4085530638694763\n",
      "====> Epoch: 2030 || 0.34847351908683777\n",
      "====> Epoch: 2040 || 0.36786380410194397\n",
      "====> Epoch: 2050 || 0.4012405276298523\n",
      "====> Epoch: 2060 || 0.42218145728111267\n",
      "====> Epoch: 2070 || 0.3392224907875061\n",
      "====> Epoch: 2080 || 0.3635551333427429\n",
      "====> Epoch: 2090 || 0.3296019434928894\n",
      "====> Epoch: 2100 || 0.32153868675231934\n",
      "====> Epoch: 2110 || 0.39768290519714355\n",
      "====> Epoch: 2120 || 0.3861561417579651\n",
      "====> Epoch: 2130 || 0.3543679118156433\n",
      "====> Epoch: 2140 || 0.3801247775554657\n",
      "====> Epoch: 2150 || 0.34836140275001526\n",
      "====> Epoch: 2160 || 0.3957221508026123\n",
      "====> Epoch: 2170 || 0.41331353783607483\n",
      "====> Epoch: 2180 || 0.3966405391693115\n",
      "====> Epoch: 2190 || 0.34251856803894043\n",
      "====> Epoch: 2200 || 0.38732823729515076\n",
      "====> Epoch: 2210 || 0.42361220717430115\n",
      "====> Epoch: 2220 || 0.3921413719654083\n",
      "====> Epoch: 2230 || 0.3822909891605377\n",
      "====> Epoch: 2240 || 0.32178425788879395\n",
      "====> Epoch: 2250 || 0.3374861180782318\n",
      "====> Epoch: 2260 || 0.3136416971683502\n",
      "====> Epoch: 2270 || 0.3897128403186798\n",
      "====> Epoch: 2280 || 0.4052746295928955\n",
      "====> Epoch: 2290 || 0.35738104581832886\n",
      "====> Epoch: 2300 || 0.3619441092014313\n",
      "====> Epoch: 2310 || 0.3765532374382019\n",
      "====> Epoch: 2320 || 0.37771111726760864\n",
      "====> Epoch: 2330 || 0.3749435842037201\n",
      "====> Epoch: 2340 || 0.369570791721344\n",
      "====> Epoch: 2350 || 0.39002880454063416\n",
      "====> Epoch: 2360 || 0.3528361916542053\n",
      "====> Epoch: 2370 || 0.34888532757759094\n",
      "====> Epoch: 2380 || 0.3263534605503082\n",
      "====> Epoch: 2390 || 0.33308547735214233\n",
      "====> Epoch: 2400 || 0.397171288728714\n",
      "====> Epoch: 2410 || 0.37096282839775085\n",
      "====> Epoch: 2420 || 0.3617191016674042\n",
      "====> Epoch: 2430 || 0.3412993252277374\n",
      "====> Epoch: 2440 || 0.3888627588748932\n",
      "====> Epoch: 2450 || 0.34396591782569885\n",
      "====> Epoch: 2460 || 0.37434375286102295\n",
      "====> Epoch: 2470 || 0.37866055965423584\n",
      "====> Epoch: 2480 || 0.3431214392185211\n",
      "====> Epoch: 2490 || 0.3627665936946869\n",
      "====> Epoch: 2500 || 0.3370484411716461\n",
      "====> Epoch: 2510 || 0.3788674771785736\n",
      "====> Epoch: 2520 || 0.3529035449028015\n",
      "====> Epoch: 2530 || 0.33259299397468567\n",
      "====> Epoch: 2540 || 0.38388320803642273\n",
      "====> Epoch: 2550 || 0.33610424399375916\n",
      "====> Epoch: 2560 || 0.37188035249710083\n",
      "====> Epoch: 2570 || 0.34563109278678894\n",
      "====> Epoch: 2580 || 0.35499924421310425\n",
      "====> Epoch: 2590 || 0.38927558064460754\n",
      "====> Epoch: 2600 || 0.3686000406742096\n",
      "====> Epoch: 2610 || 0.35702499747276306\n",
      "====> Epoch: 2620 || 0.36006033420562744\n",
      "====> Epoch: 2630 || 0.38524243235588074\n",
      "====> Epoch: 2640 || 0.39900150895118713\n",
      "====> Epoch: 2650 || 0.41743433475494385\n",
      "====> Epoch: 2660 || 0.33933091163635254\n",
      "====> Epoch: 2670 || 0.3621695935726166\n",
      "====> Epoch: 2680 || 0.3698846995830536\n",
      "====> Epoch: 2690 || 0.41332513093948364\n",
      "====> Epoch: 2700 || 0.3401504158973694\n",
      "====> Epoch: 2710 || 0.3714843690395355\n",
      "====> Epoch: 2720 || 0.34652411937713623\n",
      "====> Epoch: 2730 || 0.34131482243537903\n",
      "====> Epoch: 2740 || 0.347702294588089\n",
      "====> Epoch: 2750 || 0.3970593214035034\n",
      "====> Epoch: 2760 || 0.3570498526096344\n",
      "====> Epoch: 2770 || 0.35095250606536865\n",
      "====> Epoch: 2780 || 0.3766401708126068\n",
      "====> Epoch: 2790 || 0.39561671018600464\n",
      "====> Epoch: 2800 || 0.3264647126197815\n",
      "====> Epoch: 2810 || 0.38828879594802856\n",
      "====> Epoch: 2820 || 0.3711380362510681\n",
      "====> Epoch: 2830 || 0.3844471573829651\n",
      "====> Epoch: 2840 || 0.3346412777900696\n",
      "====> Epoch: 2850 || 0.3704012632369995\n",
      "====> Epoch: 2860 || 0.39684155583381653\n",
      "====> Epoch: 2870 || 0.3961998522281647\n",
      "====> Epoch: 2880 || 0.36542603373527527\n",
      "====> Epoch: 2890 || 0.3761447072029114\n",
      "====> Epoch: 2900 || 0.34618279337882996\n",
      "====> Epoch: 2910 || 0.37202513217926025\n",
      "====> Epoch: 2920 || 0.3858884572982788\n",
      "====> Epoch: 2930 || 0.34611693024635315\n",
      "====> Epoch: 2940 || 0.31993550062179565\n",
      "====> Epoch: 2950 || 0.33496689796447754\n",
      "====> Epoch: 2960 || 0.38487210869789124\n",
      "====> Epoch: 2970 || 0.33003970980644226\n",
      "====> Epoch: 2980 || 0.3565813899040222\n",
      "====> Epoch: 2990 || 0.3160388767719269\n",
      "====> Epoch: 2999 || 0.35236313939094543\n",
      "[2023-10-13 12:17:24] Evaluate_01: epoch = 1000 train time = 97 s train loss = 0.002366 train acc = 1.0000, test acc = 0.4693\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import argparse\n",
    "\n",
    "import torch.utils.data\n",
    "from torch import optim\n",
    "\n",
    "from torchvision.utils import save_image, make_grid\n",
    "    # 'custom': {'lr': 2e-4, 'k': 512, 'hidden': 128},\n",
    "    # 'imagenet': {'lr': 2e-4, 'k': 512, 'hidden': 128},\n",
    "    # 'cifar10': {'lr': 2e-4, 'k': 10, 'hidden': 256},\n",
    "    # 'mnist': {'lr': 1e-4, 'k': 10, 'hidden': 64}\n",
    "parser = argparse.ArgumentParser(description='Variational AutoEncoders')\n",
    "\n",
    "model_parser = parser.add_argument_group('Model Parameters')\n",
    "model_parser.add_argument('--model', default='vae', choices=['vae', 'vqvae'],\n",
    "                            help='autoencoder variant to use: vae | vqvae')\n",
    "model_parser.add_argument('--batch-size', type=int, default=128, metavar='N',\n",
    "                            help='input batch size for training (default: 128)')\n",
    "model_parser.add_argument('--hidden', type=int, default=256, metavar='N',\n",
    "                            help='number of hidden channels')\n",
    "\n",
    "model_parser.add_argument('-k', '--dict-size',  default=10,type=int, dest='k', metavar='K',\n",
    "                            help='number of atoms in dictionary')\n",
    "model_parser.add_argument('--lr', type=float, default=2e-4,\n",
    "                            help='learning rate')\n",
    "model_parser.add_argument('--vq_coef', type=float, default=None,\n",
    "                            help='vq coefficient in loss')\n",
    "model_parser.add_argument('--commit_coef', type=float, default=None,\n",
    "                            help='commitment coefficient in loss')\n",
    "model_parser.add_argument('--kl_coef', type=float, default=None,\n",
    "                            help='kl-divergence coefficient in loss')\n",
    "\n",
    "training_parser = parser.add_argument_group('Training Parameters')\n",
    "training_parser.add_argument('--dataset', default='cifar10', choices=['mnist', 'cifar10', 'imagenet',\n",
    "                                                                        'custom'],\n",
    "                                help='dataset to use: mnist | cifar10 | imagenet | custom')\n",
    "training_parser.add_argument('--dataset_dir_name', default='',\n",
    "                                help='name of the dir containing the dataset if dataset == custom')\n",
    "training_parser.add_argument('--data-dir', default='/media/ssd/Datasets',\n",
    "                                help='directory containing the dataset')\n",
    "training_parser.add_argument('--epochs', type=int, default=20, metavar='N',\n",
    "                                help='number of epochs to train (default: 10)')\n",
    "training_parser.add_argument('--max-epoch-samples', type=int, default=50000,\n",
    "                                help='max num of samples per epoch')\n",
    "training_parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                                help='enables CUDA training')\n",
    "training_parser.add_argument('--seed', type=int, default=6, metavar='S',\n",
    "                                help='random seed (default: 1)')\n",
    "training_parser.add_argument('--gpus', default='0',\n",
    "                                help='gpus used for training - e.g 0,1,3')\n",
    "\n",
    "logging_parser = parser.add_argument_group('Logging Parameters')\n",
    "logging_parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                            help='how many batches to wait before logging training status')\n",
    "logging_parser.add_argument('--results-dir', metavar='RESULTS_DIR', default='./results',\n",
    "                            help='results dir')\n",
    "logging_parser.add_argument('--save-name', default='',\n",
    "                            help='saved folder')\n",
    "logging_parser.add_argument('--data-format', default='json',\n",
    "                            help='in which format to save the data')\n",
    "\n",
    "\n",
    "# 256, 794, 3, 3\n",
    "\n",
    "args_cave = parser.parse_args([])\n",
    "\n",
    "\n",
    "torch.manual_seed(args_cave.seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(args_cave.seed)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# dataset = MNIST(\n",
    "#     root='/home/ssd7T/ZTL_gcond/data_cv', train=True, transform=transforms.ToTensor(),\n",
    "#     download=True)\n",
    "# data_loader = DataLoader(\n",
    "#     dataset=dataset, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "lr = args_cave.lr \n",
    "k = args_cave.k \n",
    "hidden = args_cave.hidden \n",
    "num_channels = 3 # CIFA\n",
    "\n",
    "model = CVAE(d = hidden, k=k, num_channels=num_channels).to(device) \n",
    "\n",
    "# def __init__(self, d, kl_coef=0.1, **kwargs):\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 10 if args_cave.dataset == 'imagenet' else 30, 0.5,)\n",
    "    \n",
    "    \n",
    "batch = args_cave.batch_size\n",
    "# A\n",
    "\n",
    "epochs = 3000\n",
    "for epoch in range(epochs):\n",
    "\n",
    "        \n",
    "    random_indices = np.random.choice(len(img_real_train), batch, replace=False)\n",
    "\n",
    "# 使用随机选择的索引来获取数据并改变形状\n",
    "    batch_img = images_all[random_indices].reshape((batch, 3, 32, 32)).to(device)\n",
    "    # batch_syn = img_syn[random_indices].reshape((batch, 3, 32, 32)).to(device) \n",
    "    # batch_img_y = label_real_train[c*batch:(c+1)*batch].to(device) \n",
    "        \n",
    "    outputs = model(batch_img)\n",
    "    \n",
    "    loss = model.loss_function(batch_img, *outputs)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "        # logs['loss'].append(loss.item())\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == epochs -1:\n",
    "        # print(\"Epoch {:02d}/{:02d} , Loss {:9.4f}\".format(\n",
    "        #     epoch, epochs,  loss.item()))\n",
    "        print(\"====> Epoch: {} || {}\".format(epoch, loss.item()))\n",
    "        \n",
    "with torch.no_grad():\n",
    "  output = model(img_real_test.to(device))\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[0]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'cvae_all_2.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 || 2.1340150833129883\n",
      "====> Epoch: 10 || 0.9069045186042786\n",
      "====> Epoch: 20 || 0.7115136981010437\n",
      "====> Epoch: 30 || 0.6463376879692078\n",
      "====> Epoch: 40 || 0.613821804523468\n",
      "====> Epoch: 50 || 0.5472981929779053\n",
      "====> Epoch: 60 || 0.4958128035068512\n",
      "====> Epoch: 70 || 0.46100789308547974\n",
      "====> Epoch: 80 || 0.4959169626235962\n",
      "====> Epoch: 90 || 0.5134686231613159\n",
      "====> Epoch: 100 || 0.5289812684059143\n",
      "====> Epoch: 110 || 0.49020203948020935\n",
      "====> Epoch: 120 || 0.48215851187705994\n",
      "====> Epoch: 130 || 0.43007057905197144\n",
      "====> Epoch: 140 || 0.4775165021419525\n",
      "====> Epoch: 150 || 0.43863627314567566\n",
      "====> Epoch: 160 || 0.46100640296936035\n",
      "====> Epoch: 170 || 0.43461373448371887\n",
      "====> Epoch: 180 || 0.44392457604408264\n",
      "====> Epoch: 190 || 0.42891979217529297\n",
      "====> Epoch: 200 || 0.4349367320537567\n",
      "====> Epoch: 210 || 0.489485502243042\n",
      "====> Epoch: 220 || 0.47778603434562683\n",
      "====> Epoch: 230 || 0.3813686966896057\n",
      "====> Epoch: 240 || 0.45476803183555603\n",
      "====> Epoch: 250 || 0.4639662206172943\n",
      "====> Epoch: 260 || 0.4373057186603546\n",
      "====> Epoch: 270 || 0.41897469758987427\n",
      "====> Epoch: 280 || 0.4527134299278259\n",
      "====> Epoch: 290 || 0.4042868912220001\n",
      "====> Epoch: 300 || 0.4330745041370392\n",
      "====> Epoch: 310 || 0.44621092081069946\n",
      "====> Epoch: 320 || 0.4150562584400177\n",
      "====> Epoch: 330 || 0.3603501617908478\n",
      "====> Epoch: 340 || 0.39940840005874634\n",
      "====> Epoch: 350 || 0.4265647530555725\n",
      "====> Epoch: 360 || 0.3978925049304962\n",
      "====> Epoch: 370 || 0.42582687735557556\n",
      "====> Epoch: 380 || 0.4261152744293213\n",
      "====> Epoch: 390 || 0.4298822283744812\n",
      "====> Epoch: 400 || 0.4414408504962921\n",
      "====> Epoch: 410 || 0.3736182749271393\n",
      "====> Epoch: 420 || 0.3780660927295685\n",
      "====> Epoch: 430 || 0.4095444977283478\n",
      "====> Epoch: 440 || 0.42080944776535034\n",
      "====> Epoch: 450 || 0.4168647825717926\n",
      "====> Epoch: 460 || 0.3923683166503906\n",
      "====> Epoch: 470 || 0.4285748600959778\n",
      "====> Epoch: 480 || 0.4614524841308594\n",
      "====> Epoch: 490 || 0.4416845440864563\n",
      "====> Epoch: 500 || 0.4077506363391876\n",
      "====> Epoch: 510 || 0.3841198682785034\n",
      "====> Epoch: 520 || 0.413532018661499\n",
      "====> Epoch: 530 || 0.4629996716976166\n",
      "====> Epoch: 540 || 0.37779584527015686\n",
      "====> Epoch: 550 || 0.3932826817035675\n",
      "====> Epoch: 560 || 0.42053475975990295\n",
      "====> Epoch: 570 || 0.4127426743507385\n",
      "====> Epoch: 580 || 0.47089603543281555\n",
      "====> Epoch: 590 || 0.39793866872787476\n",
      "====> Epoch: 600 || 0.37593862414360046\n",
      "====> Epoch: 610 || 0.4927254021167755\n",
      "====> Epoch: 620 || 0.4122471511363983\n",
      "====> Epoch: 630 || 0.3734842836856842\n",
      "====> Epoch: 640 || 0.40261363983154297\n",
      "====> Epoch: 650 || 0.3797494173049927\n",
      "====> Epoch: 660 || 0.40120819211006165\n",
      "====> Epoch: 670 || 0.3812292814254761\n",
      "====> Epoch: 680 || 0.4327891170978546\n",
      "====> Epoch: 690 || 0.3847178816795349\n",
      "====> Epoch: 700 || 0.43417680263519287\n",
      "====> Epoch: 710 || 0.3737294375896454\n",
      "====> Epoch: 720 || 0.3841664791107178\n",
      "====> Epoch: 730 || 0.36259549856185913\n",
      "====> Epoch: 740 || 0.3969312608242035\n",
      "====> Epoch: 750 || 0.41263100504875183\n",
      "====> Epoch: 760 || 0.3951859474182129\n",
      "====> Epoch: 770 || 0.4090858995914459\n",
      "====> Epoch: 780 || 0.41769832372665405\n",
      "====> Epoch: 790 || 0.4050036072731018\n",
      "====> Epoch: 800 || 0.3889845609664917\n",
      "====> Epoch: 810 || 0.3926600217819214\n",
      "====> Epoch: 820 || 0.4190354645252228\n",
      "====> Epoch: 830 || 0.38657641410827637\n",
      "====> Epoch: 840 || 0.4174971580505371\n",
      "====> Epoch: 850 || 0.40897995233535767\n",
      "====> Epoch: 860 || 0.37425968050956726\n",
      "====> Epoch: 870 || 0.3806009888648987\n",
      "====> Epoch: 880 || 0.4196621775627136\n",
      "====> Epoch: 890 || 0.36276471614837646\n",
      "====> Epoch: 900 || 0.4332427382469177\n",
      "====> Epoch: 910 || 0.40352576971054077\n",
      "====> Epoch: 920 || 0.39144232869148254\n",
      "====> Epoch: 930 || 0.3650929629802704\n",
      "====> Epoch: 940 || 0.3662548065185547\n",
      "====> Epoch: 950 || 0.38327476382255554\n",
      "====> Epoch: 960 || 0.3983727991580963\n",
      "====> Epoch: 970 || 0.4147070348262787\n",
      "====> Epoch: 980 || 0.4028657376766205\n",
      "====> Epoch: 990 || 0.41019532084465027\n",
      "====> Epoch: 1000 || 0.37110230326652527\n",
      "====> Epoch: 1010 || 0.4152294099330902\n",
      "====> Epoch: 1020 || 0.3923919200897217\n",
      "====> Epoch: 1030 || 0.41663888096809387\n",
      "====> Epoch: 1040 || 0.4421481192111969\n",
      "====> Epoch: 1050 || 0.3853934407234192\n",
      "====> Epoch: 1060 || 0.38611075282096863\n",
      "====> Epoch: 1070 || 0.3865514397621155\n",
      "====> Epoch: 1080 || 0.37096574902534485\n",
      "====> Epoch: 1090 || 0.3926456868648529\n",
      "====> Epoch: 1100 || 0.38931334018707275\n",
      "====> Epoch: 1110 || 0.4105288088321686\n",
      "====> Epoch: 1120 || 0.39113521575927734\n",
      "====> Epoch: 1130 || 0.41839835047721863\n",
      "====> Epoch: 1140 || 0.3669161796569824\n",
      "====> Epoch: 1150 || 0.3844916820526123\n",
      "====> Epoch: 1160 || 0.3926362991333008\n",
      "====> Epoch: 1170 || 0.3582760691642761\n",
      "====> Epoch: 1180 || 0.41602084040641785\n",
      "====> Epoch: 1190 || 0.3906376361846924\n",
      "====> Epoch: 1200 || 0.36223307251930237\n",
      "====> Epoch: 1210 || 0.39409440755844116\n",
      "====> Epoch: 1220 || 0.3488205075263977\n",
      "====> Epoch: 1230 || 0.3992610573768616\n",
      "====> Epoch: 1240 || 0.4054659307003021\n",
      "====> Epoch: 1250 || 0.41292548179626465\n",
      "====> Epoch: 1260 || 0.41529688239097595\n",
      "====> Epoch: 1270 || 0.388592928647995\n",
      "====> Epoch: 1280 || 0.35115906596183777\n",
      "====> Epoch: 1290 || 0.3518730700016022\n",
      "====> Epoch: 1300 || 0.37279462814331055\n",
      "====> Epoch: 1310 || 0.3508428931236267\n",
      "====> Epoch: 1320 || 0.3365510106086731\n",
      "====> Epoch: 1330 || 0.3522864878177643\n",
      "====> Epoch: 1340 || 0.3877369165420532\n",
      "====> Epoch: 1350 || 0.3522575795650482\n",
      "====> Epoch: 1360 || 0.3945784568786621\n",
      "====> Epoch: 1370 || 0.39264899492263794\n",
      "====> Epoch: 1380 || 0.37907639145851135\n",
      "====> Epoch: 1390 || 0.3942318558692932\n",
      "====> Epoch: 1400 || 0.35735851526260376\n",
      "====> Epoch: 1410 || 0.4093066453933716\n",
      "====> Epoch: 1420 || 0.3784526288509369\n",
      "====> Epoch: 1430 || 0.3973233103752136\n",
      "====> Epoch: 1440 || 0.3784235119819641\n",
      "====> Epoch: 1450 || 0.3585667908191681\n",
      "====> Epoch: 1460 || 0.3730280101299286\n",
      "====> Epoch: 1470 || 0.405634343624115\n",
      "====> Epoch: 1480 || 0.4350280165672302\n",
      "====> Epoch: 1490 || 0.40722909569740295\n",
      "====> Epoch: 1500 || 0.38264477252960205\n",
      "====> Epoch: 1510 || 0.3588648736476898\n",
      "====> Epoch: 1520 || 0.403368204832077\n",
      "====> Epoch: 1530 || 0.36546120047569275\n",
      "====> Epoch: 1540 || 0.36218154430389404\n",
      "====> Epoch: 1550 || 0.36258062720298767\n",
      "====> Epoch: 1560 || 0.37831389904022217\n",
      "====> Epoch: 1570 || 0.3998904824256897\n",
      "====> Epoch: 1580 || 0.34388700127601624\n",
      "====> Epoch: 1590 || 0.37151455879211426\n",
      "====> Epoch: 1600 || 0.36323845386505127\n",
      "====> Epoch: 1610 || 0.3692968487739563\n",
      "====> Epoch: 1620 || 0.34661629796028137\n",
      "====> Epoch: 1630 || 0.38178664445877075\n",
      "====> Epoch: 1640 || 0.3893885612487793\n",
      "====> Epoch: 1650 || 0.37051132321357727\n",
      "====> Epoch: 1660 || 0.37959903478622437\n",
      "====> Epoch: 1670 || 0.3180103600025177\n",
      "====> Epoch: 1680 || 0.3910474181175232\n",
      "====> Epoch: 1690 || 0.346210777759552\n",
      "====> Epoch: 1700 || 0.38957351446151733\n",
      "====> Epoch: 1710 || 0.3582400977611542\n",
      "====> Epoch: 1720 || 0.3583902418613434\n",
      "====> Epoch: 1730 || 0.3645004332065582\n",
      "====> Epoch: 1740 || 0.3743475377559662\n",
      "====> Epoch: 1750 || 0.3275996446609497\n",
      "====> Epoch: 1760 || 0.3935281038284302\n",
      "====> Epoch: 1770 || 0.37612229585647583\n",
      "====> Epoch: 1780 || 0.3364933431148529\n",
      "====> Epoch: 1790 || 0.37428227066993713\n",
      "====> Epoch: 1800 || 0.3882972002029419\n",
      "====> Epoch: 1810 || 0.3376835584640503\n",
      "====> Epoch: 1820 || 0.339668333530426\n",
      "====> Epoch: 1830 || 0.37944403290748596\n",
      "====> Epoch: 1840 || 0.4114561080932617\n",
      "====> Epoch: 1850 || 0.3501182198524475\n",
      "====> Epoch: 1860 || 0.32023143768310547\n",
      "====> Epoch: 1870 || 0.39755186438560486\n",
      "====> Epoch: 1880 || 0.3402402102947235\n",
      "====> Epoch: 1890 || 0.3359454274177551\n",
      "====> Epoch: 1900 || 0.33202528953552246\n",
      "====> Epoch: 1910 || 0.4035351872444153\n",
      "====> Epoch: 1920 || 0.336472749710083\n",
      "====> Epoch: 1930 || 0.37675002217292786\n",
      "====> Epoch: 1940 || 0.3595312833786011\n",
      "====> Epoch: 1950 || 0.33358052372932434\n",
      "====> Epoch: 1960 || 0.3370647728443146\n",
      "====> Epoch: 1970 || 0.41218969225883484\n",
      "====> Epoch: 1980 || 0.36672329902648926\n",
      "====> Epoch: 1990 || 0.331317663192749\n",
      "====> Epoch: 2000 || 0.3418937027454376\n",
      "====> Epoch: 2010 || 0.3469794988632202\n",
      "====> Epoch: 2020 || 0.3110601603984833\n",
      "====> Epoch: 2030 || 0.3192591369152069\n",
      "====> Epoch: 2040 || 0.34477534890174866\n",
      "====> Epoch: 2050 || 0.41699230670928955\n",
      "====> Epoch: 2060 || 0.3182441294193268\n",
      "====> Epoch: 2070 || 0.37536922097206116\n",
      "====> Epoch: 2080 || 0.3946954309940338\n",
      "====> Epoch: 2090 || 0.3375704288482666\n",
      "====> Epoch: 2100 || 0.33608412742614746\n",
      "====> Epoch: 2110 || 0.32917320728302\n",
      "====> Epoch: 2120 || 0.339121550321579\n",
      "====> Epoch: 2130 || 0.37338122725486755\n",
      "====> Epoch: 2140 || 0.3593715727329254\n",
      "====> Epoch: 2150 || 0.37044060230255127\n",
      "====> Epoch: 2160 || 0.35646265745162964\n",
      "====> Epoch: 2170 || 0.34780216217041016\n",
      "====> Epoch: 2180 || 0.39095497131347656\n",
      "====> Epoch: 2190 || 0.403956800699234\n",
      "====> Epoch: 2200 || 0.3359822630882263\n",
      "====> Epoch: 2210 || 0.38490593433380127\n",
      "====> Epoch: 2220 || 0.3502109944820404\n",
      "====> Epoch: 2230 || 0.3489988446235657\n",
      "====> Epoch: 2240 || 0.3700346350669861\n",
      "====> Epoch: 2250 || 0.3661043643951416\n",
      "====> Epoch: 2260 || 0.35019779205322266\n",
      "====> Epoch: 2270 || 0.3598306477069855\n",
      "====> Epoch: 2280 || 0.40356388688087463\n",
      "====> Epoch: 2290 || 0.35823819041252136\n",
      "====> Epoch: 2300 || 0.3339096009731293\n",
      "====> Epoch: 2310 || 0.32560572028160095\n",
      "====> Epoch: 2320 || 0.3484269678592682\n",
      "====> Epoch: 2330 || 0.382156640291214\n",
      "====> Epoch: 2340 || 0.3297722339630127\n",
      "====> Epoch: 2350 || 0.3318169116973877\n",
      "====> Epoch: 2360 || 0.3524853587150574\n",
      "====> Epoch: 2370 || 0.3701070249080658\n",
      "====> Epoch: 2380 || 0.35123443603515625\n",
      "====> Epoch: 2390 || 0.42748716473579407\n",
      "====> Epoch: 2400 || 0.37035590410232544\n",
      "====> Epoch: 2410 || 0.3711586892604828\n",
      "====> Epoch: 2420 || 0.3771984577178955\n",
      "====> Epoch: 2430 || 0.3439346253871918\n",
      "====> Epoch: 2440 || 0.37947455048561096\n",
      "====> Epoch: 2450 || 0.31810465455055237\n",
      "====> Epoch: 2460 || 0.38012316823005676\n",
      "====> Epoch: 2470 || 0.33706849813461304\n",
      "====> Epoch: 2480 || 0.363366037607193\n",
      "====> Epoch: 2490 || 0.34461233019828796\n",
      "====> Epoch: 2500 || 0.34462645649909973\n",
      "====> Epoch: 2510 || 0.37085190415382385\n",
      "====> Epoch: 2520 || 0.3661719858646393\n",
      "====> Epoch: 2530 || 0.4226958751678467\n",
      "====> Epoch: 2540 || 0.3606364130973816\n",
      "====> Epoch: 2550 || 0.3910267651081085\n",
      "====> Epoch: 2560 || 0.3552025854587555\n",
      "====> Epoch: 2570 || 0.35418274998664856\n",
      "====> Epoch: 2580 || 0.338639497756958\n",
      "====> Epoch: 2590 || 0.4145677387714386\n",
      "====> Epoch: 2600 || 0.32142555713653564\n",
      "====> Epoch: 2610 || 0.34329545497894287\n",
      "====> Epoch: 2620 || 0.4127259850502014\n",
      "====> Epoch: 2630 || 0.3851766586303711\n",
      "====> Epoch: 2640 || 0.34412848949432373\n",
      "====> Epoch: 2650 || 0.3356156647205353\n",
      "====> Epoch: 2660 || 0.3318004012107849\n",
      "====> Epoch: 2670 || 0.35704073309898376\n",
      "====> Epoch: 2680 || 0.36897557973861694\n",
      "====> Epoch: 2690 || 0.32947099208831787\n",
      "====> Epoch: 2700 || 0.35791048407554626\n",
      "====> Epoch: 2710 || 0.3519746959209442\n",
      "====> Epoch: 2720 || 0.3569963574409485\n",
      "====> Epoch: 2730 || 0.3500189483165741\n",
      "====> Epoch: 2740 || 0.3806881308555603\n",
      "====> Epoch: 2750 || 0.32834696769714355\n",
      "====> Epoch: 2760 || 0.37584641575813293\n",
      "====> Epoch: 2770 || 0.32990971207618713\n",
      "====> Epoch: 2780 || 0.36306846141815186\n",
      "====> Epoch: 2790 || 0.3473898470401764\n",
      "====> Epoch: 2800 || 0.34743863344192505\n",
      "====> Epoch: 2810 || 0.3387528359889984\n",
      "====> Epoch: 2820 || 0.38935697078704834\n",
      "====> Epoch: 2830 || 0.3611736297607422\n",
      "====> Epoch: 2840 || 0.33279097080230713\n",
      "====> Epoch: 2850 || 0.3722588121891022\n",
      "====> Epoch: 2860 || 0.35728543996810913\n",
      "====> Epoch: 2870 || 0.3277594745159149\n",
      "====> Epoch: 2880 || 0.34272119402885437\n",
      "====> Epoch: 2890 || 0.33011293411254883\n",
      "====> Epoch: 2900 || 0.33858078718185425\n",
      "====> Epoch: 2910 || 0.33981162309646606\n",
      "====> Epoch: 2920 || 0.36218714714050293\n",
      "====> Epoch: 2930 || 0.3440372347831726\n",
      "====> Epoch: 2940 || 0.3644007444381714\n",
      "====> Epoch: 2950 || 0.34824854135513306\n",
      "====> Epoch: 2960 || 0.39045459032058716\n",
      "====> Epoch: 2970 || 0.3463321924209595\n",
      "====> Epoch: 2980 || 0.35788092017173767\n",
      "====> Epoch: 2990 || 0.354665607213974\n",
      "====> Epoch: 2999 || 0.30090925097465515\n",
      "[2023-10-13 12:24:24] Evaluate_01: epoch = 1000 train time = 98 s train loss = 0.004649 train acc = 1.0000, test acc = 0.4632\n"
     ]
    }
   ],
   "source": [
    "model = CVAE(d = hidden, k=k, num_channels=num_channels).to(device) \n",
    "\n",
    "# 训练原图训\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 10 if args_cave.dataset == 'imagenet' else 30, 0.5,)\n",
    "\n",
    "epochs = 3000\n",
    "for epoch in range(epochs):\n",
    "\n",
    "\n",
    "    random_indices = np.random.choice(len(img_real_train), batch, replace=False)\n",
    "\n",
    "# 使用随机选择的索引来获取数据并改变形状\n",
    "    batch_img = img_real_train[random_indices].reshape((batch, 3, 32, 32)).to(device)\n",
    "    # batch_syn = img_syn[random_indices].reshape((batch, 3, 32, 32)).to(device) \n",
    "    # batch_img_y = label_real_train[c*batch:(c+1)*batch].to(device) \n",
    "        \n",
    "    outputs = model(batch_img)\n",
    "    \n",
    "    loss = model.loss_function(batch_img, *outputs)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "        # logs['loss'].append(loss.item())\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == epochs -1:\n",
    "        # print(\"Epoch {:02d}/{:02d} , Loss {:9.4f}\".format(\n",
    "        #     epoch, epochs,  loss.item()))\n",
    "        print(\"====> Epoch: {} || {}\".format(epoch, loss.item()))\n",
    "        \n",
    "with torch.no_grad():\n",
    "  output = model(img_real_test.to(device))\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[0]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 || 2.224699020385742\n",
      "====> Epoch: 10 || 0.9188709259033203\n",
      "====> Epoch: 20 || 0.7404829859733582\n",
      "====> Epoch: 30 || 0.6518579721450806\n",
      "====> Epoch: 40 || 0.640002429485321\n",
      "====> Epoch: 50 || 0.5574132204055786\n",
      "====> Epoch: 60 || 0.5992719531059265\n",
      "====> Epoch: 70 || 0.5128530859947205\n",
      "====> Epoch: 80 || 0.529251217842102\n",
      "====> Epoch: 90 || 0.4890080988407135\n",
      "====> Epoch: 100 || 0.5311537981033325\n",
      "====> Epoch: 110 || 0.4657144844532013\n",
      "====> Epoch: 120 || 0.5117236971855164\n",
      "====> Epoch: 130 || 0.501807451248169\n",
      "====> Epoch: 140 || 0.47017645835876465\n",
      "====> Epoch: 150 || 0.4720045328140259\n",
      "====> Epoch: 160 || 0.4383760392665863\n",
      "====> Epoch: 170 || 0.4994126856327057\n",
      "====> Epoch: 180 || 0.46501556038856506\n",
      "====> Epoch: 190 || 0.4902753233909607\n",
      "====> Epoch: 200 || 0.40907248854637146\n",
      "====> Epoch: 210 || 0.4566342830657959\n",
      "====> Epoch: 220 || 0.45014289021492004\n",
      "====> Epoch: 230 || 0.45091938972473145\n",
      "====> Epoch: 240 || 0.4700677692890167\n",
      "====> Epoch: 250 || 0.40921589732170105\n",
      "====> Epoch: 260 || 0.4108089804649353\n",
      "====> Epoch: 270 || 0.4698663353919983\n",
      "====> Epoch: 280 || 0.4468250870704651\n",
      "====> Epoch: 290 || 0.4292556941509247\n",
      "====> Epoch: 300 || 0.4231142997741699\n",
      "====> Epoch: 310 || 0.46392422914505005\n",
      "====> Epoch: 320 || 0.4095323085784912\n",
      "====> Epoch: 330 || 0.45026642084121704\n",
      "====> Epoch: 340 || 0.42846623063087463\n",
      "====> Epoch: 350 || 0.4336239993572235\n",
      "====> Epoch: 360 || 0.4177227318286896\n",
      "====> Epoch: 370 || 0.4437223970890045\n",
      "====> Epoch: 380 || 0.4793400764465332\n",
      "====> Epoch: 390 || 0.4107884168624878\n",
      "====> Epoch: 400 || 0.48985207080841064\n",
      "====> Epoch: 410 || 0.38983994722366333\n",
      "====> Epoch: 420 || 0.40871357917785645\n",
      "====> Epoch: 430 || 0.45605939626693726\n",
      "====> Epoch: 440 || 0.4532996416091919\n",
      "====> Epoch: 450 || 0.38335829973220825\n",
      "====> Epoch: 460 || 0.4425348937511444\n",
      "====> Epoch: 470 || 0.3956032395362854\n",
      "====> Epoch: 480 || 0.4233319163322449\n",
      "====> Epoch: 490 || 0.43119534850120544\n",
      "====> Epoch: 500 || 0.39505496621131897\n",
      "====> Epoch: 510 || 0.4063393771648407\n",
      "====> Epoch: 520 || 0.4135163724422455\n",
      "====> Epoch: 530 || 0.4164440631866455\n",
      "====> Epoch: 540 || 0.43141043186187744\n",
      "====> Epoch: 550 || 0.427862286567688\n",
      "====> Epoch: 560 || 0.41331538558006287\n",
      "====> Epoch: 570 || 0.3934735059738159\n",
      "====> Epoch: 580 || 0.415821373462677\n",
      "====> Epoch: 590 || 0.40686655044555664\n",
      "====> Epoch: 600 || 0.4136829376220703\n",
      "====> Epoch: 610 || 0.4417214095592499\n",
      "====> Epoch: 620 || 0.3794896602630615\n",
      "====> Epoch: 630 || 0.42220160365104675\n",
      "====> Epoch: 640 || 0.47499164938926697\n",
      "====> Epoch: 650 || 0.3919075131416321\n",
      "====> Epoch: 660 || 0.39764270186424255\n",
      "====> Epoch: 670 || 0.4149516224861145\n",
      "====> Epoch: 680 || 0.3901382088661194\n",
      "====> Epoch: 690 || 0.42025652527809143\n",
      "====> Epoch: 700 || 0.4000832140445709\n",
      "====> Epoch: 710 || 0.4479514956474304\n",
      "====> Epoch: 720 || 0.39026087522506714\n",
      "====> Epoch: 730 || 0.40019017457962036\n",
      "====> Epoch: 740 || 0.44205397367477417\n",
      "====> Epoch: 750 || 0.3847653567790985\n",
      "====> Epoch: 760 || 0.4024757146835327\n",
      "====> Epoch: 770 || 0.4081035256385803\n",
      "====> Epoch: 780 || 0.3735114336013794\n",
      "====> Epoch: 790 || 0.41895031929016113\n",
      "====> Epoch: 800 || 0.400871217250824\n",
      "====> Epoch: 810 || 0.40502581000328064\n",
      "====> Epoch: 820 || 0.38565540313720703\n",
      "====> Epoch: 830 || 0.38674476742744446\n",
      "====> Epoch: 840 || 0.4147554934024811\n",
      "====> Epoch: 850 || 0.39539074897766113\n",
      "====> Epoch: 860 || 0.4316462576389313\n",
      "====> Epoch: 870 || 0.41740864515304565\n",
      "====> Epoch: 880 || 0.4014485478401184\n",
      "====> Epoch: 890 || 0.40137407183647156\n",
      "====> Epoch: 900 || 0.3992439806461334\n",
      "====> Epoch: 910 || 0.4454900026321411\n",
      "====> Epoch: 920 || 0.48443976044654846\n",
      "====> Epoch: 930 || 0.41116055846214294\n",
      "====> Epoch: 940 || 0.3912622928619385\n",
      "====> Epoch: 950 || 0.37530753016471863\n",
      "====> Epoch: 960 || 0.3943376839160919\n",
      "====> Epoch: 970 || 0.39223235845565796\n",
      "====> Epoch: 980 || 0.41626301407814026\n",
      "====> Epoch: 990 || 0.4148385226726532\n",
      "====> Epoch: 1000 || 0.3756265342235565\n",
      "====> Epoch: 1010 || 0.37558797001838684\n",
      "====> Epoch: 1020 || 0.3309673070907593\n",
      "====> Epoch: 1030 || 0.3523348569869995\n",
      "====> Epoch: 1040 || 0.409819632768631\n",
      "====> Epoch: 1050 || 0.4030575752258301\n",
      "====> Epoch: 1060 || 0.39595431089401245\n",
      "====> Epoch: 1070 || 0.3830631673336029\n",
      "====> Epoch: 1080 || 0.365697979927063\n",
      "====> Epoch: 1090 || 0.42558813095092773\n",
      "====> Epoch: 1100 || 0.43590599298477173\n",
      "====> Epoch: 1110 || 0.4089455306529999\n",
      "====> Epoch: 1120 || 0.3667827844619751\n",
      "====> Epoch: 1130 || 0.42962297797203064\n",
      "====> Epoch: 1140 || 0.3834172487258911\n",
      "====> Epoch: 1150 || 0.4176025390625\n",
      "====> Epoch: 1160 || 0.4011788070201874\n",
      "====> Epoch: 1170 || 0.41288506984710693\n",
      "====> Epoch: 1180 || 0.36573171615600586\n",
      "====> Epoch: 1190 || 0.42219239473342896\n",
      "====> Epoch: 1200 || 0.42541801929473877\n",
      "====> Epoch: 1210 || 0.3862832486629486\n",
      "====> Epoch: 1220 || 0.34137994050979614\n",
      "====> Epoch: 1230 || 0.40470099449157715\n",
      "====> Epoch: 1240 || 0.4024827480316162\n",
      "====> Epoch: 1250 || 0.40164780616760254\n",
      "====> Epoch: 1260 || 0.3941079378128052\n",
      "====> Epoch: 1270 || 0.38557812571525574\n",
      "====> Epoch: 1280 || 0.3749408721923828\n",
      "====> Epoch: 1290 || 0.3587155044078827\n",
      "====> Epoch: 1300 || 0.37737709283828735\n",
      "====> Epoch: 1310 || 0.4237629175186157\n",
      "====> Epoch: 1320 || 0.34697338938713074\n",
      "====> Epoch: 1330 || 0.3899219334125519\n",
      "====> Epoch: 1340 || 0.3792208135128021\n",
      "====> Epoch: 1350 || 0.3730047643184662\n",
      "====> Epoch: 1360 || 0.36334314942359924\n",
      "====> Epoch: 1370 || 0.3816995620727539\n",
      "====> Epoch: 1380 || 0.35168424248695374\n",
      "====> Epoch: 1390 || 0.4165131151676178\n",
      "====> Epoch: 1400 || 0.3681187629699707\n",
      "====> Epoch: 1410 || 0.36787354946136475\n",
      "====> Epoch: 1420 || 0.4152566194534302\n",
      "====> Epoch: 1430 || 0.4215961992740631\n",
      "====> Epoch: 1440 || 0.38428691029548645\n",
      "====> Epoch: 1450 || 0.38057294487953186\n",
      "====> Epoch: 1460 || 0.3908293545246124\n",
      "====> Epoch: 1470 || 0.42942100763320923\n",
      "====> Epoch: 1480 || 0.3755771517753601\n",
      "====> Epoch: 1490 || 0.40307605266571045\n",
      "====> Epoch: 1500 || 0.415181428194046\n",
      "====> Epoch: 1510 || 0.379036009311676\n",
      "====> Epoch: 1520 || 0.4231301248073578\n",
      "====> Epoch: 1530 || 0.3843427300453186\n",
      "====> Epoch: 1540 || 0.4019503593444824\n",
      "====> Epoch: 1550 || 0.36538997292518616\n",
      "====> Epoch: 1560 || 0.37459295988082886\n",
      "====> Epoch: 1570 || 0.3578471541404724\n",
      "====> Epoch: 1580 || 0.385719895362854\n",
      "====> Epoch: 1590 || 0.3712775409221649\n",
      "====> Epoch: 1600 || 0.3187507092952728\n",
      "====> Epoch: 1610 || 0.4096517562866211\n",
      "====> Epoch: 1620 || 0.44489869475364685\n",
      "====> Epoch: 1630 || 0.40426161885261536\n",
      "====> Epoch: 1640 || 0.41385477781295776\n",
      "====> Epoch: 1650 || 0.4207082688808441\n",
      "====> Epoch: 1660 || 0.33785274624824524\n",
      "====> Epoch: 1670 || 0.3840630352497101\n",
      "====> Epoch: 1680 || 0.3591236472129822\n",
      "====> Epoch: 1690 || 0.35479867458343506\n",
      "====> Epoch: 1700 || 0.3644971549510956\n",
      "====> Epoch: 1710 || 0.3558303713798523\n",
      "====> Epoch: 1720 || 0.3695679306983948\n",
      "====> Epoch: 1730 || 0.3342207670211792\n",
      "====> Epoch: 1740 || 0.4124864339828491\n",
      "====> Epoch: 1750 || 0.35040730237960815\n",
      "====> Epoch: 1760 || 0.359014630317688\n",
      "====> Epoch: 1770 || 0.3625023365020752\n",
      "====> Epoch: 1780 || 0.3593616485595703\n",
      "====> Epoch: 1790 || 0.3270586133003235\n",
      "====> Epoch: 1800 || 0.37868136167526245\n",
      "====> Epoch: 1810 || 0.35169467329978943\n",
      "====> Epoch: 1820 || 0.3448336720466614\n",
      "====> Epoch: 1830 || 0.36006662249565125\n",
      "====> Epoch: 1840 || 0.36441513895988464\n",
      "====> Epoch: 1850 || 0.38781142234802246\n",
      "====> Epoch: 1860 || 0.3668282926082611\n",
      "====> Epoch: 1870 || 0.3407585322856903\n",
      "====> Epoch: 1880 || 0.3615652918815613\n",
      "====> Epoch: 1890 || 0.3751142919063568\n",
      "====> Epoch: 1900 || 0.36583101749420166\n",
      "====> Epoch: 1910 || 0.35538631677627563\n",
      "====> Epoch: 1920 || 0.35297566652297974\n",
      "====> Epoch: 1930 || 0.351644366979599\n",
      "====> Epoch: 1940 || 0.3717838525772095\n",
      "====> Epoch: 1950 || 0.3622855544090271\n",
      "====> Epoch: 1960 || 0.32817476987838745\n",
      "====> Epoch: 1970 || 0.36181139945983887\n",
      "====> Epoch: 1980 || 0.4028705358505249\n",
      "====> Epoch: 1990 || 0.3861314356327057\n",
      "====> Epoch: 2000 || 0.3609360158443451\n",
      "====> Epoch: 2010 || 0.34315815567970276\n",
      "====> Epoch: 2020 || 0.32457977533340454\n",
      "====> Epoch: 2030 || 0.34355491399765015\n",
      "====> Epoch: 2040 || 0.35533004999160767\n",
      "====> Epoch: 2050 || 0.3746740520000458\n",
      "====> Epoch: 2060 || 0.44327986240386963\n",
      "====> Epoch: 2070 || 0.32314231991767883\n",
      "====> Epoch: 2080 || 0.3421843647956848\n",
      "====> Epoch: 2090 || 0.36265313625335693\n",
      "====> Epoch: 2100 || 0.4205363094806671\n",
      "====> Epoch: 2110 || 0.34474310278892517\n",
      "====> Epoch: 2120 || 0.4149245023727417\n",
      "====> Epoch: 2130 || 0.3822242319583893\n",
      "====> Epoch: 2140 || 0.38446882367134094\n",
      "====> Epoch: 2150 || 0.42197561264038086\n",
      "====> Epoch: 2160 || 0.37144848704338074\n",
      "====> Epoch: 2170 || 0.3536350727081299\n",
      "====> Epoch: 2180 || 0.32275062799453735\n",
      "====> Epoch: 2190 || 0.33377736806869507\n",
      "====> Epoch: 2200 || 0.36117690801620483\n",
      "====> Epoch: 2210 || 0.3645438551902771\n",
      "====> Epoch: 2220 || 0.38131141662597656\n",
      "====> Epoch: 2230 || 0.3275556266307831\n",
      "====> Epoch: 2240 || 0.3570575714111328\n",
      "====> Epoch: 2250 || 0.4356297254562378\n",
      "====> Epoch: 2260 || 0.40812236070632935\n",
      "====> Epoch: 2270 || 0.35771650075912476\n",
      "====> Epoch: 2280 || 0.37526649236679077\n",
      "====> Epoch: 2290 || 0.3893114924430847\n",
      "====> Epoch: 2300 || 0.38480010628700256\n",
      "====> Epoch: 2310 || 0.3623957335948944\n",
      "====> Epoch: 2320 || 0.35555097460746765\n",
      "====> Epoch: 2330 || 0.3885176181793213\n",
      "====> Epoch: 2340 || 0.3702292740345001\n",
      "====> Epoch: 2350 || 0.33991098403930664\n",
      "====> Epoch: 2360 || 0.3556121289730072\n",
      "====> Epoch: 2370 || 0.3449658453464508\n",
      "====> Epoch: 2380 || 0.33752891421318054\n",
      "====> Epoch: 2390 || 0.4031577408313751\n",
      "====> Epoch: 2400 || 0.39208099246025085\n",
      "====> Epoch: 2410 || 0.4150179624557495\n",
      "====> Epoch: 2420 || 0.36482974886894226\n",
      "====> Epoch: 2430 || 0.38905081152915955\n",
      "====> Epoch: 2440 || 0.34498223662376404\n",
      "====> Epoch: 2450 || 0.3853569030761719\n",
      "====> Epoch: 2460 || 0.37565740942955017\n",
      "====> Epoch: 2470 || 0.3489953875541687\n",
      "====> Epoch: 2480 || 0.3612091839313507\n",
      "====> Epoch: 2490 || 0.3639596402645111\n",
      "====> Epoch: 2500 || 0.38978809118270874\n",
      "====> Epoch: 2510 || 0.3434261083602905\n",
      "====> Epoch: 2520 || 0.40108203887939453\n",
      "====> Epoch: 2530 || 0.3775562047958374\n",
      "====> Epoch: 2540 || 0.3697280287742615\n",
      "====> Epoch: 2550 || 0.37524858117103577\n",
      "====> Epoch: 2560 || 0.3835639953613281\n",
      "====> Epoch: 2570 || 0.35724133253097534\n",
      "====> Epoch: 2580 || 0.34717991948127747\n",
      "====> Epoch: 2590 || 0.36896929144859314\n",
      "====> Epoch: 2600 || 0.3922446072101593\n",
      "====> Epoch: 2610 || 0.3481569290161133\n",
      "====> Epoch: 2620 || 0.38131183385849\n",
      "====> Epoch: 2630 || 0.35079920291900635\n",
      "====> Epoch: 2640 || 0.37769222259521484\n",
      "====> Epoch: 2650 || 0.36885011196136475\n",
      "====> Epoch: 2660 || 0.3903263509273529\n",
      "====> Epoch: 2670 || 0.33112508058547974\n",
      "====> Epoch: 2680 || 0.37424612045288086\n",
      "====> Epoch: 2690 || 0.35723328590393066\n",
      "====> Epoch: 2700 || 0.3682282567024231\n",
      "====> Epoch: 2710 || 0.35472536087036133\n",
      "====> Epoch: 2720 || 0.35712558031082153\n",
      "====> Epoch: 2730 || 0.3752223551273346\n",
      "====> Epoch: 2740 || 0.356567919254303\n",
      "====> Epoch: 2750 || 0.3439742624759674\n",
      "====> Epoch: 2760 || 0.3610093891620636\n",
      "====> Epoch: 2770 || 0.3742801547050476\n",
      "====> Epoch: 2780 || 0.38374248147010803\n",
      "====> Epoch: 2790 || 0.39469459652900696\n",
      "====> Epoch: 2800 || 0.3985484540462494\n",
      "====> Epoch: 2810 || 0.36556074023246765\n",
      "====> Epoch: 2820 || 0.3880012631416321\n",
      "====> Epoch: 2830 || 0.37535354495048523\n",
      "====> Epoch: 2840 || 0.4364435076713562\n",
      "====> Epoch: 2850 || 0.36865270137786865\n",
      "====> Epoch: 2860 || 0.37998923659324646\n",
      "====> Epoch: 2870 || 0.3786374628543854\n",
      "====> Epoch: 2880 || 0.3778807818889618\n",
      "====> Epoch: 2890 || 0.3775068521499634\n",
      "====> Epoch: 2900 || 0.39519551396369934\n",
      "====> Epoch: 2910 || 0.35498398542404175\n",
      "====> Epoch: 2920 || 0.36984795331954956\n",
      "====> Epoch: 2930 || 0.35897591710090637\n",
      "====> Epoch: 2940 || 0.3275420367717743\n",
      "====> Epoch: 2950 || 0.34514319896698\n",
      "====> Epoch: 2960 || 0.3329337239265442\n",
      "====> Epoch: 2970 || 0.33832281827926636\n",
      "====> Epoch: 2980 || 0.3444744646549225\n",
      "====> Epoch: 2990 || 0.4057973325252533\n",
      "====> Epoch: 2999 || 0.36669468879699707\n",
      "[2023-10-13 12:31:12] Evaluate_01: epoch = 1000 train time = 96 s train loss = 0.003123 train acc = 1.0000, test acc = 0.4733\n"
     ]
    }
   ],
   "source": [
    "model = CVAE(d = hidden, k=k, num_channels=num_channels).to(device) \n",
    "\n",
    "# 样本对训\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 10 if args_cave.dataset == 'imagenet' else 30, 0.5,)\n",
    "\n",
    "epochs = 3000\n",
    "for epoch in range(epochs):\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    random_indices = np.random.choice(len(img_real_train), batch, replace=False)\n",
    "\n",
    "# 使用随机选择的索引来获取数据并改变形状\n",
    "    batch_img = img_real_train[random_indices].reshape((batch, 3, 32, 32)).to(device)\n",
    "    batch_syn = img_syn[random_indices].reshape((batch, 3, 32, 32)).to(device) \n",
    "    # batch_img_y = label_real_train[c*batch:(c+1)*batch].to(device) \n",
    "    \n",
    "    outputs = model(batch_img)\n",
    "    \n",
    "    loss = model.loss_function(batch_syn, *outputs)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "        # logs['loss'].append(loss.item())\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == epochs -1:\n",
    "        # print(\"Epoch {:02d}/{:02d} , Loss {:9.4f}\".format(\n",
    "        #     epoch, epochs,  loss.item()))\n",
    "        print(\"====> Epoch: {} || {}\".format(epoch, loss.item()))\n",
    "        \n",
    "with torch.no_grad():\n",
    "  output = model(img_real_test.to(device))\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[0]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 || 0.35182124376296997\n",
      "====> Epoch: 10 || 0.3487131595611572\n",
      "====> Epoch: 20 || 0.3917742371559143\n",
      "====> Epoch: 30 || 0.37243616580963135\n",
      "====> Epoch: 40 || 0.4066743850708008\n",
      "====> Epoch: 50 || 0.3578777015209198\n",
      "====> Epoch: 60 || 0.37656667828559875\n",
      "====> Epoch: 70 || 0.3317330479621887\n",
      "====> Epoch: 80 || 0.3398778438568115\n",
      "====> Epoch: 90 || 0.3423633277416229\n",
      "====> Epoch: 100 || 0.37219443917274475\n",
      "====> Epoch: 110 || 0.3841681182384491\n",
      "====> Epoch: 120 || 0.35255375504493713\n",
      "====> Epoch: 130 || 0.369001179933548\n",
      "====> Epoch: 140 || 0.3786856532096863\n",
      "====> Epoch: 150 || 0.38036856055259705\n",
      "====> Epoch: 160 || 0.35241803526878357\n",
      "====> Epoch: 170 || 0.3669365346431732\n",
      "====> Epoch: 180 || 0.3631303310394287\n",
      "====> Epoch: 190 || 0.3775741457939148\n",
      "====> Epoch: 200 || 0.3434806764125824\n",
      "====> Epoch: 210 || 0.34137073159217834\n",
      "====> Epoch: 220 || 0.3592779040336609\n",
      "====> Epoch: 230 || 0.410616010427475\n",
      "====> Epoch: 240 || 0.3482930362224579\n",
      "====> Epoch: 250 || 0.3754007816314697\n",
      "====> Epoch: 260 || 0.33983945846557617\n",
      "====> Epoch: 270 || 0.35906168818473816\n",
      "====> Epoch: 280 || 0.3950710594654083\n",
      "====> Epoch: 290 || 0.3539677858352661\n",
      "====> Epoch: 300 || 0.3458711504936218\n",
      "====> Epoch: 310 || 0.3644593060016632\n",
      "====> Epoch: 320 || 0.3267831802368164\n",
      "====> Epoch: 330 || 0.3542864918708801\n",
      "====> Epoch: 340 || 0.335890531539917\n",
      "====> Epoch: 350 || 0.3900485336780548\n",
      "====> Epoch: 360 || 0.3511835038661957\n",
      "====> Epoch: 370 || 0.38926446437835693\n",
      "====> Epoch: 380 || 0.357707142829895\n",
      "====> Epoch: 390 || 0.3309038281440735\n",
      "====> Epoch: 400 || 0.3275149166584015\n",
      "====> Epoch: 410 || 0.38469165563583374\n",
      "====> Epoch: 420 || 0.40691041946411133\n",
      "====> Epoch: 430 || 0.376667857170105\n",
      "====> Epoch: 440 || 0.3479108214378357\n",
      "====> Epoch: 450 || 0.3935113251209259\n",
      "====> Epoch: 460 || 0.37149161100387573\n",
      "====> Epoch: 470 || 0.37473973631858826\n",
      "====> Epoch: 480 || 0.34923622012138367\n",
      "====> Epoch: 490 || 0.3500499427318573\n",
      "====> Epoch: 500 || 0.35866841673851013\n",
      "====> Epoch: 510 || 0.31577277183532715\n",
      "====> Epoch: 520 || 0.3518621325492859\n",
      "====> Epoch: 530 || 0.40268439054489136\n",
      "====> Epoch: 540 || 0.3430599272251129\n",
      "====> Epoch: 550 || 0.3074760437011719\n",
      "====> Epoch: 560 || 0.36478668451309204\n",
      "====> Epoch: 570 || 0.3533983826637268\n",
      "====> Epoch: 580 || 0.3318488299846649\n",
      "====> Epoch: 590 || 0.41602128744125366\n",
      "====> Epoch: 600 || 0.36079633235931396\n",
      "====> Epoch: 610 || 0.35240495204925537\n",
      "====> Epoch: 620 || 0.36166760325431824\n",
      "====> Epoch: 630 || 0.38513150811195374\n",
      "====> Epoch: 640 || 0.3754783272743225\n",
      "====> Epoch: 650 || 0.41027793288230896\n",
      "====> Epoch: 660 || 0.354009747505188\n",
      "====> Epoch: 670 || 0.31883084774017334\n",
      "====> Epoch: 680 || 0.3620854914188385\n",
      "====> Epoch: 690 || 0.36853110790252686\n",
      "====> Epoch: 700 || 0.34665775299072266\n",
      "====> Epoch: 710 || 0.3298531472682953\n",
      "====> Epoch: 720 || 0.33538153767585754\n",
      "====> Epoch: 730 || 0.337384968996048\n",
      "====> Epoch: 740 || 0.3471887707710266\n",
      "====> Epoch: 750 || 0.31617358326911926\n",
      "====> Epoch: 760 || 0.3616148829460144\n",
      "====> Epoch: 770 || 0.32520702481269836\n",
      "====> Epoch: 780 || 0.35268428921699524\n",
      "====> Epoch: 790 || 0.3663494288921356\n",
      "====> Epoch: 800 || 0.38245904445648193\n",
      "====> Epoch: 810 || 0.3691921532154083\n",
      "====> Epoch: 820 || 0.3430428206920624\n",
      "====> Epoch: 830 || 0.37362512946128845\n",
      "====> Epoch: 840 || 0.3465644419193268\n",
      "====> Epoch: 850 || 0.363101989030838\n",
      "====> Epoch: 860 || 0.31364744901657104\n",
      "====> Epoch: 870 || 0.32903018593788147\n",
      "====> Epoch: 880 || 0.3399028480052948\n",
      "====> Epoch: 890 || 0.35198646783828735\n",
      "====> Epoch: 900 || 0.35240450501441956\n",
      "====> Epoch: 910 || 0.3453914523124695\n",
      "====> Epoch: 920 || 0.36433303356170654\n",
      "====> Epoch: 930 || 0.311346173286438\n",
      "====> Epoch: 940 || 0.3320014476776123\n",
      "====> Epoch: 950 || 0.3704979419708252\n",
      "====> Epoch: 960 || 0.3796975016593933\n",
      "====> Epoch: 970 || 0.3511178195476532\n",
      "====> Epoch: 980 || 0.33811306953430176\n",
      "====> Epoch: 990 || 0.3770773112773895\n",
      "====> Epoch: 1000 || 0.35293713212013245\n",
      "====> Epoch: 1010 || 0.34278547763824463\n",
      "====> Epoch: 1020 || 0.4129958152770996\n",
      "====> Epoch: 1030 || 0.40753409266471863\n",
      "====> Epoch: 1040 || 0.34508222341537476\n",
      "====> Epoch: 1050 || 0.33396396040916443\n",
      "====> Epoch: 1060 || 0.33378857374191284\n",
      "====> Epoch: 1070 || 0.35151931643486023\n",
      "====> Epoch: 1080 || 0.3371834456920624\n",
      "====> Epoch: 1090 || 0.3378266394138336\n",
      "====> Epoch: 1100 || 0.36079519987106323\n",
      "====> Epoch: 1110 || 0.3435526192188263\n",
      "====> Epoch: 1120 || 0.38107749819755554\n",
      "====> Epoch: 1130 || 0.33940303325653076\n",
      "====> Epoch: 1140 || 0.36205410957336426\n",
      "====> Epoch: 1150 || 0.34230560064315796\n",
      "====> Epoch: 1160 || 0.37356704473495483\n",
      "====> Epoch: 1170 || 0.36164817214012146\n",
      "====> Epoch: 1180 || 0.3725114166736603\n",
      "====> Epoch: 1190 || 0.3509425222873688\n",
      "====> Epoch: 1200 || 0.3479929566383362\n",
      "====> Epoch: 1210 || 0.35301223397254944\n",
      "====> Epoch: 1220 || 0.3537583351135254\n",
      "====> Epoch: 1230 || 0.3298582136631012\n",
      "====> Epoch: 1240 || 0.3328981399536133\n",
      "====> Epoch: 1250 || 0.3594232499599457\n",
      "====> Epoch: 1260 || 0.3408994674682617\n",
      "====> Epoch: 1270 || 0.41218966245651245\n",
      "====> Epoch: 1280 || 0.33093246817588806\n",
      "====> Epoch: 1290 || 0.3041961193084717\n",
      "====> Epoch: 1300 || 0.33786067366600037\n",
      "====> Epoch: 1310 || 0.420065701007843\n",
      "====> Epoch: 1320 || 0.3653448522090912\n",
      "====> Epoch: 1330 || 0.35845816135406494\n",
      "====> Epoch: 1340 || 0.328220009803772\n",
      "====> Epoch: 1350 || 0.3223596215248108\n",
      "====> Epoch: 1360 || 0.335450679063797\n",
      "====> Epoch: 1370 || 0.3359731137752533\n",
      "====> Epoch: 1380 || 0.34684261679649353\n",
      "====> Epoch: 1390 || 0.29194724559783936\n",
      "====> Epoch: 1400 || 0.371338427066803\n",
      "====> Epoch: 1410 || 0.3608454465866089\n",
      "====> Epoch: 1420 || 0.3528028726577759\n",
      "====> Epoch: 1430 || 0.36195626854896545\n",
      "====> Epoch: 1440 || 0.32823991775512695\n",
      "====> Epoch: 1450 || 0.31412380933761597\n",
      "====> Epoch: 1460 || 0.3639432191848755\n",
      "====> Epoch: 1470 || 0.384665846824646\n",
      "====> Epoch: 1480 || 0.3249530494213104\n",
      "====> Epoch: 1490 || 0.34937581419944763\n",
      "====> Epoch: 1500 || 0.359845370054245\n",
      "====> Epoch: 1510 || 0.33215439319610596\n",
      "====> Epoch: 1520 || 0.3398643732070923\n",
      "====> Epoch: 1530 || 0.32170504331588745\n",
      "====> Epoch: 1540 || 0.36032211780548096\n",
      "====> Epoch: 1550 || 0.33063793182373047\n",
      "====> Epoch: 1560 || 0.3676062226295471\n",
      "====> Epoch: 1570 || 0.35646358132362366\n",
      "====> Epoch: 1580 || 0.3339250981807709\n",
      "====> Epoch: 1590 || 0.35317814350128174\n",
      "====> Epoch: 1600 || 0.355691134929657\n",
      "====> Epoch: 1610 || 0.3278219401836395\n",
      "====> Epoch: 1620 || 0.3984932005405426\n",
      "====> Epoch: 1630 || 0.331074059009552\n",
      "====> Epoch: 1640 || 0.3357156813144684\n",
      "====> Epoch: 1650 || 0.3728819191455841\n",
      "====> Epoch: 1660 || 0.3531784415245056\n",
      "====> Epoch: 1670 || 0.38970649242401123\n",
      "====> Epoch: 1680 || 0.3826947510242462\n",
      "====> Epoch: 1690 || 0.3529299795627594\n",
      "====> Epoch: 1700 || 0.3650714159011841\n",
      "====> Epoch: 1710 || 0.3000158965587616\n",
      "====> Epoch: 1720 || 0.33486178517341614\n",
      "====> Epoch: 1730 || 0.3580581247806549\n",
      "====> Epoch: 1740 || 0.35799217224121094\n",
      "====> Epoch: 1750 || 0.3720518946647644\n",
      "====> Epoch: 1760 || 0.32638147473335266\n",
      "====> Epoch: 1770 || 0.4031486511230469\n",
      "====> Epoch: 1780 || 0.32620927691459656\n",
      "====> Epoch: 1790 || 0.33183905482292175\n",
      "====> Epoch: 1800 || 0.3290730118751526\n",
      "====> Epoch: 1810 || 0.39059317111968994\n",
      "====> Epoch: 1820 || 0.3309447765350342\n",
      "====> Epoch: 1830 || 0.3116951584815979\n",
      "====> Epoch: 1840 || 0.3077681064605713\n",
      "====> Epoch: 1850 || 0.36063507199287415\n",
      "====> Epoch: 1860 || 0.3634604811668396\n",
      "====> Epoch: 1870 || 0.3823319673538208\n",
      "====> Epoch: 1880 || 0.40558165311813354\n",
      "====> Epoch: 1890 || 0.36191609501838684\n",
      "====> Epoch: 1900 || 0.35440313816070557\n",
      "====> Epoch: 1910 || 0.3100849390029907\n",
      "====> Epoch: 1920 || 0.33990615606307983\n",
      "====> Epoch: 1930 || 0.3712815046310425\n",
      "====> Epoch: 1940 || 0.35556894540786743\n",
      "====> Epoch: 1950 || 0.31519728899002075\n",
      "====> Epoch: 1960 || 0.3599172532558441\n",
      "====> Epoch: 1970 || 0.33627641201019287\n",
      "====> Epoch: 1980 || 0.34271422028541565\n",
      "====> Epoch: 1990 || 0.37349048256874084\n",
      "====> Epoch: 2000 || 0.37042176723480225\n",
      "====> Epoch: 2010 || 0.36182352900505066\n",
      "====> Epoch: 2020 || 0.35761716961860657\n",
      "====> Epoch: 2030 || 0.44490480422973633\n",
      "====> Epoch: 2040 || 0.36666807532310486\n",
      "====> Epoch: 2050 || 0.3801210820674896\n",
      "====> Epoch: 2060 || 0.3691026568412781\n",
      "====> Epoch: 2070 || 0.34251126646995544\n",
      "====> Epoch: 2080 || 0.33633115887641907\n",
      "====> Epoch: 2090 || 0.3812728822231293\n",
      "====> Epoch: 2100 || 0.36321282386779785\n",
      "====> Epoch: 2110 || 0.3541037440299988\n",
      "====> Epoch: 2120 || 0.4035909175872803\n",
      "====> Epoch: 2130 || 0.34803709387779236\n",
      "====> Epoch: 2140 || 0.4068220555782318\n",
      "====> Epoch: 2150 || 0.3839472830295563\n",
      "====> Epoch: 2160 || 0.34246718883514404\n",
      "====> Epoch: 2170 || 0.37439510226249695\n",
      "====> Epoch: 2180 || 0.32566145062446594\n",
      "====> Epoch: 2190 || 0.36811983585357666\n",
      "====> Epoch: 2200 || 0.3532767593860626\n",
      "====> Epoch: 2210 || 0.38180404901504517\n",
      "====> Epoch: 2220 || 0.3638792335987091\n",
      "====> Epoch: 2230 || 0.39690303802490234\n",
      "====> Epoch: 2240 || 0.3347240388393402\n",
      "====> Epoch: 2250 || 0.3182480037212372\n",
      "====> Epoch: 2260 || 0.3284802734851837\n",
      "====> Epoch: 2270 || 0.29648950695991516\n",
      "====> Epoch: 2280 || 0.327799916267395\n",
      "====> Epoch: 2290 || 0.34841418266296387\n",
      "====> Epoch: 2300 || 0.4110439419746399\n",
      "====> Epoch: 2310 || 0.36435404419898987\n",
      "====> Epoch: 2320 || 0.33777153491973877\n",
      "====> Epoch: 2330 || 0.3477904498577118\n",
      "====> Epoch: 2340 || 0.3399306833744049\n",
      "====> Epoch: 2350 || 0.34265127778053284\n",
      "====> Epoch: 2360 || 0.3745363652706146\n",
      "====> Epoch: 2370 || 0.32514601945877075\n",
      "====> Epoch: 2380 || 0.357410192489624\n",
      "====> Epoch: 2390 || 0.3405214548110962\n",
      "====> Epoch: 2400 || 0.34858062863349915\n",
      "====> Epoch: 2410 || 0.36671096086502075\n",
      "====> Epoch: 2420 || 0.3562173843383789\n",
      "====> Epoch: 2430 || 0.3617573380470276\n",
      "====> Epoch: 2440 || 0.36335089802742004\n",
      "====> Epoch: 2450 || 0.35613393783569336\n",
      "====> Epoch: 2460 || 0.3408931493759155\n",
      "====> Epoch: 2470 || 0.34298819303512573\n",
      "====> Epoch: 2480 || 0.35253018140792847\n",
      "====> Epoch: 2490 || 0.3256044089794159\n",
      "====> Epoch: 2500 || 0.3151548206806183\n",
      "====> Epoch: 2510 || 0.35272616147994995\n",
      "====> Epoch: 2520 || 0.3469853103160858\n",
      "====> Epoch: 2530 || 0.3369155824184418\n",
      "====> Epoch: 2540 || 0.3280599117279053\n",
      "====> Epoch: 2550 || 0.3111175000667572\n",
      "====> Epoch: 2560 || 0.3041855990886688\n",
      "====> Epoch: 2570 || 0.34365612268447876\n",
      "====> Epoch: 2580 || 0.3762505352497101\n",
      "====> Epoch: 2590 || 0.38622382283210754\n",
      "====> Epoch: 2600 || 0.3786357343196869\n",
      "====> Epoch: 2610 || 0.34478557109832764\n",
      "====> Epoch: 2620 || 0.35056155920028687\n",
      "====> Epoch: 2630 || 0.33989712595939636\n",
      "====> Epoch: 2640 || 0.33886680006980896\n",
      "====> Epoch: 2650 || 0.3100627064704895\n",
      "====> Epoch: 2660 || 0.35405227541923523\n",
      "====> Epoch: 2670 || 0.3661558926105499\n",
      "====> Epoch: 2680 || 0.35431861877441406\n",
      "====> Epoch: 2690 || 0.38015228509902954\n",
      "====> Epoch: 2700 || 0.3531532883644104\n",
      "====> Epoch: 2710 || 0.3637949228286743\n",
      "====> Epoch: 2720 || 0.39378130435943604\n",
      "====> Epoch: 2730 || 0.3401572108268738\n",
      "====> Epoch: 2740 || 0.3554823398590088\n",
      "====> Epoch: 2750 || 0.345268189907074\n",
      "====> Epoch: 2760 || 0.3115885555744171\n",
      "====> Epoch: 2770 || 0.3764428198337555\n",
      "====> Epoch: 2780 || 0.3528705835342407\n",
      "====> Epoch: 2790 || 0.32195502519607544\n",
      "====> Epoch: 2800 || 0.3628106713294983\n",
      "====> Epoch: 2810 || 0.3341868221759796\n",
      "====> Epoch: 2820 || 0.3504248559474945\n",
      "====> Epoch: 2830 || 0.4038567543029785\n",
      "====> Epoch: 2840 || 0.3700231611728668\n",
      "====> Epoch: 2850 || 0.36122822761535645\n",
      "====> Epoch: 2860 || 0.35816946625709534\n",
      "====> Epoch: 2870 || 0.33480262756347656\n",
      "====> Epoch: 2880 || 0.3336530327796936\n",
      "====> Epoch: 2890 || 0.29321932792663574\n",
      "====> Epoch: 2900 || 0.3308272361755371\n",
      "====> Epoch: 2910 || 0.32242581248283386\n",
      "====> Epoch: 2920 || 0.32541462779045105\n",
      "====> Epoch: 2930 || 0.3727078139781952\n",
      "====> Epoch: 2940 || 0.3200499415397644\n",
      "====> Epoch: 2950 || 0.37746211886405945\n",
      "====> Epoch: 2960 || 0.3540598154067993\n",
      "====> Epoch: 2970 || 0.33424416184425354\n",
      "====> Epoch: 2980 || 0.337275892496109\n",
      "====> Epoch: 2990 || 0.3830870985984802\n",
      "====> Epoch: 2999 || 0.3282313048839569\n",
      "[2023-10-13 12:37:56] Evaluate_01: epoch = 1000 train time = 97 s train loss = 0.004053 train acc = 1.0000, test acc = 0.4732\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('cvae_all_2.pt').to(device)  \n",
    "# A + 合成数据集 0.4552 0.4548 0.4674\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 10 if args_cave.dataset == 'imagenet' else 30, 0.5,)\n",
    "\n",
    "epochs = 3000\n",
    "for epoch in range(epochs):\n",
    "\n",
    "\n",
    "    # batch_img = images_all[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    \n",
    "    # batch_img = img_real_train[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    # batch_syn = img_syn[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    \n",
    "    # 随机选择batch个索引\n",
    "    random_indices = np.random.choice(len(img_real_train), batch, replace=False)\n",
    "\n",
    "    # 使用随机选择的索引来获取数据并改变形状\n",
    "    # batch_img = img_real_train[random_indices].reshape((batch, 3, 32, 32)).to(device)\n",
    "    batch_syn = img_syn[random_indices].reshape((batch, 3, 32, 32)).to(device) \n",
    "\n",
    "    # batch_img_y = label_real_train[c*batch:(c+1)*batch].to(device) \n",
    "    \n",
    "    outputs = model(batch_syn)\n",
    "    \n",
    "    loss = model.loss_function(batch_syn, *outputs)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # logs['loss'].append(loss.item())\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == epochs -1:\n",
    "        # print(\"Epoch {:02d}/{:02d} , Loss {:9.4f}\".format(\n",
    "        #     epoch, epochs,  loss.item()))\n",
    "        print(\"====> Epoch: {} || {}\".format(epoch, loss.item()))\n",
    "        \n",
    "with torch.no_grad():\n",
    "  output = model(img_real_test.to(device))\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[0]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 || 0.3757937252521515\n",
      "====> Epoch: 10 || 0.3825913071632385\n",
      "====> Epoch: 20 || 0.3968660533428192\n",
      "====> Epoch: 30 || 0.40076813101768494\n",
      "====> Epoch: 40 || 0.4041665494441986\n",
      "====> Epoch: 50 || 0.345682829618454\n",
      "====> Epoch: 60 || 0.3817612826824188\n",
      "====> Epoch: 70 || 0.34802284836769104\n",
      "====> Epoch: 80 || 0.31748664379119873\n",
      "====> Epoch: 90 || 0.36636874079704285\n",
      "====> Epoch: 100 || 0.40857332944869995\n",
      "====> Epoch: 110 || 0.40054237842559814\n",
      "====> Epoch: 120 || 0.3380434811115265\n",
      "====> Epoch: 130 || 0.339511513710022\n",
      "====> Epoch: 140 || 0.3632967472076416\n",
      "====> Epoch: 150 || 0.3440603017807007\n",
      "====> Epoch: 160 || 0.3688947260379791\n",
      "====> Epoch: 170 || 0.38125380873680115\n",
      "====> Epoch: 180 || 0.36186617612838745\n",
      "====> Epoch: 190 || 0.3839729428291321\n",
      "====> Epoch: 200 || 0.34188199043273926\n",
      "====> Epoch: 210 || 0.3742049038410187\n",
      "====> Epoch: 220 || 0.35022541880607605\n",
      "====> Epoch: 230 || 0.35687145590782166\n",
      "====> Epoch: 240 || 0.35229793190956116\n",
      "====> Epoch: 250 || 0.34314587712287903\n",
      "====> Epoch: 260 || 0.42488935589790344\n",
      "====> Epoch: 270 || 0.352079838514328\n",
      "====> Epoch: 280 || 0.3635888993740082\n",
      "====> Epoch: 290 || 0.3975234627723694\n",
      "====> Epoch: 300 || 0.35933732986450195\n",
      "====> Epoch: 310 || 0.375652939081192\n",
      "====> Epoch: 320 || 0.3404349684715271\n",
      "====> Epoch: 330 || 0.35573610663414\n",
      "====> Epoch: 340 || 0.36370229721069336\n",
      "====> Epoch: 350 || 0.3375735282897949\n",
      "====> Epoch: 360 || 0.38787418603897095\n",
      "====> Epoch: 370 || 0.34037572145462036\n",
      "====> Epoch: 380 || 0.3781326115131378\n",
      "====> Epoch: 390 || 0.3481999337673187\n",
      "====> Epoch: 400 || 0.36478859186172485\n",
      "====> Epoch: 410 || 0.3451755940914154\n",
      "====> Epoch: 420 || 0.36236128211021423\n",
      "====> Epoch: 430 || 0.3736962676048279\n",
      "====> Epoch: 440 || 0.37383559346199036\n",
      "====> Epoch: 450 || 0.3808140754699707\n",
      "====> Epoch: 460 || 0.37555161118507385\n",
      "====> Epoch: 470 || 0.3630632758140564\n",
      "====> Epoch: 480 || 0.3844800591468811\n",
      "====> Epoch: 490 || 0.4088936448097229\n",
      "====> Epoch: 500 || 0.3592584431171417\n",
      "====> Epoch: 510 || 0.3386353850364685\n",
      "====> Epoch: 520 || 0.3888433277606964\n",
      "====> Epoch: 530 || 0.3522803783416748\n",
      "====> Epoch: 540 || 0.33263108134269714\n",
      "====> Epoch: 550 || 0.3638756275177002\n",
      "====> Epoch: 560 || 0.35857701301574707\n",
      "====> Epoch: 570 || 0.40447646379470825\n",
      "====> Epoch: 580 || 0.36917534470558167\n",
      "====> Epoch: 590 || 0.3117717206478119\n",
      "====> Epoch: 600 || 0.3709558844566345\n",
      "====> Epoch: 610 || 0.4058883786201477\n",
      "====> Epoch: 620 || 0.3745742440223694\n",
      "====> Epoch: 630 || 0.35234442353248596\n",
      "====> Epoch: 640 || 0.3285248875617981\n",
      "====> Epoch: 650 || 0.3750963807106018\n",
      "====> Epoch: 660 || 0.355075865983963\n",
      "====> Epoch: 670 || 0.3914247453212738\n",
      "====> Epoch: 680 || 0.34799811244010925\n",
      "====> Epoch: 690 || 0.36463990807533264\n",
      "====> Epoch: 700 || 0.3585999608039856\n",
      "====> Epoch: 710 || 0.3994329571723938\n",
      "====> Epoch: 720 || 0.391498863697052\n",
      "====> Epoch: 730 || 0.35736411809921265\n",
      "====> Epoch: 740 || 0.3870789408683777\n",
      "====> Epoch: 750 || 0.36906787753105164\n",
      "====> Epoch: 760 || 0.3510645627975464\n",
      "====> Epoch: 770 || 0.3759992718696594\n",
      "====> Epoch: 780 || 0.3717809021472931\n",
      "====> Epoch: 790 || 0.32892414927482605\n",
      "====> Epoch: 800 || 0.3646063804626465\n",
      "====> Epoch: 810 || 0.35947757959365845\n",
      "====> Epoch: 820 || 0.345043420791626\n",
      "====> Epoch: 830 || 0.3620964288711548\n",
      "====> Epoch: 840 || 0.3509249985218048\n",
      "====> Epoch: 850 || 0.39548996090888977\n",
      "====> Epoch: 860 || 0.3818361461162567\n",
      "====> Epoch: 870 || 0.3451642096042633\n",
      "====> Epoch: 880 || 0.34001800417900085\n",
      "====> Epoch: 890 || 0.38291820883750916\n",
      "====> Epoch: 900 || 0.379372775554657\n",
      "====> Epoch: 910 || 0.3399828374385834\n",
      "====> Epoch: 920 || 0.3642627000808716\n",
      "====> Epoch: 930 || 0.36057552695274353\n",
      "====> Epoch: 940 || 0.3998771905899048\n",
      "====> Epoch: 950 || 0.34703943133354187\n",
      "====> Epoch: 960 || 0.37256771326065063\n",
      "====> Epoch: 970 || 0.34631526470184326\n",
      "====> Epoch: 980 || 0.37574532628059387\n",
      "====> Epoch: 990 || 0.3470183312892914\n",
      "====> Epoch: 1000 || 0.38552337884902954\n",
      "====> Epoch: 1010 || 0.3701767921447754\n",
      "====> Epoch: 1020 || 0.3727724254131317\n",
      "====> Epoch: 1030 || 0.3249105215072632\n",
      "====> Epoch: 1040 || 0.36170411109924316\n",
      "====> Epoch: 1050 || 0.36736881732940674\n",
      "====> Epoch: 1060 || 0.31434643268585205\n",
      "====> Epoch: 1070 || 0.3929292559623718\n",
      "====> Epoch: 1080 || 0.3955534100532532\n",
      "====> Epoch: 1090 || 0.3592243194580078\n",
      "====> Epoch: 1100 || 0.387029230594635\n",
      "====> Epoch: 1110 || 0.40795567631721497\n",
      "====> Epoch: 1120 || 0.33873409032821655\n",
      "====> Epoch: 1130 || 0.36666709184646606\n",
      "====> Epoch: 1140 || 0.3906368613243103\n",
      "====> Epoch: 1150 || 0.38154569268226624\n",
      "====> Epoch: 1160 || 0.37415996193885803\n",
      "====> Epoch: 1170 || 0.3277336359024048\n",
      "====> Epoch: 1180 || 0.3505079746246338\n",
      "====> Epoch: 1190 || 0.35082918405532837\n",
      "====> Epoch: 1200 || 0.3446100354194641\n",
      "====> Epoch: 1210 || 0.36228981614112854\n",
      "====> Epoch: 1220 || 0.38192835450172424\n",
      "====> Epoch: 1230 || 0.42083460092544556\n",
      "====> Epoch: 1240 || 0.3813236355781555\n",
      "====> Epoch: 1250 || 0.36231735348701477\n",
      "====> Epoch: 1260 || 0.3555711507797241\n",
      "====> Epoch: 1270 || 0.3290060758590698\n",
      "====> Epoch: 1280 || 0.395414799451828\n",
      "====> Epoch: 1290 || 0.4083588123321533\n",
      "====> Epoch: 1300 || 0.3604823052883148\n",
      "====> Epoch: 1310 || 0.3468729555606842\n",
      "====> Epoch: 1320 || 0.3904823362827301\n",
      "====> Epoch: 1330 || 0.32238703966140747\n",
      "====> Epoch: 1340 || 0.36893147230148315\n",
      "====> Epoch: 1350 || 0.3433663249015808\n",
      "====> Epoch: 1360 || 0.3711289167404175\n",
      "====> Epoch: 1370 || 0.32727324962615967\n",
      "====> Epoch: 1380 || 0.3577878475189209\n",
      "====> Epoch: 1390 || 0.3606264293193817\n",
      "====> Epoch: 1400 || 0.3513539433479309\n",
      "====> Epoch: 1410 || 0.33751222491264343\n",
      "====> Epoch: 1420 || 0.35529738664627075\n",
      "====> Epoch: 1430 || 0.4225892424583435\n",
      "====> Epoch: 1440 || 0.3158475160598755\n",
      "====> Epoch: 1450 || 0.3608841001987457\n",
      "====> Epoch: 1460 || 0.357162207365036\n",
      "====> Epoch: 1470 || 0.3314853310585022\n",
      "====> Epoch: 1480 || 0.3684142231941223\n",
      "====> Epoch: 1490 || 0.39992260932922363\n",
      "====> Epoch: 1500 || 0.37089020013809204\n",
      "====> Epoch: 1510 || 0.34893667697906494\n",
      "====> Epoch: 1520 || 0.3404804766178131\n",
      "====> Epoch: 1530 || 0.3996829390525818\n",
      "====> Epoch: 1540 || 0.38307976722717285\n",
      "====> Epoch: 1550 || 0.3205701410770416\n",
      "====> Epoch: 1560 || 0.4137381911277771\n",
      "====> Epoch: 1570 || 0.3908311426639557\n",
      "====> Epoch: 1580 || 0.329833447933197\n",
      "====> Epoch: 1590 || 0.3476569652557373\n",
      "====> Epoch: 1600 || 0.36375218629837036\n",
      "====> Epoch: 1610 || 0.3217003643512726\n",
      "====> Epoch: 1620 || 0.3409162759780884\n",
      "====> Epoch: 1630 || 0.38965556025505066\n",
      "====> Epoch: 1640 || 0.3418629765510559\n",
      "====> Epoch: 1650 || 0.3436926603317261\n",
      "====> Epoch: 1660 || 0.3967686593532562\n",
      "====> Epoch: 1670 || 0.3534669280052185\n",
      "====> Epoch: 1680 || 0.3176882565021515\n",
      "====> Epoch: 1690 || 0.3538612723350525\n",
      "====> Epoch: 1700 || 0.34645748138427734\n",
      "====> Epoch: 1710 || 0.4028373658657074\n",
      "====> Epoch: 1720 || 0.38379809260368347\n",
      "====> Epoch: 1730 || 0.3326896131038666\n",
      "====> Epoch: 1740 || 0.3714113235473633\n",
      "====> Epoch: 1750 || 0.38716527819633484\n",
      "====> Epoch: 1760 || 0.3810746669769287\n",
      "====> Epoch: 1770 || 0.336237370967865\n",
      "====> Epoch: 1780 || 0.3429977595806122\n",
      "====> Epoch: 1790 || 0.35736674070358276\n",
      "====> Epoch: 1800 || 0.36043938994407654\n",
      "====> Epoch: 1810 || 0.31407564878463745\n",
      "====> Epoch: 1820 || 0.31274664402008057\n",
      "====> Epoch: 1830 || 0.34689241647720337\n",
      "====> Epoch: 1840 || 0.37803906202316284\n",
      "====> Epoch: 1850 || 0.3445929288864136\n",
      "====> Epoch: 1860 || 0.3981591761112213\n",
      "====> Epoch: 1870 || 0.3336527347564697\n",
      "====> Epoch: 1880 || 0.3459058403968811\n",
      "====> Epoch: 1890 || 0.3539818823337555\n",
      "====> Epoch: 1900 || 0.33708620071411133\n",
      "====> Epoch: 1910 || 0.35340753197669983\n",
      "====> Epoch: 1920 || 0.3499574065208435\n",
      "====> Epoch: 1930 || 0.3382479250431061\n",
      "====> Epoch: 1940 || 0.40681958198547363\n",
      "====> Epoch: 1950 || 0.343540221452713\n",
      "====> Epoch: 1960 || 0.3510970175266266\n",
      "====> Epoch: 1970 || 0.34325194358825684\n",
      "====> Epoch: 1980 || 0.34151890873908997\n",
      "====> Epoch: 1990 || 0.3941027522087097\n",
      "====> Epoch: 2000 || 0.38823455572128296\n",
      "====> Epoch: 2010 || 0.3823852837085724\n",
      "====> Epoch: 2020 || 0.3315069079399109\n",
      "====> Epoch: 2030 || 0.37802910804748535\n",
      "====> Epoch: 2040 || 0.3657350540161133\n",
      "====> Epoch: 2050 || 0.3813854455947876\n",
      "====> Epoch: 2060 || 0.3396908938884735\n",
      "====> Epoch: 2070 || 0.3369283378124237\n",
      "====> Epoch: 2080 || 0.3711352050304413\n",
      "====> Epoch: 2090 || 0.3371252417564392\n",
      "====> Epoch: 2100 || 0.36637601256370544\n",
      "====> Epoch: 2110 || 0.32297655940055847\n",
      "====> Epoch: 2120 || 0.32061347365379333\n",
      "====> Epoch: 2130 || 0.3306976854801178\n",
      "====> Epoch: 2140 || 0.33095481991767883\n",
      "====> Epoch: 2150 || 0.34733930230140686\n",
      "====> Epoch: 2160 || 0.40540778636932373\n",
      "====> Epoch: 2170 || 0.3480461537837982\n",
      "====> Epoch: 2180 || 0.3612864315509796\n",
      "====> Epoch: 2190 || 0.3472612202167511\n",
      "====> Epoch: 2200 || 0.3860929012298584\n",
      "====> Epoch: 2210 || 0.328199177980423\n",
      "====> Epoch: 2220 || 0.323942095041275\n",
      "====> Epoch: 2230 || 0.36091116070747375\n",
      "====> Epoch: 2240 || 0.3676654100418091\n",
      "====> Epoch: 2250 || 0.31194886565208435\n",
      "====> Epoch: 2260 || 0.32299208641052246\n",
      "====> Epoch: 2270 || 0.3718058466911316\n",
      "====> Epoch: 2280 || 0.3929348587989807\n",
      "====> Epoch: 2290 || 0.36809390783309937\n",
      "====> Epoch: 2300 || 0.37369605898857117\n",
      "====> Epoch: 2310 || 0.34820812940597534\n",
      "====> Epoch: 2320 || 0.331097275018692\n",
      "====> Epoch: 2330 || 0.39443880319595337\n",
      "====> Epoch: 2340 || 0.37759602069854736\n",
      "====> Epoch: 2350 || 0.3442291021347046\n",
      "====> Epoch: 2360 || 0.4183862507343292\n",
      "====> Epoch: 2370 || 0.29863131046295166\n",
      "====> Epoch: 2380 || 0.34324923157691956\n",
      "====> Epoch: 2390 || 0.3304554224014282\n",
      "====> Epoch: 2400 || 0.3764062523841858\n",
      "====> Epoch: 2410 || 0.3484261631965637\n",
      "====> Epoch: 2420 || 0.38611820340156555\n",
      "====> Epoch: 2430 || 0.3779716193675995\n",
      "====> Epoch: 2440 || 0.35924041271209717\n",
      "====> Epoch: 2450 || 0.3772485852241516\n",
      "====> Epoch: 2460 || 0.35106170177459717\n",
      "====> Epoch: 2470 || 0.3510791063308716\n",
      "====> Epoch: 2480 || 0.32774195075035095\n",
      "====> Epoch: 2490 || 0.37935763597488403\n",
      "====> Epoch: 2500 || 0.3433854579925537\n",
      "====> Epoch: 2510 || 0.3524838089942932\n",
      "====> Epoch: 2520 || 0.3046390116214752\n",
      "====> Epoch: 2530 || 0.3545893430709839\n",
      "====> Epoch: 2540 || 0.3116094172000885\n",
      "====> Epoch: 2550 || 0.37693309783935547\n",
      "====> Epoch: 2560 || 0.3231615126132965\n",
      "====> Epoch: 2570 || 0.4290899634361267\n",
      "====> Epoch: 2580 || 0.3689784109592438\n",
      "====> Epoch: 2590 || 0.3525778651237488\n",
      "====> Epoch: 2600 || 0.3614404797554016\n",
      "====> Epoch: 2610 || 0.3602096438407898\n",
      "====> Epoch: 2620 || 0.35400620102882385\n",
      "====> Epoch: 2630 || 0.3180886507034302\n",
      "====> Epoch: 2640 || 0.34807199239730835\n",
      "====> Epoch: 2650 || 0.35512036085128784\n",
      "====> Epoch: 2660 || 0.3682843744754791\n",
      "====> Epoch: 2670 || 0.3721100687980652\n",
      "====> Epoch: 2680 || 0.31288543343544006\n",
      "====> Epoch: 2690 || 0.350669801235199\n",
      "====> Epoch: 2700 || 0.31814804673194885\n",
      "====> Epoch: 2710 || 0.32487326860427856\n",
      "====> Epoch: 2720 || 0.354833722114563\n",
      "====> Epoch: 2730 || 0.33412879705429077\n",
      "====> Epoch: 2740 || 0.33945202827453613\n",
      "====> Epoch: 2750 || 0.3336748778820038\n",
      "====> Epoch: 2760 || 0.32521113753318787\n",
      "====> Epoch: 2770 || 0.42808347940444946\n",
      "====> Epoch: 2780 || 0.3734685778617859\n",
      "====> Epoch: 2790 || 0.33748936653137207\n",
      "====> Epoch: 2800 || 0.3476278483867645\n",
      "====> Epoch: 2810 || 0.3354676067829132\n",
      "====> Epoch: 2820 || 0.35152700543403625\n",
      "====> Epoch: 2830 || 0.3231661021709442\n",
      "====> Epoch: 2840 || 0.35903263092041016\n",
      "====> Epoch: 2850 || 0.3312075138092041\n",
      "====> Epoch: 2860 || 0.373297780752182\n",
      "====> Epoch: 2870 || 0.37847650051116943\n",
      "====> Epoch: 2880 || 0.3274741768836975\n",
      "====> Epoch: 2890 || 0.3818814754486084\n",
      "====> Epoch: 2900 || 0.3467656373977661\n",
      "====> Epoch: 2910 || 0.36809486150741577\n",
      "====> Epoch: 2920 || 0.3627268373966217\n",
      "====> Epoch: 2930 || 0.3785461485385895\n",
      "====> Epoch: 2940 || 0.35308408737182617\n",
      "====> Epoch: 2950 || 0.33765003085136414\n",
      "====> Epoch: 2960 || 0.36857861280441284\n",
      "====> Epoch: 2970 || 0.3101779818534851\n",
      "====> Epoch: 2980 || 0.369816392660141\n",
      "====> Epoch: 2990 || 0.3333396017551422\n",
      "====> Epoch: 2999 || 0.3535167872905731\n",
      "[2023-10-13 12:44:40] Evaluate_01: epoch = 1000 train time = 97 s train loss = 0.004196 train acc = 1.0000, test acc = 0.4853\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('cvae_all_2.pt').to(device) \n",
    "# A + 样本对 0.4552 0.4548 0.4674 0.4720\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 10 if args_cave.dataset == 'imagenet' else 30, 0.5,)\n",
    "\n",
    "epochs = 3000\n",
    "for epoch in range(epochs):\n",
    "        \n",
    "    # batch_img = images_all[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    \n",
    "    # batch_img = img_real_train[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    # batch_syn = img_syn[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    \n",
    "    # 随机选择batch个索引\n",
    "    random_indices = np.random.choice(len(img_real_train), batch, replace=False)\n",
    "\n",
    "    # 使用随机选择的索引来获取数据并改变形状\n",
    "    batch_img = img_real_train[random_indices].reshape((batch, 3, 32, 32)).to(device)\n",
    "    batch_syn = img_syn[random_indices].reshape((batch, 3, 32, 32)).to(device) \n",
    "\n",
    "    # batch_img_y = label_real_train[c*batch:(c+1)*batch].to(device) \n",
    "    \n",
    "    outputs = model(batch_img)\n",
    "    \n",
    "    loss = model.loss_function(batch_syn, *outputs)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # logs['loss'].append(loss.item())\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == epochs -1:\n",
    "        # print(\"Epoch {:02d}/{:02d} , Loss {:9.4f}\".format(\n",
    "        #     epoch, epochs,  loss.item()))\n",
    "        print(\"====> Epoch: {} || {}\".format(epoch, loss.item()))\n",
    "        \n",
    "with torch.no_grad():\n",
    "  output = model(img_real_test.to(device))\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[0]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test 合成数据集结果（1500张）\n",
    "# 直接输入原图： 0.5100\n",
    "# 样本对训练原图 - 合成图差异： 0.5093\n",
    "\n",
    "# A :                  0.3860 - 0.005  |   0.4056\n",
    "# 只用样本对中的原图 :  0.3808 - 0.006  |   0.4034\n",
    "# 只用样本对训 ：       0.3719, 0.005 |   0.3762\n",
    "\n",
    "# A+合成图 FINTUNE :    0.4056 - 0.005  |   0.3825 0.4110 0.4075\n",
    "\n",
    "# A+样本对 FINTUNE :   0.3840 - 0.004  |   0.3885 0.3785 0.3850\n",
    "\n",
    "\n",
    "# accs = [0.3642,0.3756,0.3759]np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_net(epoch, model, test_loader, cuda, save_path, args, writer):\n",
    "    model.eval()\n",
    "    loss_dict = model.latest_losses()\n",
    "    losses = {k + '_test': 0 for k, v in loss_dict.items()}\n",
    "    i, data = None, None\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            if cuda:\n",
    "                data = data.cuda()\n",
    "            outputs = model(data)\n",
    "            model.loss_function(data, *outputs)\n",
    "            latest_losses = model.latest_losses()\n",
    "            for key in latest_losses:\n",
    "                losses[key + '_test'] += float(latest_losses[key])\n",
    "            if i == 0:\n",
    "                write_images(data, outputs, writer, 'test')\n",
    "\n",
    "                save_reconstructed_images(data, epoch, outputs[0], save_path, 'reconstruction_test')\n",
    "                # save_checkpoint(model, epoch, save_path)\n",
    "            if args.dataset == 'imagenet' and i * len(data) > 1000:\n",
    "                break\n",
    "\n",
    "    for key in losses:\n",
    "        if args.dataset not in ['imagenet', 'custom']:\n",
    "            losses[key] /= (len(test_loader.dataset) / test_loader.batch_size)\n",
    "        else:\n",
    "            losses[key] /= (i * len(data))\n",
    "    loss_string = ' '.join(['{}: {:.6f}'.format(k, v) for k, v in losses.items()])\n",
    "    logging.info('====> Test set losses: {}'.format(loss_string))\n",
    "    return losses\n",
    "\n",
    "\n",
    "def write_images(data, outputs, writer, suffix):\n",
    "    original = data.mul(0.5).add(0.5)\n",
    "    original_grid = make_grid(original[:6])\n",
    "    writer.add_image(f'original/{suffix}', original_grid)\n",
    "    reconstructed = outputs[0].mul(0.5).add(0.5)\n",
    "    reconstructed_grid = make_grid(reconstructed[:6])\n",
    "    writer.add_image(f'reconstructed/{suffix}', reconstructed_grid)\n",
    "\n",
    "\n",
    "def save_reconstructed_images(data, epoch, outputs, save_path, name):\n",
    "    size = data.size()\n",
    "    n = min(data.size(0), 8)\n",
    "    batch_size = data.size(0)\n",
    "    comparison = torch.cat([data[:n],\n",
    "                            outputs.view(batch_size, size[1], size[2], size[3])[:n]])\n",
    "    save_image(comparison.cpu(),\n",
    "               os.path.join(save_path, name + '_' + str(epoch) + '.png'), nrow=n, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ztl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
