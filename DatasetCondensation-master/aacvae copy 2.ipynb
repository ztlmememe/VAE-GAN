{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "# from utils import get_loops, get_dataset, get_network, get_eval_pool, evaluate_synset, get_daparam, match_loss, get_time, TensorDataset, epoch, DiffAugment, ParamDiffAug\n",
    "\n",
    "from utils_baseline import get_dataset, get_network, get_eval_pool, evaluate_synset, get_time, DiffAugment, ParamDiffAug\n",
    "import warnings\n",
    "import argparse\n",
    "from a_cvae import  CVAE\n",
    "import torch.utils.data\n",
    "from torch import optim\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# watch -n 1 nvidia-smi\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Parameter Processing')\n",
    "\n",
    "\n",
    "parser.add_argument('--dsa', type=str, default='True', choices=['True', 'False'],\n",
    "                    help='whether to use differentiable Siamese augmentation.')\n",
    "\n",
    "parser.add_argument('--zca', default='True', action='store_true', help=\"do ZCA whitening\")\n",
    "\n",
    "parser.add_argument('--load_all', action='store_true', help=\"only use if you can fit all expert trajectories into RAM\")\n",
    "\n",
    "parser.add_argument('--no_aug', type=bool, default=False, help='this turns off diff aug during distillation')\n",
    "\n",
    "parser.add_argument('--texture', action='store_true', help=\"will distill textures instead\")\n",
    "parser.add_argument('--canvas_size', type=int, default=2, help='size of synthetic canvas')\n",
    "parser.add_argument('--canvas_samples', type=int, default=1, help='number of canvas samples per iteration')\n",
    "\n",
    "\n",
    "\n",
    "parser.add_argument('--dataset', type=str, default='CIFAR10', help='dataset')\n",
    "parser.add_argument('--model', type=str, default='ConvNet', help='model')\n",
    "parser.add_argument('--ipc', type=int, default=50, help='image(s) per class')\n",
    "parser.add_argument('--eval_mode', type=str, default='SS', help='eval_mode') # S: the same to training model, M: multi architectures,  W: net width, D: net depth, A: activation function, P: pooling layer, N: normalization layer,\n",
    "parser.add_argument('--max_start_epoch', type=int, default=25, help='max epoch we can start at')\n",
    "parser.add_argument('--epoch_eval_train', type=int, default=1000, help='epochs to train a model with synthetic data') # it can be small for speeding up with little performance drop\n",
    "parser.add_argument('--Iteration', type=int, default=2000, help='training iterations')\n",
    "parser.add_argument('--lr_img', type=float, default=1.0, help='learning rate for updating synthetic images')\n",
    "parser.add_argument('--lr_net', type=float, default=0.01, help='learning rate for updating network parameters')\n",
    "parser.add_argument('--batch_real', type=int, default=256, help='batch size for real data')\n",
    "parser.add_argument('--batch_train', type=int, default=256, help='batch size for training networks')\n",
    "parser.add_argument('--init', type=str, default='real', help='noise/real: initialize synthetic images from random noise or randomly sampled real images.')\n",
    "parser.add_argument('--dsa_strategy', type=str, default='color_crop_cutout_flip_scale_rotate', help='differentiable Siamese augmentation strategy')\n",
    "parser.add_argument('--data_path', type=str, default='/home/ssd7T/ZTL_gcond/data_cv', help='dataset path')\n",
    "parser.add_argument('--save_path', type=str, default='/home/ssd7T/ztl_dm/gen', help='path to save results')\n",
    "parser.add_argument('--dis_metric', type=str, default='ours', help='distance metric')\n",
    "parser.add_argument('--subset', type=str, default='imagenette', help='ImageNet subset. This only does anything when --dataset=ImageNet')\n",
    "parser.add_argument('-k', '--dict-size',  default=10,type=int, dest='k', metavar='K',\n",
    "                            help='number of atoms in dictionary')\n",
    "parser.add_argument('--lr', type=float, default=2e-4,\n",
    "                            help='learning rate')\n",
    "\n",
    "parser.add_argument('--lr_cvae', type=float, default=2e-4,\n",
    "                            help='learning rate')\n",
    "\n",
    "parser.add_argument('--vq_coef', type=float, default=None,\n",
    "                            help='vq coefficient in loss')\n",
    "parser.add_argument('--commit_coef', type=float, default=None,\n",
    "                            help='commitment coefficient in loss')\n",
    "parser.add_argument('--kl_coef', type=float, default=None,\n",
    "                            help='kl-divergence coefficient in loss')\n",
    "\n",
    "parser.add_argument('--num_exp', type=int, default=10, help='the batchs of test data')\n",
    "parser.add_argument('--num_eval', type=int, default=3, help='the number of evaluating randomly initialized models')\n",
    "parser.add_argument('--pairsnum', type=int, default=100, help='image real for test')\n",
    "parser.add_argument('--test_mode', type=int, default=0, help='test mode')\n",
    "# 0 no cvae, just test all train images(T) and labels  90 70 50 30 10\n",
    "\n",
    "# 1 train cvae with all the train images(T), obtain model A, then input the train images for test(T2), using output for test\n",
    "# 2 train cvae with all the train images(T), obtain model A, then input the train images for test(T2), using combination of output and T for test\n",
    "\n",
    "# 3 train cvae with N batchs of the sample pairs(T1 - S1), obtain model B, then input the train images for test(T2), using output for test\n",
    "# 4 train cvae with N batchs of the sample pairs(T1 - S1), obtain model B, then input the train images for test(T2), using combination of output and T for test\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                            help='input batch size for training (default: 128)')\n",
    "parser.add_argument('--hidden', type=int, default=256, metavar='N',\n",
    "                            help='number of hidden channels')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                                help='random seed (default: 1)')\n",
    "parser.add_argument('--epochs_cave', type=int, default=3000,\n",
    "                            help='train cvae')\n",
    "parser.add_argument('--gpu_id', type=str, default=\"0\",\n",
    "                            help='gpu')\n",
    "args = parser.parse_args([])\n",
    "# --seed\n",
    "# 显示第 0 和第 1 个 GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{args.gpu_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_mode: 0\n",
      "CUDNN STATUS: True\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train ZCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:08<00:00, 5705.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ZCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 5674.21it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test_mode:\",args.test_mode)\n",
    "\n",
    "if args.zca and args.texture:\n",
    "    raise AssertionError(\"Cannot use zca and texture together\")\n",
    "\n",
    "if args.texture and args.pix_init == \"real\":\n",
    "    print(\"WARNING: Using texture with real initialization will take a very long time to smooth out the boundaries between images.\")\n",
    "\n",
    "\n",
    "print(\"CUDNN STATUS: {}\".format(torch.backends.cudnn.enabled))\n",
    "\n",
    "args.dsa = True if args.dsa == 'True' else False\n",
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader, loader_train_dict, class_map, class_map_inv = get_dataset(args.dataset, args.data_path, args.batch_real, args.subset, args=args)\n",
    "\n",
    "\n",
    "im_res = im_size[0]\n",
    "\n",
    "args.im_size = im_size\n",
    "\n",
    "accs_all_exps = dict() # record performances of all experiments\n",
    "\n",
    "if args.dsa:\n",
    "    # args.epoch_eval_train = 1000\n",
    "    args.dc_aug_param = None\n",
    "\n",
    "args.dsa_param = ParamDiffAug()\n",
    "\n",
    "dsa_params = args.dsa_param\n",
    "if args.zca:\n",
    "    zca_trans = args.zca_trans\n",
    "else:\n",
    "    zca_trans = None\n",
    "\n",
    "args.dsa_param = dsa_params\n",
    "args.zca_trans = zca_trans\n",
    "\n",
    "\n",
    "args.distributed = torch.cuda.device_count() > 1\n",
    "\n",
    "data_save = []\n",
    "pairs_real = []\n",
    "indexs_real = []\n",
    "\n",
    "images_all = []\n",
    "labels_all = []\n",
    "indices_class = [[] for c in range(num_classes)]\n",
    "\n",
    "images_all = [torch.unsqueeze(dst_train[i][0], dim=0) for i in range(len(dst_train))]\n",
    "labels_all = [dst_train[i][1] for i in range(len(dst_train))]\n",
    "for i, lab in enumerate(labels_all):\n",
    "    indices_class[lab].append(i)\n",
    "images_all = torch.cat(images_all, dim=0).to(args.device)\n",
    "labels_all = torch.tensor(labels_all, dtype=torch.long, device=args.device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(args.pairsnum):\n",
    "    try:\n",
    "\n",
    "        # scp -r /home/ssd7T/ztl_ftd kwang@10.11.65.8:/home/kwang/ztl/ztl_ftd\n",
    "        indexs_real_=torch.load(f'/home/ssd7T/ztl_ftd/indexs_real_{i}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexs_real=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexs_real_=torch.load(f'/home/ssd7T/ztl_ftd/indexs_real_{2}.pt')\n",
    "indexs_real.append(indexs_real_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 9\n",
    "exp = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49461,\n",
       " 49477,\n",
       " 49502,\n",
       " 49520,\n",
       " 49534,\n",
       " 49540,\n",
       " 49546,\n",
       " 49580,\n",
       " 49583,\n",
       " 49596,\n",
       " 49601,\n",
       " 49611,\n",
       " 49634,\n",
       " 49637,\n",
       " 49642,\n",
       " 49662,\n",
       " 49664,\n",
       " 49670,\n",
       " 49688,\n",
       " 49694,\n",
       " 49732,\n",
       " 49750,\n",
       " 49766,\n",
       " 49779,\n",
       " 49780,\n",
       " 49783,\n",
       " 49785,\n",
       " 49793,\n",
       " 49816,\n",
       " 49823,\n",
       " 49831,\n",
       " 49833,\n",
       " 49842,\n",
       " 49844,\n",
       " 49860,\n",
       " 49864,\n",
       " 49878,\n",
       " 49879,\n",
       " 49880,\n",
       " 49889,\n",
       " 49904,\n",
       " 49908,\n",
       " 49911,\n",
       " 49917,\n",
       " 49926,\n",
       " 49931,\n",
       " 49945,\n",
       " 49963,\n",
       " 49971,\n",
       " 49997]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_class[c][50*exp:50*exp + 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        def get_images_init(c, n,exp): # get random n images from class c\n",
    "            # start_idx = i  # 指定起始索引 i\n",
    "            # end_idx = i + n  # 计算结束索引（不包括结束索引）\n",
    "\n",
    "            # 从指定的起始索引到结束索引获取元素\n",
    "            idx_shuffle  = indices_class[c][exp:exp + n]\n",
    "\n",
    "            # idx_shuffle = np.random.permutation(indices_class[c])[:n]\n",
    "            return images_all[idx_shuffle],idx_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "new_lst = np.array(indexs_real).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_lst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_syn = torch.randn(size=(num_classes * 100, channel, im_size[0], im_size[1]), dtype=torch.float)\n",
    "\n",
    "test_label_syn = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 3, 32, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_all[new_lst].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49490"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def array_diff1(a, b):\n",
    "    #创建数组在，且数组元素在a不在b中\n",
    "    return [x for x in a if x not in b]\n",
    "len(array_diff1(indices,new_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.array(indices_class).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   29,    30,    35, ..., 49963, 49971, 49997])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "列表里有重复的元素！\n"
     ]
    }
   ],
   "source": [
    "lst=new_lst\n",
    "set_lst=set(lst)\n",
    "#set会生成一个元素无序且不重复的可迭代对象，也就是我们常说的去重\n",
    "if len(set_lst)==len(lst):\n",
    "    print('列表里的元素互不重复！')\n",
    "else:\n",
    "    print('列表里有重复的元素！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_lst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9,\n",
       "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_all[new_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_syn = labels_all[new_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes * args.pairsnum * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_image_syn.data = images_all[new_lst]\n",
    "test_label_syn_.append(labels_all[idx].to(\"cpu\"))\n",
    "test_label_syn = torch.from_numpy(np.concatenate(test_label_syn_, axis=0))\n",
    "test_label_syn = torch.cat(test_label_syn, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_init(c, n,exp): # get random n images from class c\n",
    "    # start_idx = i  # 指定起始索引 i\n",
    "    # end_idx = i + n  # 计算结束索引（不包括结束索引）\n",
    "\n",
    "    # 从指定的起始索引到结束索引获取元素\n",
    "    idx_shuffle  = indices_class[c][exp:exp + n]\n",
    "\n",
    "    # idx_shuffle = np.random.permutation(indices_class[c])[:n]\n",
    "    return images_all[idx_shuffle],idx_shuffle\n",
    "\n",
    "for exp in range(100 - args.pairsnum):\n",
    "    # 80-99\n",
    "\n",
    "    exp = exp + 80\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        reals,index = get_images_init(c, args.ipc,exp)\n",
    "        reals = reals.detach().data\n",
    "        pairs_real.append(reals)\n",
    "        indexs_real.append(index)\n",
    "\n",
    "if args.pairsnum!=100:\n",
    "        \n",
    "    img_real_test= torch.cat(pairs_real, dim=0)\n",
    "\n",
    "    label_real_test = []\n",
    "    for i in range(int(len(indexs_real)/10)):\n",
    "        # print(i)\n",
    "        label_real_test_ = []\n",
    "        for c in range(num_classes):\n",
    "            idx_shuffle = indexs_real[c + i*10]\n",
    "            label_real_test_.append(labels_all[idx_shuffle].to(\"cpu\"))\n",
    "            # print()\n",
    "        # img_real = torch.from_numpy(np.concatenate(img_real, axis=0))\n",
    "        label_real_test_ = torch.from_numpy(np.concatenate(label_real_test_, axis=0))\n",
    "        label_real_test.append(label_real_test_)\n",
    "    label_real_test = torch.cat(label_real_test, dim=0)\n",
    "\n",
    "pairs_real = []\n",
    "indexs_real = []\n",
    "\n",
    "\n",
    "device = args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get img_real and img_syn for training CVAE\n",
    "img_syn = []\n",
    "label_syn = []\n",
    "img_real_train = []\n",
    "label_real_train = []\n",
    "# /home/ssd7T/ztl_dm/indexs_real_20.pt 0-39 50 -89 90 70 50 30 10\n",
    "for i in range(args.pairsnum):\n",
    "    try:\n",
    "\n",
    "        # scp -r /home/ssd7T/ztl_ftd kwang@10.11.65.8:/home/kwang/ztl/ztl_ftd\n",
    "        img_syn_ = torch.load(f'/home/ssd7T/ztl_ftd/img_syn_{i}.pt')\n",
    "        label_syn_ = torch.load(f'/home/ssd7T/ztl_ftd/label_syn_{i}.pt')\n",
    "        pairs_real_=torch.load(f'/home/ssd7T/ztl_ftd/pairs_real_{i}.pt')\n",
    "        indexs_real_=torch.load(f'/home/ssd7T/ztl_ftd/indexs_real_{i}.pt')\n",
    "        # /home/ssd7T/ztl_ftd/label_syn_19.pt\n",
    "        # img_real_train_ = torch.cat(pairs_real_, dim=0)\n",
    "        img_real_train_ = []\n",
    "        for c in range(num_classes):\n",
    "            idx_shuffle = indexs_real_[c]\n",
    "            img_real_train_.append(images_all[idx_shuffle].to(\"cpu\"))\n",
    "        # img_real = torch.from_numpy(np.concatenate(img_real, axis=0))\n",
    "        img_real_train_ = torch.from_numpy(np.concatenate(img_real_train_, axis=0))\n",
    "        \n",
    "    \n",
    "        label_real_ = []\n",
    "        for c in range(num_classes):\n",
    "            idx_shuffle = indexs_real_[c]\n",
    "            label_real_.append(labels_all[idx_shuffle].to(\"cpu\"))\n",
    "        # img_real = torch.from_numpy(np.concatenate(img_real, axis=0))\n",
    "        label_real_train_ = torch.from_numpy(np.concatenate(label_real_, axis=0))\n",
    "        # label_real_train_ = torch.cat(label_real_train_, dim=0)\n",
    "        \n",
    "        img_real_train.append(img_real_train_)\n",
    "        label_real_train.append( label_real_train_)\n",
    "        # if i == 3 or i == 22 or i == 42 or i == 62:\n",
    "        #     pairs_real_=torch.load(f'pairs_real_{i}.pt')\n",
    "        #     img_real_train_ = torch.cat(pairs_real_, dim=0)\n",
    "        #     img_real_train.append(img_real_train_)\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "img_real_train = torch.cat(img_real_train, dim=0).to(device)\n",
    "label_real_train = torch.cat(label_real_train, dim=0).to(device)\n",
    "\n",
    "img_real_test_concat= img_real_train\n",
    "\n",
    "label_real_test_concat = label_real_train\n",
    "\n",
    "if args.pairsnum!=100:\n",
    "    print(\"test set from train shape:\",img_real_test.shape)\n",
    "print(\"train set for contact shape:\",img_real_test_concat.shape)\n",
    "\n",
    "accs = []\n",
    "model_eval_pool = get_eval_pool(args.eval_mode, args.model, args.model)\n",
    "import copy\n",
    "accs_all_exps = dict() # record performances of all experiments\n",
    "for key in model_eval_pool:\n",
    "    accs_all_exps[key] = []\n",
    "args.dsa_param = ParamDiffAug()\n",
    "args.dsa = False if args.dsa_strategy in ['none', 'None'] else True\n",
    "model_eval= model_eval_pool[0]\n",
    "\n",
    "for it_eval in range(args.num_eval):\n",
    "    # net_eval = get_network(model_eval, channel, num_classes, im_size).to(args.device) # get a random model\n",
    "\n",
    "    if args.test_mode == 0:\n",
    "        # with torch.no_grad():\n",
    "        #         output = model(images_all.to(device))\n",
    "        #     data_save = []\n",
    "        #     net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "        #     image_syn_eval, label_syn_eval = copy.deepcopy(output[0]), copy.deepcopy(labels_all) # avoid any unaware modification\n",
    "        #     print(\"Final test shape:\",image_syn_eval.shape)\n",
    "        #     _, acc_train, acc_test = evaluate_synset(it_eval, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "        #     accs.append(acc_test)\n",
    "            \n",
    "        data_save = []\n",
    "        net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "        # image_syn_eval, label_syn_eval = copy.deepcopy(images_all), copy.deepcopy(labels_all) # avoid any unaware modification\n",
    "        image_syn_eval, label_syn_eval = copy.deepcopy(img_real_test_concat.to(device)), copy.deepcopy(label_real_test_concat.to(device))\n",
    "        print(\"Final test shape:\",image_syn_eval.shape)\n",
    "        \n",
    "        \n",
    "print('Test mode %d Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'%(args.test_mode,len(accs), model_eval, np.mean(accs), np.std(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40000])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([np.ones(4000)*i for i in range(num_classes)]).view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3179, 39585, 49194, 37509, 22805,   749, 11517,  1572, 43785,\n",
       "       17977])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(indices_class[c])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(indices_class[c]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indices_class[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[122, 127, 146, 147, 166, 186, 188, 202, 205, 208]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_class[c][16:16 + 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 假设您有两个四维张量 tensor_a 和 tensor_b\n",
    "\n",
    "# tensor_a 的形状 (a, b, c, d)\n",
    "# tensor_b 的形状 (b, c, d, e)\n",
    "\n",
    "\n",
    "\n",
    "# 创建示例的四维张量和子张量\n",
    "tensor = images_all\n",
    "sub_tensor = img_real_test_concat[:50, :, :, :]\n",
    "\n",
    "# 获取四维张量的形状\n",
    "tensor_shape = tensor.shape\n",
    "sub_tensor_shape = sub_tensor.shape\n",
    "\n",
    "# 遍历主张量的四维范围来检查子张量是否存在\n",
    "for i in range(tensor_shape[0] - sub_tensor_shape[0] + 1):\n",
    "    for j in range(tensor_shape[1] - sub_tensor_shape[1] + 1):\n",
    "        for k in range(tensor_shape[2] - sub_tensor_shape[2] + 1):\n",
    "            sub_array = tensor[i:i+sub_tensor_shape[0], j:j+sub_tensor_shape[1], k:k+sub_tensor_shape[2], :]\n",
    "            # print(sub_array.shape)\n",
    "            if np.array_equal(sub_array, sub_tensor):\n",
    "                print(\"子张量存在于主张量中，起始位置为 ({}, {}, {})\".format(i, j, k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "big_tensor = images_all # torch.Size([50000, 3, 32, 32])\n",
    "i = 1999\n",
    "small_tensor = img_real_test_concat[i:i+1, :, :, :] # torch.Size([50, 3, 32, 32])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big_tensor contains small_tensor\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for i in range(len(big_tensor)):\n",
    "    # i = i+1\n",
    "    curr_tensor = big_tensor[i:(i+1), :, :, :]\n",
    "    if torch.all(torch.eq(curr_tensor, small_tensor)):\n",
    "        a +=1\n",
    "        print(\"big_tensor contains small_tensor\")\n",
    "        break\n",
    "else:\n",
    "  print(\"big_tensor does not contain small_tensor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ztl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
