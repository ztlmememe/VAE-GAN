{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "# Numpy\n",
    "import numpy as np\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Torchvision\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# OS\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 87\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "\n",
    "def print_model(encoder, decoder):\n",
    "    print(\"============== Encoder ==============\")\n",
    "    print(encoder)\n",
    "    print(\"============== Decoder ==============\")\n",
    "    print(decoder)\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    autoencoder = Autoencoder()\n",
    "    print_model(autoencoder.encoder, autoencoder.decoder)\n",
    "    if torch.cuda.is_available():\n",
    "        autoencoder = autoencoder.cuda()\n",
    "        print(\"Model moved to GPU in order to speed up training.\")\n",
    "    return autoencoder\n",
    "\n",
    "\n",
    "def get_torch_vars(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.cpu().numpy()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Input size: [batch, 3, 32, 32]\n",
    "        # Output size: [batch, 3, 32, 32]\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 12, 4, stride=2, padding=1),            # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(12, 24, 4, stride=2, padding=1),           # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.Conv2d(24, 48, 4, stride=2, padding=1),           # [batch, 48, 4, 4]\n",
    "            nn.ReLU(),\n",
    "# \t\t\tnn.Conv2d(48, 96, 4, stride=2, padding=1),           # [batch, 96, 2, 2]\n",
    "#             nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(96, 48, 4, stride=2, padding=1),  # [batch, 48, 4, 4]\n",
    "#             nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),  # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),  # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),   # [batch, 3, 32, 32]\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device  = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description='Parameter Processing')\n",
    "parser.add_argument('--dataset', type=str, default='CIFAR10', help='dataset')\n",
    "parser.add_argument('--model', type=str, default='ConvNet', help='model')\n",
    "parser.add_argument('--ipc', type=int, default=50, help='image(s) per class')\n",
    "parser.add_argument('--eval_mode', type=str, default='SS', help='eval_mode') # S: the same to training model, M: multi architectures,  W: net width, D: net depth, A: activation function, P: pooling layer, N: normalization layer,\n",
    "parser.add_argument('--num_exp', type=int, default=1, help='the number of experiments')\n",
    "parser.add_argument('--num_eval', type=int, default=1, help='the number of evaluating randomly initialized models')\n",
    "parser.add_argument('--epoch_eval_train', type=int, default=1000, help='epochs to train a model with synthetic data') # it can be small for speeding up with little performance drop\n",
    "parser.add_argument('--Iteration', type=int, default=2000, help='training iterations')\n",
    "parser.add_argument('--lr_img', type=float, default=1.0, help='learning rate for updating synthetic images')\n",
    "parser.add_argument('--lr_net', type=float, default=0.01, help='learning rate for updating network parameters')\n",
    "parser.add_argument('--batch_real', type=int, default=256, help='batch size for real data')\n",
    "parser.add_argument('--batch_train', type=int, default=256, help='batch size for training networks')\n",
    "parser.add_argument('--init', type=str, default='real', help='noise/real: initialize synthetic images from random noise or randomly sampled real images.')\n",
    "parser.add_argument('--dsa_strategy', type=str, default='color_crop_cutout_flip_scale_rotate', help='differentiable Siamese augmentation strategy')\n",
    "parser.add_argument('--data_path', type=str, default='/home/ssd7T/ZTL_gcond/data_cv', help='dataset path')\n",
    "parser.add_argument('--save_path', type=str, default='result/gen', help='path to save results')\n",
    "parser.add_argument('--dis_metric', type=str, default='ours', help='distance metric')\n",
    "from utils import get_loops, get_dataset, get_network, get_eval_pool, evaluate_synset, get_daparam, match_loss, get_time, TensorDataset, epoch, DiffAugment, ParamDiffAug\n",
    "import warnings\n",
    "args = parser.parse_args([])\n",
    "args.device = device\n",
    "channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader = get_dataset(args.dataset, args.data_path)\n",
    "\n",
    "images_all = [torch.unsqueeze(dst_train[i][0], dim=0) for i in range(len(dst_train))]\n",
    "labels_all = [dst_train[i][1] for i in range(len(dst_train))]\n",
    "indices_class = [[] for c in range(num_classes)]\n",
    "for i, lab in enumerate(labels_all):\n",
    "    indices_class[lab].append(i)\n",
    "images_all = torch.cat(images_all, dim=0).to(device)\n",
    "labels_all = torch.tensor(labels_all, dtype=torch.long, device=device)\n",
    "\n",
    "accs = []\n",
    "model_eval_pool = get_eval_pool(args.eval_mode, args.model, args.model)\n",
    "import copy\n",
    "accs_all_exps = dict() # record performances of all experiments\n",
    "for key in model_eval_pool:\n",
    "    accs_all_exps[key] = []\n",
    "args.dsa_param = ParamDiffAug()\n",
    "args.dsa = False if args.dsa_strategy in ['none', 'None'] else True\n",
    "model_eval= model_eval_pool[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_syn = []\n",
    "label_syn = []\n",
    "img_real_train = []\n",
    "label_real_train = []\n",
    "\n",
    "for i in range(50):\n",
    "    try:\n",
    "    \n",
    "        img_syn_ = torch.load(f'img_syn_{i}.pt')\n",
    "        label_syn_ = torch.load(f'label_syn_{i}.pt')\n",
    "        # pairs_real_=torch.load(f'pairs_real_{i}.pt')\n",
    "        indexs_real_=torch.load(f'indexs_real_{i}.pt')\n",
    "        \n",
    "        # img_real_train_ = torch.cat(pairs_real_, dim=0)\n",
    "        \n",
    "    \n",
    "        label_real_ = []\n",
    "        for c in range(num_classes):\n",
    "            idx_shuffle = indexs_real_[c]\n",
    "            label_real_.append(labels_all[idx_shuffle].to(\"cpu\"))\n",
    "        # img_real = torch.from_numpy(np.concatenate(img_real, axis=0))\n",
    "        label_real_train_ = torch.from_numpy(np.concatenate(label_real_, axis=0))\n",
    "        # label_real_train_ = torch.cat(label_real_train_, dim=0)\n",
    "        \n",
    "        img_syn.append(img_syn_)\n",
    "        label_syn.append(label_syn_)\n",
    "        # img_real_train.append(img_real_train_)\n",
    "        label_real_train.append( label_real_train_)\n",
    "        if i == 3 or i == 22 or i == 42 or i == 62:\n",
    "            pairs_real_=torch.load(f'pairs_real_{i}.pt')\n",
    "            img_real_train_ = torch.cat(pairs_real_, dim=0)\n",
    "            img_real_train.append(img_real_train_)\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "img_syn = torch.cat(img_syn, dim=0).to(device)\n",
    "label_syn = torch.cat(label_syn, dim=0).to(device)\n",
    "img_real_train = torch.cat(img_real_train, dim=0).to(device)\n",
    "label_real_train = torch.cat(label_real_train, dim=0).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_syn_test = []\n",
    "label_syn_test = []\n",
    "img_real_train_test = []\n",
    "label_real_train_test = []\n",
    "\n",
    "for i in range(10):\n",
    "    try:\n",
    "        i +=60\n",
    "        img_syn_ = torch.load(f'img_syn_{i}.pt')\n",
    "        label_syn_ = torch.load(f'label_syn_{i}.pt')\n",
    "        # pairs_real_=torch.load(f'pairs_real_{i}.pt')\n",
    "        indexs_real_=torch.load(f'indexs_real_{i}.pt')\n",
    "        \n",
    "        # img_real_train_ = torch.cat(pairs_real_, dim=0)\n",
    "        \n",
    "    \n",
    "        label_real_ = []\n",
    "        for c in range(num_classes):\n",
    "            idx_shuffle = indexs_real_[c]\n",
    "            label_real_.append(labels_all[idx_shuffle].to(\"cpu\"))\n",
    "        # img_real = torch.from_numpy(np.concatenate(img_real, axis=0))\n",
    "        label_real_train_ = torch.from_numpy(np.concatenate(label_real_, axis=0))\n",
    "        # label_real_train_ = torch.cat(label_real_train_, dim=0)\n",
    "        \n",
    "        img_syn_test.append(img_syn_)\n",
    "        label_syn_test.append(label_syn_)\n",
    "        # img_real_train.append(img_real_train_)\n",
    "        label_real_train_test.append( label_real_train_)\n",
    "        if i == 3 or i == 22 or i == 42 or i == 62:\n",
    "            pairs_real_=torch.load(f'pairs_real_{i}.pt')\n",
    "            img_real_train_ = torch.cat(pairs_real_, dim=0)\n",
    "            img_real_train_test.append(img_real_train_)\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "img_syn_test = torch.cat(img_syn_test, dim=0).to(device)\n",
    "label_syn_test = torch.cat(label_syn_test, dim=0).to(device)\n",
    "img_real_train_test = torch.cat(img_real_train_test, dim=0).to(device)\n",
    "label_real_train_test = torch.cat(label_real_train_test, dim=0).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_syn = []\n",
    "label_syn = []\n",
    "img_real_train = []\n",
    "label_real_train = []\n",
    "\n",
    "for i in range(64):\n",
    "    try:\n",
    "    \n",
    "        img_syn_ = torch.load(f'img_syn_{i}.pt')\n",
    "        label_syn_ = torch.load(f'label_syn_{i}.pt')\n",
    "        # pairs_real_=torch.load(f'pairs_real_{i}.pt')\n",
    "        indexs_real_=torch.load(f'indexs_real_{i}.pt')\n",
    "        \n",
    "        # img_real_train_ = torch.cat(pairs_real_, dim=0)\n",
    "        \n",
    "    \n",
    "        label_real_ = []\n",
    "        for c in range(num_classes):\n",
    "            idx_shuffle = indexs_real_[c]\n",
    "            label_real_.append(labels_all[idx_shuffle].to(\"cpu\"))\n",
    "        # img_real = torch.from_numpy(np.concatenate(img_real, axis=0))\n",
    "        label_real_train_ = torch.from_numpy(np.concatenate(label_real_, axis=0))\n",
    "        # label_real_train_ = torch.cat(label_real_train_, dim=0)\n",
    "        \n",
    "        img_syn.append(img_syn_)\n",
    "        label_syn.append(label_syn_)\n",
    "        # img_real_train.append(img_real_train_)\n",
    "        label_real_train.append( label_real_train_)\n",
    "        if i == 3 or i == 22 or i == 42 or i == 62:\n",
    "            pairs_real_=torch.load(f'pairs_real_{i}.pt')\n",
    "            img_real_train_ = torch.cat(pairs_real_, dim=0)\n",
    "            img_real_train.append(img_real_train_)\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "img_syn = torch.cat(img_syn, dim=0).to(device)\n",
    "label_syn = torch.cat(label_syn, dim=0).to(device)\n",
    "img_real_train = torch.cat(img_real_train, dim=0).to(device)\n",
    "label_real_train = torch.cat(label_real_train, dim=0).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6500])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_real_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6500, 3, 32, 32])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_real_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Encoder ==============\n",
      "Sequential(\n",
      "  (0): Conv2d(3, 12, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(12, 24, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (3): ReLU()\n",
      "  (4): Conv2d(24, 48, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (5): ReLU()\n",
      ")\n",
      "============== Decoder ==============\n",
      "Sequential(\n",
      "  (0): ConvTranspose2d(48, 24, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): ConvTranspose2d(24, 12, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (3): ReLU()\n",
      "  (4): ConvTranspose2d(12, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (5): Sigmoid()\n",
      ")\n",
      "\n",
      "Model moved to GPU in order to speed up training.\n"
     ]
    }
   ],
   "source": [
    "# torch.save(img_syn, 'img_syn.pt')\n",
    "# torch.save(label_syn, 'label_syn.pt')\n",
    "# # 读取tensor\n",
    "# img_syn = torch.load('img_syn.pt')\n",
    "# label_syn = torch.load('label_syn.pt')\n",
    "\n",
    "# img_syn =img_syn.to(device)\n",
    "# label_syn =label_syn.to(device)\n",
    "# device = img_syn.device\n",
    "\n",
    "# Create model\n",
    "autoencoder = create_model().to(device)\n",
    "\n",
    "# Load data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_real = []\n",
    "label_real = []\n",
    "for c in range(num_classes):\n",
    "    idx_shuffle = np.random.permutation(indices_class[c])\n",
    "    img_real.append(images_all[idx_shuffle].to(\"cpu\") )\n",
    "    label_real.append(labels_all[idx_shuffle].to(\"cpu\"))\n",
    "img_real_all = torch.from_numpy(np.concatenate(img_real, axis=0))\n",
    "label_real_all = torch.from_numpy(np.concatenate(label_real, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_real_test = []\n",
    "label_real_test = []\n",
    "for c in range(num_classes):\n",
    "    idx_shuffle = np.random.permutation(indices_class[c])[:50]\n",
    "    img_real_test.append(images_all[idx_shuffle].to(\"cpu\") )\n",
    "    label_real_test.append(labels_all[idx_shuffle].to(\"cpu\"))\n",
    "img_real_test = torch.from_numpy(np.concatenate(img_real_test, axis=0))\n",
    "label_real_test = torch.from_numpy(np.concatenate(label_real_test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用全部数据集训"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_classes = 10\n",
    "batch = 50\n",
    "num_feat = 3072\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters())\n",
    "# model = Autoencoder(num_feat).to(device)  \n",
    "# 训练\n",
    "for epoch in range(1000):\n",
    "\n",
    "  total_loss = 0\n",
    "  for c in range(num_classes):\n",
    "                # 获取类别c的合成图像和类别中心\n",
    "                # image_syn[c*args.ipc:(c+1)*args.ipc].reshape((args.ipc, channel, im_size[0], im_size[1]))\n",
    "    batch_img = img_real_all[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)) \n",
    "    batch_img = batch_img.to(device) \n",
    "    \n",
    "    # ============ Forward ============\n",
    "    encoded, outputs = autoencoder(batch_img)\n",
    "    loss = criterion(outputs, batch_img)\n",
    "    # ============ Backward ============\n",
    "    # print(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(autoencoder,\"autoencoder_all.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangkai/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/wangkai/.local/lib/python3.9/site-packages/torch/nn/functional.py:4298: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/wangkai/.local/lib/python3.9/site-packages/torch/nn/functional.py:4236: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-09 14:23:37] Evaluate_01: epoch = 1000 train time = 30 s train loss = 0.003723 train acc = 1.0000, test acc = 0.3631\n",
      "\n",
      "Evaluate 1 random ConvNet, mean = 0.3631 std = 0.0000\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# 恢复原图性能\n",
    "with torch.no_grad():\n",
    "  output = autoencoder(img_real_test.to(device))\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[1]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)\n",
    "print()\n",
    "print('Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'%(len(accs), model_eval, np.mean(accs), np.std(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用合成数据集微调\n",
    "autoencoder = torch.load('autoencoder_all.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-09 16:46:50] Evaluate_01: epoch = 1000 train time = 30 s train loss = 0.027596 train acc = 0.9980, test acc = 0.3593\n",
      "\n",
      "Evaluate 3 random ConvNet, mean = 0.2755 std = 0.1174\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# 由原图恢复原图性能\n",
    "with torch.no_grad():\n",
    "  output = autoencoder(img_real_test.to(device))\n",
    "\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[1]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)\n",
    "print()\n",
    "print('Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'%(len(accs), model_eval, np.mean(accs), np.std(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.用全部 cifar样本训练一个auto encoder A\n",
    "# 2.用 蒸馏前原图-蒸留后图片 分别作为输入和生成目标来finetune A，得到B\n",
    "# 3.选五百个原图，分别输入A和B，测试B会不会效果更好\n",
    "\n",
    "# SEED = 87 \n",
    "# A - 恢复1500训练用生成图 0.2336 —— 向训练好的AE里输入训练用1500原图，用输出结果和1500原图的label训练CONVE3，获得TEST ACC\n",
    "# A - 恢复1500测试用生成图 0.2755 —— 向训练好的AE里输入测试用1500原图，用输出结果和1500测试原图的label训练CONVE3，获得TEST ACC\n",
    "\n",
    "# A + 5000张合成图FINETUN - 恢复训练用1500原图 0.3693 —— 向训练好的AE里输入训练用1500原图，用输出结果和1500原图的label训练CONVE3，获得TEST ACC\n",
    "# A + 5000张合成图FINETUN - 恢复测试用1500原图 0.3794 —— 向训练好的AE里输入测试用1500原图，用输出结果和1500测试原图的label训练CONVE3，获得TEST ACC\n",
    "# A + 5000张合成图FINETUN - 恢复测试用1500生成图 0.3748 —— 向训练好的AE里输入测试用1500原图，用输出结果和1500生成图的label训练CONVE3，获得TEST ACC\n",
    "\n",
    "# A + 5000张样本对FINETUN - 恢复训练用1500原图 0.3661\n",
    "# A + 5000张样本对FINETUN - 恢复测试用原图 0.3904\n",
    "# A + 5000张样本对FINETUN - 恢复测试用1500生成图 0.3639\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangkai/.local/lib/python3.9/site-packages/torch/nn/functional.py:4298: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/wangkai/.local/lib/python3.9/site-packages/torch/nn/functional.py:4236: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-09 14:53:56] Evaluate_01: epoch = 1000 train time = 486 s train loss = 0.005050 train acc = 0.9989, test acc = 0.3962\n",
      "\n",
      "Evaluate 2 random ConvNet, mean = 0.3796 std = 0.0166\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# 由原图恢复合成图性能\n",
    "\n",
    "with torch.no_grad():\n",
    "  output = autoencoder(img_real_train.to(device))\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[1]), copy.deepcopy(label_syn) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)\n",
    "print()\n",
    "print('Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'%(len(accs), model_eval, np.mean(accs), np.std(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.用全部 cifar样本训练一个auto encoder A\n",
    "# 2.用 蒸馏前原图-蒸留后图片 分别作为输入和生成目标来finetune A，得到B\n",
    "# 3.选五百个原图，分别输入A和B，测试B会不会效果更好\n",
    "\n",
    "# SEED = 87 + test 500张原图\n",
    "# A - 恢复500原图 0.3631\n",
    "# A - 恢复6500生成图 0.3796\n",
    "\n",
    "# A + 6500张合成图FINETUN - 恢复500原图 0.3766\n",
    "# A + 6500张合成图FINETUN - 恢复6500生成图 0.3907\n",
    "\n",
    "# A + 6500张样本对FINETUN - 恢复500原图 0.3853\n",
    "# A + 6500张样本对FINETUN - 恢复6500生成图 0.3926\n",
    "\n",
    "# A + 6500张合成图FINETUN(冻结encoder) - 恢复500原图 0.3627\n",
    "# A + 6500张合成图FINETUN(冻结encoder) - 恢复6500生成图 0.3878\n",
    "\n",
    "# A + 6500张样本对FINETUN(冻结encoder) - 恢复500原图 0.3785\n",
    "# A + 6500张样本对FINETUN(冻结encoder) - 恢复6500生成图 0.3913\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/wangkai/ztl_project/difussion-dd/DatasetCondensation-master/gen2 copy.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e55532d56313030227d/home/wangkai/ztl_project/difussion-dd/DatasetCondensation-master/gen2%20copy.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 用合成数据集微调\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e55532d56313030227d/home/wangkai/ztl_project/difussion-dd/DatasetCondensation-master/gen2%20copy.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m autoencoder \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mautoencoder_all.pt\u001b[39m\u001b[39m'\u001b[39m) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# 用合成数据集微调\n",
    "autoencoder = torch.load('autoencoder_all.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A + 13*50张合成图FINETUN\n",
    "\n",
    "num_classes = 10\n",
    "batch = 50\n",
    "num_feat = 3072\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters())\n",
    "# model = Autoencoder(num_feat).to(device)  \n",
    "# 训练\n",
    "for epoch in range(1000):\n",
    "\n",
    "  total_loss = 0\n",
    "  for c in range(num_classes):\n",
    "                # 获取类别c的合成图像和类别中心\n",
    "                # image_syn[c*args.ipc:(c+1)*args.ipc].reshape((args.ipc, channel, im_size[0], im_size[1]))\n",
    "    batch_img = img_syn[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)) \n",
    "    batch_img = batch_img.to(device) \n",
    "    \n",
    "    # ============ Forward ============\n",
    "    encoded, outputs = autoencoder(batch_img)\n",
    "    loss = criterion(outputs, batch_img)\n",
    "    # ============ Backward ============\n",
    "    # print(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-09 14:55:32] Evaluate_01: epoch = 1000 train time = 59 s train loss = 0.006343 train acc = 0.9980, test acc = 0.3705\n",
      "\n",
      "Evaluate 3 random ConvNet, mean = 0.3766 std = 0.0142\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# 由原图恢复原图性能\n",
    "with torch.no_grad():\n",
    "  output = autoencoder(img_real_test.to(device))\n",
    "\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[1]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)\n",
    "print()\n",
    "print('Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'%(len(accs), model_eval, np.mean(accs), np.std(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-09 15:08:06] Evaluate_01: epoch = 1000 train time = 750 s train loss = 0.002400 train acc = 1.0000, test acc = 0.4331\n",
      "\n",
      "Evaluate 4 random ConvNet, mean = 0.3907 std = 0.0274\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# 由原图恢复合成图性能\n",
    "\n",
    "with torch.no_grad():\n",
    "  output = autoencoder(img_real_train.to(device))\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[1]), copy.deepcopy(label_syn) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)\n",
    "print()\n",
    "print('Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'%(len(accs), model_eval, np.mean(accs), np.std(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用合成数据集微调\n",
    "autoencoder = torch.load('autoencoder_all.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# A + 13*50张蒸馏前原图-蒸留后图片FINETUN(B)\n",
    "num_classes = 10\n",
    "batch = 50\n",
    "num_feat = 3072\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters())\n",
    "# model = Autoencoder(num_feat).to(device)  \n",
    "# 训练\n",
    "for epoch in range(1000):\n",
    "\n",
    "  total_loss = 0\n",
    "  for c in range(num_classes):\n",
    "                # 获取类别c的合成图像和类别中心\n",
    "                # image_syn[c*args.ipc:(c+1)*args.ipc].reshape((args.ipc, channel, im_size[0], im_size[1]))\n",
    "\n",
    "    \n",
    "    # idx_shuffle = np.random.permutation(indices_class[c])[:batch]\n",
    "    batch_img_real = img_real_train[c*batch:(c+1)*batch].reshape((batch, channel, im_size[0], im_size[1])).to(device) \n",
    "    \n",
    "    batch_img = img_syn[c*batch:(c+1)*batch].reshape((batch, channel, im_size[0], im_size[1])).to(device) \n",
    "    \n",
    "    # batch_img = batch_img_real.to(device) \n",
    "    \n",
    "    # ============ Forward ============\n",
    "    encoded, outputs = autoencoder(batch_img_real)\n",
    "    loss = criterion(outputs, batch_img)\n",
    "    # ============ Backward ============\n",
    "    # print(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-09 15:09:43] Evaluate_01: epoch = 1000 train time = 59 s train loss = 0.019111 train acc = 0.9980, test acc = 0.3635\n",
      "\n",
      "Evaluate 5 random ConvNet, mean = 0.3853 std = 0.0268\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# 由原图恢复原图性能\n",
    "with torch.no_grad():\n",
    "  output = autoencoder(img_real_test.to(device))\n",
    "\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[1]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)\n",
    "print()\n",
    "print('Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'%(len(accs), model_eval, np.mean(accs), np.std(accs)))\n",
    "# [2023-10-06 20:45:24] Evaluate_00: epoch = 1000 train time = 61 s train loss = 0.000965 train acc = 1.0000, test acc = 0.5001\n",
    "# Evaluate 1 random ConvNet, mean = 0.5001 std = 0.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-09 15:20:34] Evaluate_01: epoch = 1000 train time = 648 s train loss = 0.003775 train acc = 0.9998, test acc = 0.4293\n",
      "\n",
      "Evaluate 6 random ConvNet, mean = 0.3926 std = 0.0295\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# 由原图恢复合成图性能\n",
    "\n",
    "with torch.no_grad():\n",
    "  output = autoencoder(img_real_train.to(device))\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[1]), copy.deepcopy(label_syn) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)\n",
    "print()\n",
    "print('Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'%(len(accs), model_eval, np.mean(accs), np.std(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ztl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
