{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy\n",
    "import numpy as np\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Torchvision\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# OS\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 187\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "\n",
    "def print_model(encoder, decoder):\n",
    "    print(\"============== Encoder ==============\")\n",
    "    print(encoder)\n",
    "    print(\"============== Decoder ==============\")\n",
    "    print(decoder)\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    autoencoder = Autoencoder()\n",
    "    print_model(autoencoder.encoder, autoencoder.decoder)\n",
    "    if torch.cuda.is_available():\n",
    "        autoencoder = autoencoder.cuda()\n",
    "        print(\"Model moved to GPU in order to speed up training.\")\n",
    "    return autoencoder\n",
    "\n",
    "\n",
    "def get_torch_vars(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.cpu().numpy()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Input size: [batch, 3, 32, 32]\n",
    "        # Output size: [batch, 3, 32, 32]\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 12, 4, stride=2, padding=1),            # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(12, 24, 4, stride=2, padding=1),           # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.Conv2d(24, 48, 4, stride=2, padding=1),           # [batch, 48, 4, 4]\n",
    "            nn.ReLU(),\n",
    "# \t\t\tnn.Conv2d(48, 96, 4, stride=2, padding=1),           # [batch, 96, 2, 2]\n",
    "#             nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(96, 48, 4, stride=2, padding=1),  # [batch, 48, 4, 4]\n",
    "#             nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),  # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),  # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),   # [batch, 3, 32, 32]\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Train Autoencoder\")\n",
    "parser.add_argument(\"--valid\", action=\"store_true\", default=False,\n",
    "                    help=\"Perform validation only.\")\n",
    "args = parser.parse_args([])\n",
    "\n",
    "# Create model\n",
    "autoencoder = create_model()\n",
    "\n",
    "# Load data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(img_syn, 'img_syn.pt')\n",
    "# torch.save(label_syn, 'label_syn.pt')\n",
    "# # 读取tensor\n",
    "img_syn = torch.load('img_syn.pt')\n",
    "label_syn = torch.load('label_syn.pt')\n",
    "pairs_real=torch.load('pairs_real.pt')\n",
    "indexs_real=torch.load('indexs_real.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_real_train = torch.cat(pairs_real, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = img_syn.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description='Parameter Processing')\n",
    "parser.add_argument('--dataset', type=str, default='CIFAR10', help='dataset')\n",
    "parser.add_argument('--model', type=str, default='ConvNet', help='model')\n",
    "parser.add_argument('--ipc', type=int, default=50, help='image(s) per class')\n",
    "parser.add_argument('--eval_mode', type=str, default='SS', help='eval_mode') # S: the same to training model, M: multi architectures,  W: net width, D: net depth, A: activation function, P: pooling layer, N: normalization layer,\n",
    "parser.add_argument('--num_exp', type=int, default=1, help='the number of experiments')\n",
    "parser.add_argument('--num_eval', type=int, default=1, help='the number of evaluating randomly initialized models')\n",
    "parser.add_argument('--epoch_eval_train', type=int, default=1000, help='epochs to train a model with synthetic data') # it can be small for speeding up with little performance drop\n",
    "parser.add_argument('--Iteration', type=int, default=2000, help='training iterations')\n",
    "parser.add_argument('--lr_img', type=float, default=1.0, help='learning rate for updating synthetic images')\n",
    "parser.add_argument('--lr_net', type=float, default=0.01, help='learning rate for updating network parameters')\n",
    "parser.add_argument('--batch_real', type=int, default=256, help='batch size for real data')\n",
    "parser.add_argument('--batch_train', type=int, default=256, help='batch size for training networks')\n",
    "parser.add_argument('--init', type=str, default='real', help='noise/real: initialize synthetic images from random noise or randomly sampled real images.')\n",
    "parser.add_argument('--dsa_strategy', type=str, default='color_crop_cutout_flip_scale_rotate', help='differentiable Siamese augmentation strategy')\n",
    "parser.add_argument('--data_path', type=str, default='/home/ssd7T/ZTL_gcond/data_cv', help='dataset path')\n",
    "parser.add_argument('--save_path', type=str, default='result/gen', help='path to save results')\n",
    "parser.add_argument('--dis_metric', type=str, default='ours', help='distance metric')\n",
    "from utils import get_loops, get_dataset, get_network, get_eval_pool, evaluate_synset, get_daparam, match_loss, get_time, TensorDataset, epoch, DiffAugment, ParamDiffAug\n",
    "import warnings\n",
    "args = parser.parse_args([])\n",
    "channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader = get_dataset(args.dataset, args.data_path)\n",
    "\n",
    "images_all = [torch.unsqueeze(dst_train[i][0], dim=0) for i in range(len(dst_train))]\n",
    "labels_all = [dst_train[i][1] for i in range(len(dst_train))]\n",
    "indices_class = [[] for c in range(num_classes)]\n",
    "for i, lab in enumerate(labels_all):\n",
    "    indices_class[lab].append(i)\n",
    "images_all = torch.cat(images_all, dim=0).to(device)\n",
    "labels_all = torch.tensor(labels_all, dtype=torch.long, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_real = []\n",
    "for c in range(num_classes):\n",
    "    idx_shuffle = indexs_real[c]\n",
    "    # img_real.append(images_all[idx_shuffle].to(\"cpu\") )\n",
    "    label_real.append(labels_all[idx_shuffle].to(\"cpu\"))\n",
    "# img_real = torch.from_numpy(np.concatenate(img_real, axis=0))\n",
    "label_real_train = torch.from_numpy(np.concatenate(label_real, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_real_all_train = []\n",
    "label_real_all_train = []\n",
    "for c in range(num_classes):\n",
    "    idx_shuffle = np.random.permutation(indices_class[c])[:500]\n",
    "    img_real_all_train.append(images_all[idx_shuffle].to(\"cpu\") )\n",
    "    label_real_all_train.append(labels_all[idx_shuffle].to(\"cpu\"))\n",
    "img_real_all_train = torch.from_numpy(np.concatenate(img_real_all_train, axis=0))\n",
    "label_real_all_train = torch.from_numpy(np.concatenate(label_real_all_train, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_real = []\n",
    "# label_real = []\n",
    "# for c in range(num_classes):\n",
    "#     idx_shuffle = np.random.permutation(indices_class[c])\n",
    "#     img_real.append(images_all[idx_shuffle].to(\"cpu\") )\n",
    "#     label_real.append(labels_all[idx_shuffle].to(\"cpu\"))\n",
    "# img_real = torch.from_numpy(np.concatenate(img_real, axis=0))\n",
    "# label_real = torch.from_numpy(np.concatenate(label_real, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_real_test = []\n",
    "label_real_test = []\n",
    "for c in range(num_classes):\n",
    "    idx_shuffle = np.random.permutation(indices_class[c])[:500]\n",
    "    img_real_test.append(images_all[idx_shuffle].to(\"cpu\") )\n",
    "    label_real_test.append(labels_all[idx_shuffle].to(\"cpu\"))\n",
    "img_real_test = torch.from_numpy(np.concatenate(img_real_test, axis=0))\n",
    "label_real_test = torch.from_numpy(np.concatenate(label_real_test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_real_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_real_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用全部数据集训"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_classes = 10\n",
    "batch = 50\n",
    "num_feat = 3072\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters())\n",
    "# model = Autoencoder(num_feat).to(device)  \n",
    "# 训练\n",
    "for epoch in range(1000):\n",
    "\n",
    "  total_loss = 0\n",
    "  for c in range(num_classes):\n",
    "                # 获取类别c的合成图像和类别中心\n",
    "    # batch_syn = img_syn[c*args.ipc:(c+1)*args.ipc].reshape((batch, 3, 32, 32)) \n",
    "    batch_img = img_real_all_train[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)) \n",
    "    batch_img = batch_img.to(device) \n",
    "    \n",
    "    # ============ Forward ============\n",
    "    encoded, outputs = autoencoder(batch_img)\n",
    "    loss = criterion(outputs, batch_img)\n",
    "    # ============ Backward ============\n",
    "    # print(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(autoencoder,\"autoencoder_all.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  output = autoencoder(img_real_test.to(device))\n",
    "accs = []\n",
    "model_eval_pool = get_eval_pool(args.eval_mode, args.model, args.model)\n",
    "args.device = \"cuda:0\"\n",
    "import copy\n",
    "accs_all_exps = dict() # record performances of all experiments\n",
    "for key in model_eval_pool:\n",
    "    accs_all_exps[key] = []\n",
    "args.dsa_param = ParamDiffAug()\n",
    "args.dsa = False if args.dsa_strategy in ['none', 'None'] else True\n",
    "model_eval= model_eval_pool[0]\n",
    "\n",
    "# [2023-10-06 20:45:24] Evaluate_00: epoch = 1000 train time = 61 s train loss = 0.000965 train acc = 1.0000, test acc = 0.5001\n",
    "# Evaluate 1 random ConvNet, mean = 0.5001 std = 0.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangkai/.local/lib/python3.9/site-packages/torch/nn/functional.py:4298: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/wangkai/.local/lib/python3.9/site-packages/torch/nn/functional.py:4236: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/wangkai/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-08 21:45:03] Evaluate_01: epoch = 1000 train time = 2135 s train loss = 0.046248 train acc = 0.9898, test acc = 0.5147\n",
      "\n",
      "Evaluate 1 random ConvNet, mean = 0.5147 std = 0.0000\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[1]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)\n",
    "print()\n",
    "print('Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'%(len(accs), model_eval, np.mean(accs), np.std(accs)))\n",
    "\n",
    "\n",
    "\n",
    "# SEED = 187 + test 5000张原图\n",
    "# A + test - 0.5147\n",
    "\n",
    "# 直接用500张蒸馏前原图-蒸留后图片(有对应)训AE  - 0.4998\n",
    "\n",
    "# A + 500张合成图FINETUN  - 0.5213\n",
    "# A + 500张蒸馏前原图-蒸留后图片FINETUN(B)  - 5165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(img_syn, 'img_syn.pt')\n",
    "# torch.save(autoencoder, 'autoencoder_all.pt')\n",
    "# 1.用全部 cifar样本训练一个auto encoder A\n",
    "# 2.用 蒸馏前原图-蒸留后图片 分别作为输入和生成目标来finetune A，得到B\n",
    "# 3.选五百个原图，分别输入A和B，测试B会不会效果更好\n",
    "\n",
    "# SEED = 87 + test 500张原图\n",
    "# A + test 500张原图 - 0.3446\n",
    "\n",
    "# A + 500张合成图FINETUN(冻结encoder)  - 0.3576\n",
    "# A + 500张蒸馏前原图-蒸留后图片FINETUN(B)(冻结encoder)  - 0.3075\n",
    "\n",
    "\n",
    "# A + 500张合成图FINETUN  - 0.3181\n",
    "# A + 500张蒸馏前原图-蒸留后图片FINETUN(B)  - 0.3381\n",
    "\n",
    "\n",
    "# SEED = 187 + test 500张原图\n",
    "# A + test 500张原图 - 0.3559\n",
    "\n",
    "# A + 500张合成图FINETUN(冻结encoder)  - 0.3429\n",
    "# A + 500张蒸馏前原图-蒸留后图片FINETUN(B)(冻结encoder)  - 0.3179\n",
    "\n",
    "\n",
    "# A + 500张合成图FINETUN  - 0.3607\n",
    "# A + 500张蒸馏前原图-蒸留后图片FINETUN(B)  - 0.3365\n",
    "\n",
    "\n",
    "# SEED = 87 + test 5000张原图\n",
    "# A + test 500张原图 - 0.3446\n",
    "\n",
    "# A + 500张合成图FINETUN(冻结encoder) - 0.3576\n",
    "# A + 500张蒸馏前原图-蒸留后图片FINETUN(B)(冻结encoder)  - 0.3075\n",
    "\n",
    "\n",
    "# A + 500张合成图FINETUN  - 0.3181\n",
    "# A + 500张蒸馏前原图-蒸留后图片FINETUN(B)  - 0.3381\n",
    "\n",
    "\n",
    "# SEED = 187 + test 5000张原图\n",
    "# A + test 500张原图 - 0.5176\n",
    "\n",
    "# A + 500张合成图FINETUN(冻结encoder)  - 0.4242\n",
    "# A + 500张蒸馏前原图-蒸留后图片FINETUN(B)(冻结encoder)  - 0.3664\n",
    "\n",
    "\n",
    "# A + 500张合成图FINETUN  - 0.5289\n",
    "# A + 500张蒸馏前原图-蒸留后图片FINETUN(B)  - 0.3916\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A + 500张合成图FINETUN\n",
    "\n",
    "num_classes = 10\n",
    "batch = 50\n",
    "num_feat = 3072\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters())\n",
    "# model = Autoencoder(num_feat).to(device)  \n",
    "# 训练\n",
    "for epoch in range(1000):\n",
    "\n",
    "  total_loss = 0\n",
    "  for c in range(num_classes):\n",
    "                # 获取类别c的合成图像和类别中心\n",
    "                # image_syn[c*args.ipc:(c+1)*args.ipc].reshape((args.ipc, channel, im_size[0], im_size[1]))\n",
    "    batch_img = img_syn[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)) \n",
    "    batch_img = batch_img.to(device) \n",
    "    \n",
    "    # ============ Forward ============\n",
    "    encoded, outputs = autoencoder(batch_img)\n",
    "    loss = criterion(outputs, batch_img)\n",
    "    # ============ Backward ============\n",
    "    # print(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-08 22:21:02] Evaluate_01: epoch = 1000 train time = 2104 s train loss = 0.026665 train acc = 0.9954, test acc = 0.5279\n",
      "\n",
      "Evaluate 2 random ConvNet, mean = 0.5213 std = 0.0066\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  output = autoencoder(img_real_test.to(device))\n",
    "\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[1]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)\n",
    "print()\n",
    "print('Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'%(len(accs), model_eval, np.mean(accs), np.std(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用合成数据集微调\n",
    "autoencoder = torch.load('autoencoder_all.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "batch = 50\n",
    "num_feat = 3072\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters())\n",
    "# model = Autoencoder(num_feat).to(device)  \n",
    "# 训练\n",
    "for epoch in range(1000):\n",
    "\n",
    "  total_loss = 0\n",
    "  for c in range(num_classes):\n",
    "                # 获取类别c的合成图像和类别中心\n",
    "    batch_syn = img_syn[c*args.ipc:(c+1)*args.ipc].reshape((batch, 3, 32, 32)) \n",
    "    batch_img = img_real_train[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)) \n",
    "    batch_img = batch_img.to(device) \n",
    "    \n",
    "    # ============ Forward ============\n",
    "    encoded, outputs = autoencoder(batch_img)\n",
    "    loss = criterion(outputs, batch_syn)\n",
    "    # ============ Backward ============\n",
    "    # print(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-08 22:57:48] Evaluate_01: epoch = 1000 train time = 2149 s train loss = 0.049232 train acc = 0.9890, test acc = 0.5069\n",
      "\n",
      "Evaluate 3 random ConvNet, mean = 0.5165 std = 0.0087\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  output = autoencoder(img_real_test.to(device))\n",
    "\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[1]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)\n",
    "print()\n",
    "print('Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'%(len(accs), model_eval, np.mean(accs), np.std(accs)))\n",
    "# [2023-10-06 20:45:24] Evaluate_00: epoch = 1000 train time = 61 s train loss = 0.000965 train acc = 1.0000, test acc = 0.5001\n",
    "# Evaluate 1 random ConvNet, mean = 0.5001 std = 0.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_encoder_parameters(model):\n",
    "    for param in model.encoder.parameters():\n",
    "        param.requires_grad = False\n",
    "# 用合成数据集微调\n",
    "autoencoder = torch.load('autoencoder_all.pt') \n",
    "freeze_encoder_parameters(autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A + 500张合成图FINETUN(冻结encoder)\n",
    "\n",
    "num_classes = 10\n",
    "batch = 50\n",
    "num_feat = 3072\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters())\n",
    "# model = Autoencoder(num_feat).to(device)  \n",
    "# 训练\n",
    "for epoch in range(1000):\n",
    "\n",
    "  total_loss = 0\n",
    "  for c in range(num_classes):\n",
    "                # 获取类别c的合成图像和类别中心\n",
    "                # image_syn[c*args.ipc:(c+1)*args.ipc].reshape((args.ipc, channel, im_size[0], im_size[1]))\n",
    "    batch_img = img_syn[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)) \n",
    "    batch_img = batch_img.to(device) \n",
    "    \n",
    "    # ============ Forward ============\n",
    "    encoded, outputs = autoencoder(batch_img)\n",
    "    loss = criterion(outputs, batch_img)\n",
    "    # ============ Backward ============\n",
    "    # print(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "  output = autoencoder(img_real_test.to(device))\n",
    "\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[1]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)\n",
    "print()\n",
    "print('Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'%(len(accs), model_eval, np.mean(accs), np.std(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = torch.load('autoencoder_all.pt') \n",
    "freeze_encoder_parameters(autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# A + 500张蒸馏前原图-蒸留后图片FINETUN(B)(冻结encoder)\n",
    "num_classes = 10\n",
    "batch = 50\n",
    "num_feat = 3072\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters())\n",
    "# model = Autoencoder(num_feat).to(device)  \n",
    "# 训练\n",
    "for epoch in range(1000):\n",
    "\n",
    "  total_loss = 0\n",
    "  for c in range(num_classes):\n",
    "                # 获取类别c的合成图像和类别中心\n",
    "                # image_syn[c*args.ipc:(c+1)*args.ipc].reshape((args.ipc, channel, im_size[0], im_size[1]))\n",
    "\n",
    "    \n",
    "    # idx_shuffle = np.random.permutation(indices_class[c])[:batch]\n",
    "    batch_img_real = img_real_test[c*batch:(c+1)*batch].reshape((batch, channel, im_size[0], im_size[1])).to(device) \n",
    "    \n",
    "    batch_img = img_syn[c*batch:(c+1)*batch].reshape((batch, channel, im_size[0], im_size[1])).to(device) \n",
    "    \n",
    "    # batch_img = batch_img_real.to(device) \n",
    "    \n",
    "    # ============ Forward ============\n",
    "    encoded, outputs = autoencoder(batch_img_real)\n",
    "    loss = criterion(outputs, batch_img)\n",
    "    # ============ Backward ============\n",
    "    # print(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "  output = autoencoder(img_real_test.to(device))\n",
    "\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[1]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)\n",
    "print()\n",
    "print('Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'%(len(accs), model_eval, np.mean(accs), np.std(accs)))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 500 张合成图训练AE：37\n",
    "# 全部CIFA10训练AE ： 39.8\n",
    "# 500 张CIFA10训练AE ： 36.5\n",
    "# 500张CIFA10本身测试 ： 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ztl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
