{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "from utils import get_loops, get_dataset, get_network, get_eval_pool, evaluate_synset, get_daparam, match_loss, get_time, TensorDataset, epoch, DiffAugment, ParamDiffAug\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# watch -n 1 nvidia-smi\n",
    "import os\n",
    "\n",
    "# 显示第 0 和第 1 个 GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "parser = argparse.ArgumentParser(description='Parameter Processing')\n",
    "parser.add_argument('--dataset', type=str, default='CIFAR10', help='dataset')\n",
    "parser.add_argument('--model', type=str, default='ConvNet', help='model')\n",
    "parser.add_argument('--ipc', type=int, default=50, help='image(s) per class')\n",
    "parser.add_argument('--eval_mode', type=str, default='SS', help='eval_mode') # S: the same to training model, M: multi architectures,  W: net width, D: net depth, A: activation function, P: pooling layer, N: normalization layer,\n",
    "\n",
    "\n",
    "\n",
    "parser.add_argument('--num_exp', type=int, default=3, help='the number of experiments')\n",
    "\n",
    "\n",
    "\n",
    "parser.add_argument('--num_eval', type=int, default=1, help='the number of evaluating randomly initialized models')\n",
    "parser.add_argument('--epoch_eval_train', type=int, default=1000, help='epochs to train a model with synthetic data') # it can be small for speeding up with little performance drop\n",
    "parser.add_argument('--Iteration', type=int, default=2000, help='training iterations')\n",
    "parser.add_argument('--lr_img', type=float, default=1.0, help='learning rate for updating synthetic images')\n",
    "parser.add_argument('--lr_net', type=float, default=0.01, help='learning rate for updating network parameters')\n",
    "parser.add_argument('--batch_real', type=int, default=256, help='batch size for real data')\n",
    "parser.add_argument('--batch_train', type=int, default=256, help='batch size for training networks')\n",
    "parser.add_argument('--init', type=str, default='real', help='noise/real: initialize synthetic images from random noise or randomly sampled real images.')\n",
    "parser.add_argument('--dsa_strategy', type=str, default='color_crop_cutout_flip_scale_rotate', help='differentiable Siamese augmentation strategy')\n",
    "parser.add_argument('--data_path', type=str, default='/home/ssd7T/ZTL_gcond/data_cv', help='dataset path')\n",
    "parser.add_argument('--save_path', type=str, default='/home/ssd7T/ztl_dm/gen', help='path to save results')\n",
    "parser.add_argument('--dis_metric', type=str, default='ours', help='distance metric')\n",
    "\n",
    "args = parser.parse_args([])\n",
    "args.method = 'DM'\n",
    "args.outer_loop, args.inner_loop = get_loops(args.ipc)\n",
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "args.dsa_param = ParamDiffAug()\n",
    "args.dsa = False if args.dsa_strategy in ['none', 'None'] else True\n",
    "\n",
    "if not os.path.exists(args.data_path):\n",
    "    os.mkdir(args.data_path)\n",
    "\n",
    "if not os.path.exists(args.save_path):\n",
    "    os.mkdir(args.save_path)\n",
    "\n",
    "eval_it_pool = np.arange(0, args.Iteration+1, 2000).tolist() if args.eval_mode == 'S' or args.eval_mode == 'SS' else [args.Iteration] # The list of iterations when we evaluate models and record results.\n",
    "print('eval_it_pool: ', eval_it_pool)\n",
    "channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader = get_dataset(args.dataset, args.data_path)\n",
    "model_eval_pool = get_eval_pool(args.eval_mode, args.model, args.model)\n",
    "\n",
    "\n",
    "accs_all_exps = dict() # record performances of all experiments\n",
    "for key in model_eval_pool:\n",
    "    accs_all_exps[key] = []\n",
    "\n",
    "data_save = []\n",
    "pairs_real = []\n",
    "indexs_real = []\n",
    "\n",
    "for exp in range(args.num_exp):\n",
    "    # pairs_real = []\n",
    "    # indexs_real = []\n",
    "    exp = exp + 80\n",
    "    print('\\n================== Exp %d ==================\\n '%exp)\n",
    "    print('Hyper-parameters: \\n', args.__dict__)\n",
    "    print('Evaluation model pool: ', model_eval_pool)\n",
    "\n",
    "    ''' organize the real dataset '''\n",
    "    images_all = []\n",
    "    labels_all = []\n",
    "    indices_class = [[] for c in range(num_classes)]\n",
    "\n",
    "    images_all = [torch.unsqueeze(dst_train[i][0], dim=0) for i in range(len(dst_train))]\n",
    "    labels_all = [dst_train[i][1] for i in range(len(dst_train))]\n",
    "    for i, lab in enumerate(labels_all):\n",
    "        indices_class[lab].append(i)\n",
    "    images_all = torch.cat(images_all, dim=0).to(args.device)\n",
    "    labels_all = torch.tensor(labels_all, dtype=torch.long, device=args.device)\n",
    "\n",
    "\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        print('class c = %d: %d real images'%(c, len(indices_class[c])))\n",
    "\n",
    "    def get_images(c, n): # get random n images from class c\n",
    "        idx_shuffle = np.random.permutation(indices_class[c])[:n]\n",
    "        return images_all[idx_shuffle]\n",
    "    \n",
    "    def get_images_init(c, n,exp): # get random n images from class c\n",
    "        # start_idx = i  # 指定起始索引 i\n",
    "        # end_idx = i + n  # 计算结束索引（不包括结束索引）\n",
    "\n",
    "        # 从指定的起始索引到结束索引获取元素\n",
    "        idx_shuffle  = indices_class[c][exp:exp + n]\n",
    "\n",
    "        # idx_shuffle = np.random.permutation(indices_class[c])[:n]\n",
    "        return images_all[idx_shuffle],idx_shuffle\n",
    "\n",
    "    for ch in range(channel):\n",
    "        print('real images channel %d, mean = %.4f, std = %.4f'%(ch, torch.mean(images_all[:, ch]), torch.std(images_all[:, ch])))\n",
    "\n",
    "\n",
    "    ''' initialize the synthetic data '''\n",
    "    image_syn = torch.randn(size=(num_classes*args.ipc, channel, im_size[0], im_size[1]), dtype=torch.float, requires_grad=True, device=args.device)\n",
    "    label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]\n",
    "\n",
    "    if args.init == 'real':\n",
    "        print('initialize synthetic data from random real images')\n",
    "        for c in range(num_classes):\n",
    "            reals,index = get_images_init(c, args.ipc,exp)\n",
    "            reals = reals.detach().data\n",
    "            pairs_real.append(reals)\n",
    "            indexs_real.append(index)\n",
    "            image_syn.data[c*args.ipc:(c+1)*args.ipc] = reals\n",
    "            # pairs_real\n",
    "    else:\n",
    "        print('initialize synthetic data from random noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_real_test= torch.cat(pairs_real, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_real_test = []\n",
    "for i in range(int(len(indexs_real)/10)):\n",
    "    # print(i)\n",
    "    label_real_test_ = []\n",
    "    for c in range(num_classes):\n",
    "        idx_shuffle = indexs_real[c + i*10]\n",
    "        label_real_test_.append(labels_all[idx_shuffle].to(\"cpu\"))\n",
    "        # print()\n",
    "    # img_real = torch.from_numpy(np.concatenate(img_real, axis=0))\n",
    "    label_real_test_ = torch.from_numpy(np.concatenate(label_real_test_, axis=0))\n",
    "    label_real_test.append(label_real_test_)\n",
    "label_real_test = torch.cat(label_real_test, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_real_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_syn = []\n",
    "label_syn = []\n",
    "img_real_train = []\n",
    "label_real_train = []\n",
    "# /home/ssd7T/ztl_dm/indexs_real_20.pt\n",
    "for i in range(80):\n",
    "    try:\n",
    "    \n",
    "        img_syn_ = torch.load(f'/home/ssd7T/ztl_dm/img_syn_{i}.pt')\n",
    "        label_syn_ = torch.load(f'/home/ssd7T/ztl_dm/label_syn_{i}.pt')\n",
    "        pairs_real_=torch.load(f'/home/ssd7T/ztl_dm/pairs_real_{i}.pt')\n",
    "        indexs_real_=torch.load(f'/home/ssd7T/ztl_dm/indexs_real_{i}.pt')\n",
    "        \n",
    "        img_real_train_ = torch.cat(pairs_real_, dim=0)\n",
    "        \n",
    "    \n",
    "        label_real_ = []\n",
    "        for c in range(num_classes):\n",
    "            idx_shuffle = indexs_real_[c]\n",
    "            label_real_.append(labels_all[idx_shuffle].to(\"cpu\"))\n",
    "        # img_real = torch.from_numpy(np.concatenate(img_real, axis=0))\n",
    "        label_real_train_ = torch.from_numpy(np.concatenate(label_real_, axis=0))\n",
    "        # label_real_train_ = torch.cat(label_real_train_, dim=0)\n",
    "        \n",
    "        img_syn.append(img_syn_)\n",
    "        label_syn.append(label_syn_)\n",
    "        img_real_train.append(img_real_train_)\n",
    "        label_real_train.append( label_real_train_)\n",
    "        # if i == 3 or i == 22 or i == 42 or i == 62:\n",
    "        #     pairs_real_=torch.load(f'pairs_real_{i}.pt')\n",
    "        #     img_real_train_ = torch.cat(pairs_real_, dim=0)\n",
    "        #     img_real_train.append(img_real_train_)\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "img_syn = torch.cat(img_syn, dim=0).to(device)\n",
    "label_syn = torch.cat(label_syn, dim=0).to(device)\n",
    "img_real_train = torch.cat(img_real_train, dim=0).to(device)\n",
    "label_real_train = torch.cat(label_real_train, dim=0).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_real_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_real_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_syn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy\n",
    "import numpy as np\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Torchvision\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# OS\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 87\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "\n",
    "def print_model(encoder, decoder):\n",
    "    print(\"============== Encoder ==============\")\n",
    "    print(encoder)\n",
    "    print(\"============== Decoder ==============\")\n",
    "    print(decoder)\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    autoencoder = Autoencoder()\n",
    "    print_model(autoencoder.encoder, autoencoder.decoder)\n",
    "    if torch.cuda.is_available():\n",
    "        autoencoder = autoencoder.cuda()\n",
    "        print(\"Model moved to GPU in order to speed up training.\")\n",
    "    return autoencoder\n",
    "\n",
    "\n",
    "def get_torch_vars(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.cpu().numpy()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Input size: [batch, 3, 32, 32]\n",
    "        # Output size: [batch, 3, 32, 32]\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 12, 4, stride=2, padding=1),            # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(12, 24, 4, stride=2, padding=1),           # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.Conv2d(24, 48, 4, stride=2, padding=1),           # [batch, 48, 4, 4]\n",
    "            nn.ReLU(),\n",
    "# \t\t\tnn.Conv2d(48, 96, 4, stride=2, padding=1),           # [batch, 96, 2, 2]\n",
    "#             nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(96, 48, 4, stride=2, padding=1),  # [batch, 48, 4, 4]\n",
    "#             nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),  # [batch, 24, 8, 8]\n",
    "            nn.ReLU(),\n",
    "\t\t\tnn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),  # [batch, 12, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),   # [batch, 3, 32, 32]\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = create_model().to(device)\n",
    "\n",
    "# Load data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder = torch.load('autoencoder_all.pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = 10\n",
    "batch = 50\n",
    "num_feat = 3072\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters())\n",
    "# model = Autoencoder(num_feat).to(device)  \n",
    "# 训练\n",
    "for epoch in range(1000):\n",
    "\n",
    "  total_loss = 0\n",
    "  for c in range(num_classes):\n",
    "                # 获取类别c的合成图像和类别中心\n",
    "                # image_syn[c*args.ipc:(c+1)*args.ipc].reshape((args.ipc, channel, im_size[0], im_size[1]))\n",
    "    batch_img = img_real_train[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    \n",
    "    # batch_syn = img_syn[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    \n",
    "    # ============ Forward ============\n",
    "    encoded, outputs = autoencoder(batch_img)\n",
    "    # print((outputs + batch_img).shape)\n",
    "    loss = criterion(outputs, batch_img)\n",
    "    # print(loss.item())\n",
    "    # ============ Backward ============\n",
    "    # print(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "model_eval_pool = get_eval_pool(args.eval_mode, args.model, args.model)\n",
    "import copy\n",
    "accs_all_exps = dict() # record performances of all experiments\n",
    "for key in model_eval_pool:\n",
    "    accs_all_exps[key] = []\n",
    "args.dsa_param = ParamDiffAug()\n",
    "args.dsa = False if args.dsa_strategy in ['none', 'None'] else True\n",
    "model_eval= model_eval_pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A - 输入测试图，生成图，label同测试图\n",
    "with torch.no_grad():\n",
    "  output = autoencoder(img_real_test.to(device))\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[1]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)\n",
    "# print()\n",
    "# print('Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'%(len(accs), model_eval, np.mean(accs), np.std(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A\n",
    "autoencoder = create_model().to(device)\n",
    "num_classes = 10\n",
    "batch = 50\n",
    "num_feat = 3072\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters())\n",
    "# model = Autoencoder(num_feat).to(device)  \n",
    "# 训练\n",
    "for epoch in range(3000):\n",
    "\n",
    "  total_loss = 0\n",
    "  for c in range(num_classes):\n",
    "                # 获取类别c的合成图像和类别中心\n",
    "                # image_syn[c*args.ipc:(c+1)*args.ipc].reshape((args.ipc, channel, im_size[0], im_size[1]))\n",
    "    batch_img = images_all[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    \n",
    "    # batch_syn = img_syn[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    \n",
    "    # ============ Forward ============\n",
    "    encoded, outputs = autoencoder(batch_img)\n",
    "    # print((outputs + batch_img).shape)\n",
    "    loss = criterion(outputs, batch_img)\n",
    "    # print(loss.item())\n",
    "    # ============ Backward ============\n",
    "    # print(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A - 输入测试图，生成图，label同测试图\n",
    "with torch.no_grad():\n",
    "  output = autoencoder(img_real_test.to(device))\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[1]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)\n",
    "# print()\n",
    "# print('Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'%(len(accs), model_eval, np.mean(accs), np.std(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(autoencoder,'autoencoder_all.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "batch = 50\n",
    "num_feat = 3072\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters())\n",
    "# model = Autoencoder(num_feat).to(device)  \n",
    "# 训练\n",
    "for epoch in range(1000):\n",
    "\n",
    "  total_loss = 0\n",
    "  for c in range(num_classes):\n",
    "                # 获取类别c的合成图像和类别中心\n",
    "                # image_syn[c*args.ipc:(c+1)*args.ipc].reshape((args.ipc, channel, im_size[0], im_size[1]))\n",
    "    batch_img = img_real_train[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    \n",
    "    batch_syn = img_syn[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    \n",
    "    # ============ Forward ============\n",
    "    encoded, outputs = autoencoder(batch_img)\n",
    "    # print((outputs + batch_img).shape)\n",
    "    loss = criterion(outputs, batch_syn)\n",
    "    # print(loss.item())\n",
    "    # ============ Backward ============\n",
    "    # print(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A - 输入测试图，生成图，label同测试图\n",
    "with torch.no_grad():\n",
    "  output = autoencoder(img_real_test.to(device))\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[1]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)\n",
    "# print()\n",
    "# print('Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'%(len(accs), model_eval, np.mean(accs), np.std(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = torch.load('autoencoder_all.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "batch = 50\n",
    "num_feat = 3072\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters())\n",
    "# model = Autoencoder(num_feat).to(device)  \n",
    "# 训练\n",
    "for epoch in range(1000):\n",
    "\n",
    "  total_loss = 0\n",
    "  for c in range(num_classes):\n",
    "                # 获取类别c的合成图像和类别中心\n",
    "                # image_syn[c*args.ipc:(c+1)*args.ipc].reshape((args.ipc, channel, im_size[0], im_size[1]))\n",
    "    # batch_img = img_real_train[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    \n",
    "    batch_syn = img_syn[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    \n",
    "    # ============ Forward ============\n",
    "    encoded, outputs = autoencoder(batch_syn)\n",
    "    # print((outputs + batch_img).shape)\n",
    "    loss = criterion(outputs, batch_syn)\n",
    "    # print(loss.item())\n",
    "    # ============ Backward ============\n",
    "    # print(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从训练时没见过的原图开始，生成的合成数据性能 训练1W8,test 4500 - 0.3503\n",
    "# 从训练时见过的原图开始，生成的合成数据性能 训练1W8,test 4500 - 0.3487\n",
    "\n",
    "# A + FINETUNE + 从训练时没见过的原图开始，生成的合成数据性能 训练1W8,test 4500 -  0.3546\n",
    "with torch.no_grad():\n",
    "  output = autoencoder(img_real_test.to(device))\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[1]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)\n",
    "# print()\n",
    "# print('Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'%(len(accs), model_eval, np.mean(accs), np.std(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = create_model().to(device)\n",
    "num_classes = 10\n",
    "batch = 50\n",
    "num_feat = 3072\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters())\n",
    "# model = Autoencoder(num_feat).to(device)  \n",
    "# 训练\n",
    "for epoch in range(1000):\n",
    "\n",
    "  total_loss = 0\n",
    "  for c in range(num_classes):\n",
    "                # 获取类别c的合成图像和类别中心\n",
    "                # image_syn[c*args.ipc:(c+1)*args.ipc].reshape((args.ipc, channel, im_size[0], im_size[1]))\n",
    "    batch_img = img_real_train[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    \n",
    "    batch_syn = img_syn[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    \n",
    "    # ============ Forward ============\n",
    "    encoded, outputs = autoencoder(batch_img)\n",
    "    # print((outputs + batch_img).shape)\n",
    "    loss = criterion(outputs, batch_syn)\n",
    "    # print(loss.item())\n",
    "    # ============ Backward ============\n",
    "    # print(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从训练时没见过的原图开始，生成的合成数据性能 训练1W8,test 4500 - 0.3503\n",
    "# 从训练时见过的原图开始，生成的合成数据性能 训练1W8,test 4500 - 0.3487\n",
    "\n",
    "# A + FINETUNE + 从训练时没见过的原图开始，生成的合成数据性能 训练1W8,test 4500 -  0.3546\n",
    "with torch.no_grad():\n",
    "  output = autoencoder(img_real_test.to(device))\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[1]), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)\n",
    "# print()\n",
    "# print('Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'%(len(accs), model_eval, np.mean(accs), np.std(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test 合成数据集结果（1500张）\n",
    "# 直接输入原图： 0.5100\n",
    "# 样本对训练原图 - 合成图差异： 0.5093\n",
    "\n",
    "\n",
    "# A+合成图 FINTUNE :    0.4056 - 0.005  |   0.3983 0.4110 0.4075\n",
    "# A :                  0.3860 - 0.005  |   0.3918 0.3859 0.3802\n",
    "# A+样本对 FINTUNE :   0.3840 - 0.004  |   0.3885 0.3785 0.3850\n",
    "# 只用样本对中的原图 :  0.3808 - 0.006  |   0.3780 0.3896 0.3749\n",
    "# 只用样本对训 ：       0.3719, 0.005 |   0.3642,0.3756,0.3759\n",
    "\n",
    "accs = [0.3642,0.3756,0.3759]np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37189999999999995, 0.00544609952167603)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "batch = 50\n",
    "num_feat = 3072\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters())\n",
    "# model = Autoencoder(num_feat).to(device)  \n",
    "# 训练\n",
    "for epoch in range(1000):\n",
    "\n",
    "  total_loss = 0\n",
    "  for c in range(num_classes):\n",
    "                # 获取类别c的合成图像和类别中心\n",
    "                # image_syn[c*args.ipc:(c+1)*args.ipc].reshape((args.ipc, channel, im_size[0], im_size[1]))\n",
    "    batch_img = img_real_train[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    \n",
    "    batch_syn = img_syn[c*batch:(c+1)*batch].reshape((batch, 3, 32, 32)).to(device) \n",
    "    \n",
    "    # ============ Forward ============\n",
    "    encoded, outputs = autoencoder(batch_img)\n",
    "    # print((outputs + batch_img).shape)\n",
    "    loss = criterion(outputs, batch_syn - batch_img)\n",
    "    # print(loss.item())\n",
    "    # ============ Backward ============\n",
    "    # print(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "model_eval_pool = get_eval_pool(args.eval_mode, args.model, args.model)\n",
    "import copy\n",
    "accs_all_exps = dict() # record performances of all experiments\n",
    "for key in model_eval_pool:\n",
    "    accs_all_exps[key] = []\n",
    "args.dsa_param = ParamDiffAug()\n",
    "args.dsa = False if args.dsa_strategy in ['none', 'None'] else True\n",
    "model_eval= model_eval_pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从训练时没见过的原图开始，生成的合成数据性能 训练1W8,test 4500 - 0.3503\n",
    "# 从训练时见过的原图开始，生成的合成数据性能 训练1W8,test 4500 - 0.3487\n",
    "\n",
    "# A + FINETUNE + 从训练时没见过的原图开始，生成的合成数据性能 训练1W8,test 4500 -  0.3546\n",
    "with torch.no_grad():\n",
    "  output = autoencoder(img_real_test.to(device))\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(output[1] + img_real_test), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)\n",
    "# print()\n",
    "# print('Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'%(len(accs), model_eval, np.mean(accs), np.std(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save('autoencoder_all.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_save = []\n",
    "net_eval = get_network(model_eval, channel, num_classes, im_size).to(device) # get a random model\n",
    "image_syn_eval, label_syn_eval = copy.deepcopy(img_real_test), copy.deepcopy(label_real_test) # avoid any unaware modification\n",
    "_, acc_train, acc_test = evaluate_synset(1, net_eval, image_syn_eval, label_syn_eval, testloader, args)\n",
    "accs.append(acc_test)\n",
    "# print()\n",
    "# print('Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'%(len(accs), model_eval, np.mean(accs), np.std(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 原图： 0.5100\n",
    "# 样本对训练原图 - 合成图差异： 0.5093\n",
    "# A : 0.3791\n",
    "# A+样本对 FINTUNE : \n",
    "# A+合成图 FINTUNE : \n",
    "# 样本对 ： "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_syn_vis = copy.deepcopy(output[1].detach().cpu()+ img_real_test.cpu())\n",
    "from torchvision.utils import save_image\n",
    "image_syn_vis[image_syn_vis<0] = 0.0\n",
    "image_syn_vis[image_syn_vis>1] = 1.0\n",
    "save_image(image_syn_vis, \"/home/wangkai/ztl_project/difussion-dd/DatasetCondensation-master/111.png\", nrow=50) # Trying normalize = True/False may get better visual effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_syn_ = torch.load(f'/home/ssd7T/ztl_ftd/img_syn_57.pt')\n",
    "# /home/ssd7T/ztl_ftd/img_syn_57.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = torch.load(f'/home/ssd7T/ztl_dm/mtt/CIFAR10/ConvNet/replay_buffer_0.pt')\n",
    "# /home/ssd7T/ztl_ftd/img_syn_57.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_syn_vis = copy.deepcopy(img_syn_.detach().cpu())\n",
    "from torchvision.utils import save_image\n",
    "image_syn_vis[image_syn_vis<0] = 0.0\n",
    "image_syn_vis[image_syn_vis>1] = 1.0\n",
    "save_image(image_syn_vis, \"/home/wangkai/ztl_project/difussion-dd/DatasetCondensation-master/333.png\", nrow=50) # Trying normalize = True/False may get better visual effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ztl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
